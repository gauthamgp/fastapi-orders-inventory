WEBVTT

00:04:31.000 --> 00:04:38.000
Okay, so I believe, guys, I'm audible and visible to all of you. Good morning, everyone. Yeah?

00:04:38.000 --> 00:05:08.000
So in some time, maybe in next 2-3 minutes, we are going to start with the class.

00:05:31.000 --> 00:05:42.000
Okay, fine guys, so I believe everyone has joined, so let's start with the class. So yesterday, I was talking about, uh, basic of embedding, by the way, like, what technically the embedding is, and, uh.

00:05:42.000 --> 00:05:52.000
How we'll be able to perform those embeddings with the help of, maybe, uh, OpenAI model, which is available inside Yuri, or otherwise, we can try to use any other model from, uh.

00:05:52.000 --> 00:05:57.000
Hugging face, and then we can try to convert those data into an embedding vector.

00:05:57.000 --> 00:06:08.000
Now, so, in today's class, I'll be talking about a practical implementation, that how we will be able to do this embeddings in our practical manner by using some of these databases. For example.

00:06:08.000 --> 00:06:27.000
Facebook AI Similarity Search, or you can say, uh, we can try to use even a ChromaDB, we can try to use a Quadrant, Pinecone, and… many other vector DBs, which is already available into a market, which is going to make your life easy. Plus, it has been used for a different, different kind of purposes.

00:06:27.000 --> 00:06:38.000
Now, so those who have missed studies class, so, uh, just advice, so please try to, like, go through this, today's class. I have already, like, uploaded the videos inside your dashboard.

00:06:38.000 --> 00:06:46.000
And a material. I have not given, like, any kind of assignment in my studies class, but yeah, so please try to go through a video. I think that is going to help you out a lot.

00:06:46.000 --> 00:06:52.000
So, shall we start, guys? Yes, everyone? Yep, with the practical.

00:06:52.000 --> 00:07:00.000
So, our very first data base that we are going to consider is a Facebook AI Similarity Search. Yes?

00:07:00.000 --> 00:07:08.000
Emerging class recording, um, yeah, so, obviously, we had discussed a concept, so you will love it.

00:07:08.000 --> 00:07:17.000
Okay, so I believe my screen is visible to all of you. Let's get started. So, the very first database that we are going to use it over here is a Facebook AI Similarity Search.

00:07:17.000 --> 00:07:26.000
So, uh, open up your VS Code, guys, uh, everyone. Vs Code, Google Collab, whatever you want, just try to open it, open it up.

00:07:26.000 --> 00:07:30.000
And inside a VS Code, so just try to create a folder.

00:07:30.000 --> 00:07:39.000
Let's suppose I'm creating it like a vector DB. Mmm, inside the drive, so I'm going to create.

00:07:39.000 --> 00:07:51.000
Vectordb GenAI. Okay. So… Let me close everything. Fine. So just create one simple…

00:07:51.000 --> 00:08:01.000
Folder, and inside this folder, so maybe we can try to create a Jupyter notebook. So, here, F-A-I-S-S dot IPYNB.

00:08:01.000 --> 00:08:14.000
So, Facebook AI Similarity Search. This is the database which we are going to discuss in a very first place. And, uh, I have just created a file for that one, so that I can write a code, and then I can try to do the experimentation.

00:08:14.000 --> 00:08:21.000
So everyone, please do it, and as I will progress, as I will start writing a code, so I'll keep on sharing those code with all of you.

00:08:21.000 --> 00:08:31.000
So that, uh, you all will be able to execute it.

00:08:31.000 --> 00:08:53.000
Yep. Service start, guys?

00:08:53.000 --> 00:09:05.000
Hmm. Please use quadrant as well in a later phase. Yeah, so my intention is to discuss all of these databases, so not just, like, uh, FAISS, but, uh.

00:09:05.000 --> 00:09:12.000
Facebook AI similarity search, obviously, then ChromaDB, then Pinecone, then Babyat, and then Quadrant, all of these.

00:09:12.000 --> 00:09:22.000
Fine?

00:09:22.000 --> 00:09:32.000
Neo 4J, no. So, whatever I have mentioned, uh, inside this syllabus, so I will be talking about that. Apart from that, I won't be talking about any other databases.

00:09:32.000 --> 00:09:46.000
Uh, reason is very simple. There are hundreds of databases out there, and if… I'll talk about a vector DB. So, almost everyone, even a MongoDB, right? So, MongoDB was a document-based database, it was a NoSQL-based databases.

00:09:46.000 --> 00:09:53.000
But in their recent release, so they have started providing, uh, even, uh, that.

00:09:53.000 --> 00:10:12.000
Yeah, so even now, MongoDB supports our vector databases concept. And concept is, like, almost similar. Fine. So, first of all, guys, we are going to talk about, uh, if AISS. So, Facebook AI Similarity Search. So, that is basically a database name. So, in a sort form, in an abbreviated form, so we try to call it as a.

00:10:12.000 --> 00:10:25.000
If AISS. Now, so if AISS is basically an open source database, so Facebook has created it, and they have made it open source, so that you all will be able to use it by just doing some sort of a.

00:10:25.000 --> 00:10:37.000
Installation, right? By just doing an installation, and there is no restriction. They are going to put over here. You can host it on your platform or on your server, or anywhere that you want.

00:10:37.000 --> 00:10:47.000
And, um, this is one of the amazing open source databases that you all will be able to get. And very soon, you are going to experience it, very soon you are going to see the same thing, yeah?

00:10:47.000 --> 00:11:02.000
So, we start, guys, with Facebook has similarity such. Yeah? Okay. So let's get started. I'm going to keep message only to host and panelists, so that whenever I'm going to send a code.

00:11:02.000 --> 00:11:12.000
So, you will be able to see it. Yeah. Now… So, yes, almost all the databases that we have listed, it comes under our VectorDB now.

00:11:12.000 --> 00:11:22.000
Fine. So, in a very first place, guys, what we have to do, so we have to do some sort of an installation, yeah? So unless and until we are not doing an installation, so we'll not be able to run through the entire code.

00:11:22.000 --> 00:11:29.000
So keeping that in our mind, what you have to do, so you have to go ahead and you have to create the environment. Environment creation is important.

00:11:29.000 --> 00:11:37.000
Uh, because some of you, uh, must be having a Python 3.13, some of you must be having Python 3.12, some of you having maybe Python 3.10.

00:11:37.000 --> 00:11:48.000
So, a different, different kind of a version. And, uh, different, different versions is going to give you, uh, problems, and some of you will be able to execute a code, some of you will not be able to execute a code.

00:11:48.000 --> 00:12:05.000
So, keeping that in a mind, let's try to create an environment, one ideal environment, so where we are going to keep each and everything, yeah? And we will try to… like, uh, keep only one version of the Python. Now, so it's.

00:12:05.000 --> 00:12:16.000
Better, right? It's better to go ahead with an environment creation, with the conda installation. So, I know most of you have just a Python installation in your system.

00:12:16.000 --> 00:12:24.000
But it's advisable to go ahead with the Conda installation. Conda command is, again, very much simple, and you all will be able to do an installation quickly.

00:12:24.000 --> 00:12:30.000
So, let me share a link with all of you, so that you all will be able to do a conda installation.

00:12:30.000 --> 00:12:36.000
So here… Conda?

00:12:36.000 --> 00:12:52.000
So, if you'll go to Google, you will be able to see, uh, Anaconda download, so you will be able to download this Anaconda. And going forward, so we are going to create an environment so many times, so… Just keep it inside your system, I think it will be better, right? It will be better.

00:12:52.000 --> 00:12:59.000
So, you can come over here, uh, you can try to call Condar download, or maybe a mini conda download, that's completely fine.

00:12:59.000 --> 00:13:10.000
And then you can come over here on this particular page, and you can try to say.

00:13:10.000 --> 00:13:21.000
Just a minute, I'm… Sending you a link, so that all of you will be able to download it.

00:13:21.000 --> 00:13:30.000
Yeah, so after doing a sign-up, they are going to give you an option. So, distribution installer, so just go ahead with this. So, for Windows, for a Mac machine, and for a Linux machine.

00:13:30.000 --> 00:13:39.000
So, here is a link, guys. Uh, let me copy and paste this link. Yeah, so now I have sent you a link.

00:13:39.000 --> 00:13:46.000
Sorry, I think it's available. Every one. Okay. So yeah, now a link is available to all of you guys.

00:13:46.000 --> 00:13:55.000
So, I'll talk about it. So, see, we have to create a multiple environment. Now, what is the meaning of an environment, by the way? So, environments is nothing but.

00:13:55.000 --> 00:14:04.000
Kind of, you can say, a directory with a specific installation. So, for example, if I'm trying to do two, three projects, right?

00:14:04.000 --> 00:14:11.000
So maybe I'm trying to do project number 1, maybe I'm going to do a project number 2, and maybe I'm going to do a project number 3.

00:14:11.000 --> 00:14:22.000
And all of these three projects are available in my system, yeah? In my system. Same system, yeah? I just have only one machine, so all of these projects are available in the same system.

00:14:22.000 --> 00:14:41.000
Now, there is a possibility that this project requires Python version 3.10, and its dependencies, right? Because we will end up installing a lot of libraries. Maybe this required 3.11, and this required maybe 3.13, yeah? So all these three projects requires a different, different Python installation.

00:14:41.000 --> 00:14:54.000
Now, keeping that in a mind, so we have to create a different, different environment, and that is practically possible. That is practically possible. So what it will do, what system will do, basically, is that.

00:14:54.000 --> 00:15:04.000
That it will try to create a separate directory. See, whenever you try to say that pip install XYZ, what it does, so it will try to download the entire code.

00:15:04.000 --> 00:15:09.000
And it will always try to keep it inside a particular environment. This is what pip install does. I don't know whether you have.

00:15:09.000 --> 00:15:21.000
Uh, like, uh… gone through it or not, but let's suppose if I'm trying to say that pip install numpy, or pip install Pandas, or pip install matplotlib, or pip install TensorFlow.

00:15:21.000 --> 00:15:28.000
It creates a complete directory about a TensorFlow or NumPy or Pandas, and then it will try to keep all the code which someone else has written.

00:15:28.000 --> 00:15:33.000
Uh, for you. And this is how it will be able to give you a support.

00:15:33.000 --> 00:15:42.000
With respect to a Panda's library, with respect to a NumPy library. So here, uh, when I go, when I'm going to do a multiple different kind of project.

00:15:42.000 --> 00:15:51.000
So, every project will be having its own dependencies, right? And, uh, again, most of the time, you will get stuck with respect to a dependencies conflict, because.

00:15:51.000 --> 00:16:08.000
Some of these versions are going to work with some other version of some other installation, and some may not. And a lot of time, we face this kind of an issue. So, just to keep neat and clean, right? Just to keep neat and clean in terms of doing a development. What we do is that, that.

00:16:08.000 --> 00:16:17.000
We keep on creating a multiple different, different environments. So, if I'm doing project number 1, I'll try to create one environment. If I'm doing a project number 2, I'm going to create another environment.

00:16:17.000 --> 00:16:28.000
If I'm doing a project number 3, I'll end up creating a different environment, and our respective volume installation, our respective version installation, right? So this is what I do.

00:16:28.000 --> 00:16:36.000
So, here, uh, let's suppose we are trying to experiment with a vector database today, right? So, we will try to create one environment.

00:16:36.000 --> 00:16:43.000
Now, tomorrow, so I'll be talking about, let's suppose, a lang chain, maybe day after tomorrow, I'll be talking about a Langgraph Llama indexes.

00:16:43.000 --> 00:16:47.000
So, I'll keep on creating a different, different, different, different, different, different kind of an environment.

00:16:47.000 --> 00:16:54.000
So that I will be able to do an installation of those dependencies with respect to the experiment that we are going to perform.

00:16:54.000 --> 00:17:04.000
So, environment is important, and again, so whatever project that you are going to do in future, even in a company, right? So, you will end up creating a separate environment.

00:17:04.000 --> 00:17:17.000
All along. So, let's get started, guys. Now, to create an environment, you can create an environment by using just a Python code. So, Python m virtual environment, and then environment name. That's a…

00:17:17.000 --> 00:17:32.000
Come on. But most of the time, most of you are going to face an issue while setting up a Python version. Again, it's not an issue, so going forward, you all will be able to understand that you just have to handle a little bit, right? Handle a little bit of things.

00:17:32.000 --> 00:17:37.000
Uh, so you have to, like, mention a Python version, but with respect to a conda.

00:17:37.000 --> 00:17:44.000
A command is, again, much simpler, right, much simpler, easy to maintain, and easy to, you know.

00:17:44.000 --> 00:17:56.000
Create an environment. So that's the reason why I'm asking you to install a condo. Conda is nothing but it's another distribution. So, which is going to help you out in terms of doing all the installation with respect to a Python libraries.

00:17:56.000 --> 00:18:06.000
Uh, there is another distribution you will be able to find out nowadays, called as UV installation, or UV distribution. So, UV is, again, lightning fast, obviously faster than Conda.

00:18:06.000 --> 00:18:17.000
Which I'm going to introduce in a later stage in your class, that how, with the help of UV distribution, you will be able to do a setup, and UV is a very good, uh, dependency resolver. So again.

00:18:17.000 --> 00:18:42.000
Let's try to understand dependencies, and then in a later stage, we'll try to understand the dependency resolver, yeah? But yeah, as of now, just try to install an Acunda, and I think it is going to work for all of us, and you all will be able to create an environment quickly. So, if you are using a Windows, not an issue, click on download. If you are using Mac, click on download, and if you're using a Linux, click on download. It's a very easy kind of.

00:18:42.000 --> 00:18:53.000
Installation, you all will be able to find out. Yes? Fine, guys. So, from a distribution installer, so for Windows, download this. For Mac, download this. For Linux, download this one.

00:18:53.000 --> 00:19:08.000
Right? I believe my cursor is visible to all of you, and I have already sent you a link. Let me send you this link once again. So, after doing a sign-up, just click on this Windows, and then save it somewhere, and then click, click, click, install.

00:19:08.000 --> 00:19:11.000
So once you are able to download it, click, click, click install. Simple.

00:19:11.000 --> 00:19:16.000
Fine, guys!

00:19:16.000 --> 00:19:20.000
How to check if we have a conda installed? Just type conda command.

00:19:20.000 --> 00:19:35.000
It will give you, like, some help, or some hints. So, if it is giving you a hint, it simply means that Conda is installed. If it is not giving you a hint, it simply means that Conda is not installed. Or just check the version, either way it's fine.

00:19:35.000 --> 00:19:50.000
Then you have a conta installed, by the way. Anaconda Navigator is just a UI layer on top of the Anaconda installation, so that, you know, you can go through, uh, different, different tools, which is a pre-built tool coming with your Anaconda.

00:19:50.000 --> 00:19:58.000
But the distribution name is actually Anaconda.

00:19:58.000 --> 00:20:03.000
Yeah. Fine, guys, so there are multiple ways. This is one of the simplest way, uh, which I'm talking about.

00:20:03.000 --> 00:20:12.000
Fine? Yeah? No. So, as we are able to do the… every one of us are able to do the installation, guys?

00:20:12.000 --> 00:20:19.000
Yeah? Everyone? Because in every, uh, like, uh, single day, when we are going to write a code.

00:20:19.000 --> 00:20:24.000
We will end up using it. Fine, guys. Salim Moher.

00:20:24.000 --> 00:20:30.000
Yeah? Okay, so Gopi is saying, uh, okay, wait for a moment, it's still downloading, okay, fine.

00:20:30.000 --> 00:20:40.000
So I'll give you another 2-3 minutes, uh, because I know for, like, some of you, it is going to take some time, maybe… to download and maybe to install, depends upon the system configuration and internet.

00:20:40.000 --> 00:20:47.000
Both. Yeah, so fine. Just wait for, like, a 2-3 minutes, or maybe, like.

00:20:47.000 --> 00:21:17.000
Yeah, 4 minutes, max to max.

00:21:36.000 --> 00:21:42.000
Okay, some people are asking me why I'm downloading it. So, I think I was, like, trying to give.

00:21:42.000 --> 00:21:51.000
The answer was the same since last 10 minutes, why we are downloading it.

00:21:51.000 --> 00:22:07.000
Is it like a Jupyter Nerd book? No, it's the version manager. It's not a Jupyter Notebook. Jupyter Notebook, it is going to provide, it is going to provide even, uh, different, different IDs as well, for example, RStudio, or… Uh, any other IDs for, like, writing a code or cell…

00:22:07.000 --> 00:22:15.000
It is going to provide you, but more or less, it is going to help you in terms of creating an environment.

00:22:15.000 --> 00:22:27.000
It's 900MB, it's taking too much time, then I think your internet speed is, uh…

00:22:27.000 --> 00:22:46.000
Okay, so even if you are not going to create it, it's completely fine, but going forward, you need it. Uh, because you all are going to face a lot of problem with respect to, uh, basically a worsened conflict. So, you will be able to see that, and especially with the TensorFlow, TensorFlow and PyTorch version.

00:22:46.000 --> 00:22:59.000
Which we eventually, we are going to use it a lot, uh, because we are going to deal with the models, right? So, again, all this inferencing, we'll be able to do it with respect to a PyTorch. And again, even in production, you are going to face such kind of issue.

00:22:59.000 --> 00:23:11.000
So it's always better to keep our environment clean, keep a different, different environment for a different, different work.

00:23:11.000 --> 00:23:23.000
Okay, what about poetry, roast cardiji? Tika? Hmm, palider progress karna.

00:23:23.000 --> 00:23:35.000
So even with Python 3 VM, you will be able to do it, but not everyone. Some of you are going to face a problem. That's a region, so on a neutral ground, we are doing this installation. Okay, so I believe this installation is done. Now.

00:23:35.000 --> 00:23:45.000
So, once this installation is done. Uh, let's go to the VS Core, right, and I'm going to show you that how you will be able to create the environment.

00:23:45.000 --> 00:23:50.000
So, for example, I'm going to create the environment, so where I need a Python 3.10 installation.

00:23:50.000 --> 00:24:00.000
Fine, so I would like to create an environment, and for this vector DB, so I would like to create the environment. So here, if conda is installed, I can simply write a command called as conda.

00:24:00.000 --> 00:24:09.000
Create, right, conduct create hyphen n hyphen n means name of the environment. So, for example, for a vector database, I'm creating this environment.

00:24:09.000 --> 00:24:19.000
So, vector, VCTOR dB is an environment name I'm going to give, and then Python, right? So, P-Y-T-H-O-N, Python. What is the Python person? 3.

00:24:19.000 --> 00:24:31.000
One euro, let's suppose, right? So, 3.10. So, conda create hyphen n, and thence is the environment name. Vectordb is the environment name, and then I have given that, okay. So, whenever you're trying to create this environment.

00:24:31.000 --> 00:24:42.000
Try to install Python 3.10. Although, in my system, so, latest version of Python is already available, right? But that's okay. That's okay. It is not going to touch that particular one.

00:24:42.000 --> 00:24:51.000
It is going to create a virtual environment, means it is going to create a separate folder for this particular environment, and keep all of those files inside.

00:24:51.000 --> 00:25:07.000
That particular environment. So, conduct create hyphen n, and here I have just given a vector a dB environment name, and Python 3.10. This is the command. And very simple one. Simple one, neat and clean one. You all will be able to find out. And now, hit Enter.

00:25:07.000 --> 00:25:16.000
Right? So, it will take, uh, maybe, like, a 30 second of time for you, and it is going to prepare this environment. Environment means.

00:25:16.000 --> 00:25:23.000
Eventually, it is going to create a directory for you, as simple as that. It is going to install some of these basic library.

00:25:23.000 --> 00:25:32.000
Which is required, and here is your environment location. So, like I said, it is going to create a directory.

00:25:32.000 --> 00:25:47.000
Right? Now, if I'm going to show you that how many environments do I have? So, let me show you that. So, see, it has created a directory called as vectorDB automatically, and then all of these Python libraries, right, or bundles it is trying to keep it inside this same environment.

00:25:47.000 --> 00:25:53.000
And if I'm going to show you my environment, see how many environments I have. So I have 60 plus environment.

00:25:53.000 --> 00:26:07.000
Yeah, 60, exactly 60 environment I have. Are different, different, like, environment I have created, and, like, 60-plus environment, I'm trying to, like, keep it inside my system. So, obviously, I keep on creating a different, different kind of an environment.

00:26:07.000 --> 00:26:12.000
For a different project, or for my different, different classes. And this is what we are going to do it even, uh, like, uh.

00:26:12.000 --> 00:26:18.000
In your class, right? So, 60 plus environment I have created, and even you will end up creating the same thing.

00:26:18.000 --> 00:26:21.000
It simply means that we are creating a folder, nothing much.

00:26:21.000 --> 00:26:28.000
Yeah? We are creating a folder, and whatever installation that you are going to do, so all of these things will go into a respective library ID.

00:26:28.000 --> 00:26:43.000
As simple as that. Fine? Okay. So, this is the meaning of an environment creation, by the way. So, whether you are going to use a conda, or whether you are going to use a Python, a plain Python, whether you are going to use a UV.

00:26:43.000 --> 00:26:48.000
Eventually, everyone is going to give you a folder, and inside a folder, it is going to.

00:26:48.000 --> 00:26:56.000
Install each and everything for you. Making sense, guys, to all of us, what is the meaning of environment creation?

00:26:56.000 --> 00:27:03.000
And how we are able to create those environments. Yes, yeah? So you can go and you can check in your system.

00:27:03.000 --> 00:27:12.000
So, there will be a folder you will be able to find out. So, for example, I have created, like, so many environments with the help of Conda, right? So, inside Anaconda 3.

00:27:12.000 --> 00:27:24.000
There is a folder called as ENVS, which is, like, environments, and inside that, you will be able to find out your respective environment, or else, even from here, by creating the environment, so it is going to give you the folder location, yeah?

00:27:24.000 --> 00:27:30.000
Okay, so once my environment is created, I have to activate that environment.

00:27:30.000 --> 00:27:36.000
So that, whatever I will be installing it, uh, so that will go to that particular directory, which I have created.

00:27:36.000 --> 00:27:42.000
So here is the command. A command is very simple, conda activate. So, by default, it is giving you the command.

00:27:42.000 --> 00:27:50.000
So, conda, and then activate, and then your environment name. So, whatever environment name that you had given, so you can try to, like, hit over here.

00:27:50.000 --> 00:28:01.000
And then it will end up creating, or it will end up activating that environment. Now, here, it's not visible, this is the PowerShell prompt, right? So, it is trying to, like, show it with, uh, blue color.

00:28:01.000 --> 00:28:07.000
If you will come over here, and if you are going to launch this command prompt, and here, conda activateVectorDV.

00:28:07.000 --> 00:28:11.000
You will be able to even see the name, name of the environment.

00:28:11.000 --> 00:28:22.000
Yeah? So, in PowerShell, it's just representing by this, and in a command prompt, so you will be able to see the environment. So, command prompt shows you environment name as well.

00:28:22.000 --> 00:28:28.000
So, I believe we all are able to see it. Right, guys?

00:28:28.000 --> 00:28:39.000
Why not simply using a pip to create the environment? So, basically, pip has been used to create, or do the installation in a particular environment.

00:28:39.000 --> 00:28:54.000
Yep. Okay, so Conda is not recognized, so I believe you have not installed an ACONDA. That is the reason so it is not able to recognize it. There is no other reason at all.

00:28:54.000 --> 00:29:06.000
Yes? Yeah, like, yes, you can use any of these. So, fine, we are able to activate this, uh, conda, right? So, let's activate this conda. So, this has been activated.

00:29:06.000 --> 00:29:16.000
So, in my terminal, this has been activated. Now, let's suppose if I have to use a SIM environment, right, same environment in my Jupyter notebook. This notebook. So here.

00:29:16.000 --> 00:29:22.000
Solid kernel, then secondary step. By the environment, and then from here.

00:29:22.000 --> 00:29:29.000
So, I can try to… Uh, select VectorDB, so whatever environment that I have created, so I can try to select that one.

00:29:29.000 --> 00:29:43.000
Uh, and I can try to use that particular environment, as simple as that, yeah? So, let's suppose I'm going to select this one, so… My kernel has changed, and now it is going to use our vector dB.

00:29:43.000 --> 00:29:47.000
So VCTOR, I believe I have created two separate environments, VC.

00:29:47.000 --> 00:29:56.000
Bcotor, okay. So, V, C-O-T-O-R is the one which I have to use.

00:29:56.000 --> 00:30:11.000
Fine. So this is how you will be able to attach a particular environment to a particular Jupyter notebook, because at the end of the day, Jupyter Notebook is just a, like a… kind of, you know, UI interface.

00:30:11.000 --> 00:30:23.000
Unless and until you are not going to attach a kernel, it is not going to work, and you can attach any of your environment to a Jupyter notebook. Doesn't matter at all, and then you can keep on installing other things, and then you can keep on.

00:30:23.000 --> 00:30:37.000
Like, uh, running the things inside this one. Okay, so once environment is ready, and even for some of you, environments are not ready, that's completely okay. Try to do the installation, uh, try to do the execution of the code which I'm going to write in the existing environment itself, yeah? So do it in an existing environment.

00:30:37.000 --> 00:30:45.000
If you are not able to do it, yeah? But yeah, it's always better to go ahead with a separate environment to resolve the dependency.

00:30:45.000 --> 00:30:50.000
So, next step that we have to do is that, that we have to do an installation. Installation of what?

00:30:50.000 --> 00:31:03.000
So, we have to do pip install. Hi, it is T-A-L-L pip install, and we have to basically do an installation of our Facebook AI similarity search database.

00:31:03.000 --> 00:31:12.000
So, if AI, SS hyphen CPU, so this is a library name that you have to install.

00:31:12.000 --> 00:31:20.000
So, pip install… Facebook AI, similarity search, CPU, it is asking me to install, uh…

00:31:20.000 --> 00:31:49.000
Ip UNB kernel, so fine, let's do it. So this installation, you have to do it, guys, in whatever environment you are as of now.

00:31:49.000 --> 00:31:55.000
Okay, so looks like it's done in my system, yeah? So, it's done. Is it done, guys? Everyone?

00:31:55.000 --> 00:32:01.000
So if you can say yes or no in a chat.

00:32:01.000 --> 00:32:11.000
Okay, no, no, no, yes, okay, so… Yes and no, fine. Lot of yes, some noes.

00:32:11.000 --> 00:32:19.000
So just Google installation of this one, Facebook AI Similarity Search Database, CPU version. Again, pinging you the code.

00:32:19.000 --> 00:32:32.000
They've been installed Facebook as Similarity Search, hyphen CPU. Uh, once you are able to do this installation in this environment, the environment which I have selected, or whatever by default environment that you have selected, by the way.

00:32:32.000 --> 00:32:44.000
Then, let's try to do a pip install NUMPY numPy. So, NumPy is one of the library, and then you have to install another library called as request, R-E-Q-U.

00:32:44.000 --> 00:32:50.000
Ests. So, NumPy and our request library, you have to install.

00:32:50.000 --> 00:32:55.000
These two libraries are required. So, NumPy, let me remove comma.

00:32:55.000 --> 00:33:04.000
Yeah. So in this way, it will end up installing these two libraries. So I can install multiple, and I can try to install a single, so requirement already satisfied.

00:33:04.000 --> 00:33:19.000
It's already been installed, so that's cool.

00:33:19.000 --> 00:33:31.000
So, in every environment, we have to install dependencies separately, yeah. So you have to install dependencies separately, because every environment, as I have shown you, it's a separate folder. It's a completely separate directory structure.

00:33:31.000 --> 00:33:41.000
So, one environment will not be able to, like, understand anything from the another environment.

00:33:41.000 --> 00:34:00.000
Someone is saying I'm getting a below error papers install syntax error, PIPINSTA double L, F-A-I-S-S hyphen CPU. So, syntax is correct, just try to see, like, uh… whether you are, like, you have selected a correct kernel or not.

00:34:00.000 --> 00:34:06.000
It says you may need to restart. It's just a warning, so you can avoid it.

00:34:06.000 --> 00:34:16.000
Okay, so once it is done, now those who will not be able to do installation, or those who are going to face an issue, not an issue at all, so in your Doubt clean session, anyhow, I'm going to.

00:34:16.000 --> 00:34:21.000
Uh, seat, and I'm going to close it. Uh, so you can, you can just sit tight.

00:34:21.000 --> 00:34:26.000
And, uh, yeah, wait for a doubt clearing, so that I can take access of your screen.

00:34:26.000 --> 00:34:36.000
And I can try to resolve your, uh… concerns. Okay, so Facebook has similarity search is already installed. Now, we need our data.

00:34:36.000 --> 00:34:44.000
Right? Now we need our data. So see, guys, we are going to perform some sort of a embedding operation.

00:34:44.000 --> 00:34:53.000
Embedding operation means, so we are going to take some textual information, and eventually we'll try to convert those textual information into a numerical vector.

00:34:53.000 --> 00:35:07.000
And after doing that, so we are going to store those information into a databases, right? This is something that we are going to learn, this is something that we are going to do, and this is something that we have already discussed in my previous class, which was yesterday.

00:35:07.000 --> 00:35:14.000
So, uh, here, we need a data set, right? We need a data set.

00:35:14.000 --> 00:35:26.000
So, I can get a data from a multiple sources, and again, in a real time, so people are going to give you a data, again, from a multiple, different, different places, right? There is a possibility.

00:35:26.000 --> 00:35:40.000
That people are going to give you a data, maybe into a PDF format. There is a possibility that people are going to give you a data into an Excel sheet, or maybe they are going to give you some URL, and they're going to ask you that, scrap those data.

00:35:40.000 --> 00:35:52.000
Maybe data will be available in some SQL or NoSQL databases. So there is a huge, different kind of possibilities that my data set will be available into a different, different location.

00:35:52.000 --> 00:35:58.000
Now, so as of now, I'm just going to show you about a conversion and storage.

00:35:58.000 --> 00:36:06.000
But in general, and in real time, so we try to build a complete data pipeline.

00:36:06.000 --> 00:36:18.000
So where we try to read our data from a multiple sources. There is a possibility that I'm going to receive a data into a batch mode. There is a possibility that I will receive a data into a streaming mode.

00:36:18.000 --> 00:36:28.000
There is a possibility that I will be receiving a data into a mini-batch mode, right? Means, I'm talking about a frequency of the data.

00:36:28.000 --> 00:36:35.000
There is a possibility, right? So, and again, there is a possibility that data will be coming from a multiple different different sources, maybe from a S3 bucket, maybe from Azure blobs.

00:36:35.000 --> 00:36:54.000
Or maybe from some databases, and there are hundreds of different, different databases which is available, maybe from a different, different, different, different kind of a… file system. So, as of now, I'm going to pick a data from this page. So, on your own page, there is a page called as Founder Story, and it's a small story about me, which has been mentioned over here.

00:36:54.000 --> 00:37:00.000
I'm going to come over here, and I'm going to copy this data, yeah? I'm just going to copy this data.

00:37:00.000 --> 00:37:16.000
So I'm looking for some structured, unstructured data. That's the reason, so I'm just going to, like, come over here, I'm going to copy this particular data. And let's try to keep this data. So, let's suppose there is a variable I have created, and here, so I'm going to keep this particular data.

00:37:16.000 --> 00:37:26.000
In this manner, yeah? So I've just, like, copied, and I have just pasted this particular data over here. As simple as that. From the founder Story pages.

00:37:26.000 --> 00:37:36.000
Like I said, so this is the data which I'm just trying to do a copy and paste from some of the website, right? But there is a possibility that you will receive a data into a PDF format.

00:37:36.000 --> 00:37:41.000
Then you have to write a Python function to read out those data from a PDF.

00:37:41.000 --> 00:37:50.000
File. Maybe someone is going to give you data into a Word format, Excel sheet format, maybe into a .txt format, maybe into a JSON format.

00:37:50.000 --> 00:37:58.000
So, there can be a thousands of a different, different sources of the data that you all will be able to find out in real time.

00:37:58.000 --> 00:38:07.000
Right? In real time, basically. So, here is, uh, one of the sample of the data. So, let me ping this data to all of you.

00:38:07.000 --> 00:38:13.000
So I think…

00:38:13.000 --> 00:38:20.000
Ctrl-a, CTRL-C. Ctrl-v. I believe I'm not able to ping this is…

00:38:20.000 --> 00:38:28.000
Uh, huge data. So, maybe I can just try to ping, uh…

00:38:28.000 --> 00:38:36.000
Subset of it, yeah. So, this is the dataset, uh, which is available, right? This is the dataset which is available to me.

00:38:36.000 --> 00:38:44.000
Now, so as we know that, that this data set is having so many different, different, like, lines, or maybe, uh, paragraphs, right?

00:38:44.000 --> 00:38:51.000
Paragraphs. So, what should be my very first approach? My very first approach should be to.

00:38:51.000 --> 00:39:00.000
Breakdown, right? To break down this entire data set into a small, small chunks. For example, if we are reading a PDF.

00:39:00.000 --> 00:39:05.000
Right? And someone has given me a PDF with hundreds of pages, right? Hundreds of pages.

00:39:05.000 --> 00:39:19.000
So, it's not like I'll just try to take one single, like, uh… one single variable, and inside that, I'll try to keep all those hundreds of pages, and then I'll try to convert those hundreds of pages all together in one single vector.

00:39:19.000 --> 00:39:29.000
Because that is not going to work for me, right? Because the whole idea behind doing an embedding to improvise our search, improvise our indexing, right? So that is not going to help me out.

00:39:29.000 --> 00:39:43.000
So what I am supposed to do next, if I have this kind of a dataset, right? If I have this kind of a dataset. So, basically, I'll try to break this data into a small, small, small, small chunks, right? Chunks of size, maybe, uh, 500.

00:39:43.000 --> 00:39:55.000
A text may be a thousand texts, or maybe a thousandth character, maybe a thousandth word, depends, right? But yeah, so I'm going to break down this entire dataset into a smaller, small, small, small chunks.

00:39:55.000 --> 00:40:02.000
By keeping some sort of an overlap between our chunks. Overlap, and why we are going to maintain that?

00:40:02.000 --> 00:40:09.000
Let me talk about that one. After breaking down this entire dataset into a smaller, smaller, small, small chunks.

00:40:09.000 --> 00:40:21.000
Yeah? So, salary, go ahead, guys. Shall we do it? No?

00:40:21.000 --> 00:40:27.000
Okay, so let's do it, guys. Yeah, so we are going to take this data.

00:40:27.000 --> 00:40:36.000
Now, here, so we are going to call data.strip strip, so it is going to eliminate all those leading and trailing.

00:40:36.000 --> 00:40:42.000
Uh, spaces in between our data, and I'm going to name it as a clean data. Clean underscore data.

00:40:42.000 --> 00:40:46.000
Now, this is just a symbolic one, which I have created.

00:40:46.000 --> 00:41:01.000
There are so many different, different kind of a cleaning we try to perform. So, we try to perform a normalization operation, uh, we try to just remove the punctuations or any kind of unnecessary… most of the time, repetitive words.

00:41:01.000 --> 00:41:05.000
So, so many different, different kind of NLP-based cleaning we try to perform on top of the data.

00:41:05.000 --> 00:41:10.000
Now, but again, that depends upon the kind of a problem statement which I am going to solve.

00:41:10.000 --> 00:41:15.000
So, that depends more, like, on a business domain, or, like, the problem statement that we are going to solve.

00:41:15.000 --> 00:41:27.000
So, as of now, uh, just in a symbolic manner, so I have called data a strip, so which is going to remove leading and trailing spaces from the dataset. I'm calling that dataset as a clean data, let's suppose, yeah?

00:41:27.000 --> 00:41:32.000
But on top of this, we do, again, a lot of processing.

00:41:32.000 --> 00:41:43.000
With respect to our data. Believe me, let's suppose if I'm trying to read a PDF, right? There will be so many different, different kind of edge case I will end up getting, and I have to handle all the edge cases, I have to handle all kind of edge cases.

00:41:43.000 --> 00:41:47.000
Then only I will be able to get the required data set.

00:41:47.000 --> 00:41:57.000
But here, this dataset is not that complex. There is a possibility, right? There is a possibility that I will be having some of the word.

00:41:57.000 --> 00:42:03.000
Right? Some of the word, or maybe some of the lines inside my dataset, into a different language.

00:42:03.000 --> 00:42:09.000
Maybe into a Spanish, maybe into a French, right? Maybe into a Hindi language.

00:42:09.000 --> 00:42:14.000
There is a very high chance, right? So, when I'm trying to read some sort of a book, or maybe a PDF, or some sort of a raw data.

00:42:14.000 --> 00:42:27.000
There is a chance that I will end up getting a mixture of a language, which we say a multi-language, right? So, there is a very high possibility. I have to handle all of those situations.

00:42:27.000 --> 00:42:39.000
With respect to a dataset, then only I can try to make my dataset ideal for any kind of operation, whether it's an embedding or maybe whether it's a RAG, or any other agentic operation.

00:42:39.000 --> 00:42:49.000
So, lot goes around, by the way, in terms of, like, you know, building a complete data pipeline. And again, that's a major roles and responsibility we all.

00:42:49.000 --> 00:43:08.000
Uh, try to do. Inside the organization. So here, I'm able to read a data, right? And in a symbolic manner, so I'm able to call data or a strip. Now, my requirement is to break down this dataset into a small, small chunks. Small chunks means.

00:43:08.000 --> 00:43:15.000
For example, in one single line, right, in one single line, I would like to keep maybe 800 characters.

00:43:15.000 --> 00:43:24.000
Yeah? So that is one chunk. Another 800, another chunk. Another 800, another chunk, another 800, another chunk.

00:43:24.000 --> 00:43:29.000
There could be 500, there could be 700, depends, right? So, I can try to create a chunks.

00:43:29.000 --> 00:43:40.000
And with certain chunk size. So, in one single sentence, or in one single data, I will be having only that much number of the characters, or maybe I can try to define it based on the words, whatever suits me.

00:43:40.000 --> 00:43:47.000
So here, uh, let me write the code over here. So, I can write over here that while.

00:43:47.000 --> 00:43:57.000
Right? So, while, and uh… here… I can try to define some of the variables. So, let me define some of the variable for this operation.

00:43:57.000 --> 00:44:11.000
So here, max… character, C-H-A-R, is equals to, let's suppose I'm going to define 800, yeah? 800. So, in one single line, there will be 800 character, max to max, not more than that.

00:44:11.000 --> 00:44:16.000
And then I'm going to define overlap. So, overlap is equals to 100.

00:44:16.000 --> 00:44:20.000
So, means, let's suppose I have line number 1, I have line number 2.

00:44:20.000 --> 00:44:28.000
There is an overlap of 100 characters between line number 1 and line number 2. Why I'm trying to, like, keep the overlap over here?

00:44:28.000 --> 00:44:33.000
Because when I'm going to do a checking operation, when I'm going to break down this data into a chunks.

00:44:33.000 --> 00:44:42.000
So, I have to maintain even a relation. Means context, right? So, if there will be an overlap between our data.

00:44:42.000 --> 00:44:50.000
So, obviously, it will be able to see the context, it will be able to correlate, and when I'm going to do a search operation on top of the embeddings.

00:44:50.000 --> 00:44:58.000
It will be able to give me, like, okay, so there is some match with line number 1, and there is some match with line number 2 as well.

00:44:58.000 --> 00:45:03.000
Right? So, just to maintain that context, I'm going to maintain the overlapping, yeah? Overlapping between.

00:45:03.000 --> 00:45:09.000
Two data sets. So that's the reason, so I have given, like, overlap with hundreds of, like, a character.

00:45:09.000 --> 00:45:18.000
Right? Runners of character, and then let's create a CHU. Chunks as a list.

00:45:18.000 --> 00:45:26.000
And then I'm going to keep, let's suppose, i variable is equal to 0. So, start from 0. 0 to index. Start from where? Start from here.

00:45:26.000 --> 00:45:38.000
From a growth indexes. Fine? So, I'm going to write a code. While I is lesser than, right, length of a… Clean?

00:45:38.000 --> 00:45:43.000
Clean data, yeah? So, start from zero.

00:45:43.000 --> 00:45:50.000
And then go till what? So try to go till the last one. That's the reason, so length of clean data. Length of clean data, let's suppose I have 500.

00:45:50.000 --> 00:45:58.000
So, it will go till last, right? It will go till last, then only it is going to break the loop. This is what I have written. So when this statement is true.

00:45:58.000 --> 00:46:07.000
Right, when this statement is true. Then, it has to perform a different, different, different, different operation, yeah? Different, different, different, different operation. So, what kind of operation it has to perform?

00:46:07.000 --> 00:46:15.000
So, it has to break down my entire dataset into a small, small pieces. Fine? Smaller, small pieces.

00:46:15.000 --> 00:46:17.000
So, let's suppose here I'm going to call my clean data.

00:46:17.000 --> 00:46:27.000
Uh, C-L-E-N, clean. So, clean data is my, uh, folder, uh, variable name.

00:46:27.000 --> 00:46:31.000
Yeah. So I'm just trying to call my clean data, this particular data set.

00:46:31.000 --> 00:46:34.000
Fine, this particular dataset, I'm trying to call it over here.

00:46:34.000 --> 00:46:40.000
And, uh, then I am going to write. So, this strip, right? Let me show you this data now.

00:46:40.000 --> 00:46:45.000
So how many does it looks like?

00:46:45.000 --> 00:46:50.000
So this is how my dataset looks like, right? This is how my dataset looks like, the whole dataset, yeah?

00:46:50.000 --> 00:47:00.000
Simple, insider string. So, here. Clean data, and inside this, I'm going to write indexes that start from here.

00:47:00.000 --> 00:47:05.000
And then, go till this particular point. So, I'm saying that they start from i.

00:47:05.000 --> 00:47:12.000
Right? Start from I, so I'm just trying to perform the slicing operation. I believe we all understand what is the meaning of slicing operation.

00:47:12.000 --> 00:47:14.000
So I'm saying that to start from i, you mean start from 0th indexes.

00:47:14.000 --> 00:47:20.000
And then go till. Go till where? So, go till I plus a maximum character.

00:47:20.000 --> 00:47:27.000
Go till I plus, means 0 plus 800. This is what I'm trying to say as of now.

00:47:27.000 --> 00:47:34.000
Fine? And this is going to be one data. So, I'm going to store it inside a variable, PIE.

00:47:34.000 --> 00:47:46.000
B-i-e-c-e, let's suppose. So, this is a piece. Which I'm going to a store. So, this will be having, in our very first iteration, in a very first iteration, this will be having a data i is equal to 0 till.

00:47:46.000 --> 00:47:54.000
800. This is the maximum character which I have given. So, till 800, okay? So, this is line number 1, which I'm going to maintain.

00:47:54.000 --> 00:48:03.000
Right? Line number 1, which I'm going to maintain. And then, what I'm going to do, so I'm going to append, so chunk, CH.

00:48:03.000 --> 00:48:10.000
U and K, chunk.append, append what's append piece. So, this is a list which I had created.

00:48:10.000 --> 00:48:15.000
Right? So I'm going to append this particular piece inside this particular list.

00:48:15.000 --> 00:48:20.000
Simple, as simple as that. Okay, so once this is done.

00:48:20.000 --> 00:48:29.000
Right? So, once this is, like, done, then what we are going to do. So, we are going to increment a value of i.

00:48:29.000 --> 00:48:34.000
So, we have to, like, sift a value of i now. So here.

00:48:34.000 --> 00:48:38.000
I is equals to. I plus…

00:48:38.000 --> 00:48:45.000
Maximum character. Minus overlap. So now I'm going to reset a value of i.

00:48:45.000 --> 00:48:51.000
And where my eye will be, by the way. So, I have started from 0.

00:48:51.000 --> 00:48:57.000
It went till age 100, right? It went till 800, now my eye is here, at 800th location.

00:48:57.000 --> 00:49:03.000
But I have to set this value of i at 700 location.

00:49:03.000 --> 00:49:18.000
Let's suppose. Why? So that I will be able to maintain a overlap of 100 in between, between our first sentence and between the second sentence. That's the reason I have written I is equal to I plus max care, means 800 minus.

00:49:18.000 --> 00:49:23.000
100, which is 700, overlap. So now my eye is here.

00:49:23.000 --> 00:49:40.000
Eyes here. So, next time when I is going to start, so I is going to start from where? So I is going to start from 700, by the way, and then 700 plus 800, so technically it is going to be 1500. So, it will go till 1500. And again, I'm going to reset the value of i at 1400.

00:49:40.000 --> 00:49:48.000
Simple, right? And then again, from here, I'm going to start, so that I will be able to maintain the overlap of 100, 100, 100 in between.

00:49:48.000 --> 00:49:58.000
Making sense, guys, to all of us? How we are measuring the overlap? I'm not doing much over here, so I'm just trying to play with the value of i, and with the help of i, those indexes.

00:49:58.000 --> 00:50:05.000
I'm able to maintain the overlap. That's it. Anyone who is not able to understand, by the way.

00:50:05.000 --> 00:50:14.000
This part?

00:50:14.000 --> 00:50:23.000
Yeah. Why do we need to maintain the overlap? So we do… we need to maintain the overlap so that we will be able to maintain a context, a little bit of context, we can try to.

00:50:23.000 --> 00:50:35.000
Like I maintain in both the sentences. How to decide the overlaps? So these are just a hyperparameter, so we do hit and trial, a lot of hit and trial, based on the dataset, and then we try to maintain the overlaps.

00:50:35.000 --> 00:50:51.000
Yeah? Fine, everyone? Okay. So, here, and what is the total length of the data, by the way? So, here, length of the total string, if we have to find out. So, maybe we can try to call just a len function, and you will get to know that what is the length.

00:50:51.000 --> 00:51:00.000
So, total, we have 1498 data, right? 1498, like a… this is the total, like, space which my dataset has occupied.

00:51:00.000 --> 00:51:07.000
So far, so forth. So, max to max, I will end up creating two chunks. Inside one, insider chunks, if I'm going to check.

00:51:07.000 --> 00:51:11.000
I will be having max to max, like, a two sentences, I believe.

00:51:11.000 --> 00:51:17.000
Yep, or three, yeah. So, or three. So here, if I'm going to check what is the length of chunks.

00:51:17.000 --> 00:51:23.000
So, length of chunks, so it's 3, basically. So, max to max 3 sentences, I'm able to form.

00:51:23.000 --> 00:51:33.000
Not more than that, yeah? I can, I can try to, like, uh, play with this one, so I can try to maintain maximum character is equal to, let's suppose, 300.

00:51:33.000 --> 00:51:38.000
Let's suppose I'm going to maintain this as a… Uh, 300 over here.

00:51:38.000 --> 00:51:44.000
And, uh… Here, so let's suppose I'm going to maintain 100.

00:51:44.000 --> 00:51:55.000
Now, there are 8 datasets which I'm able to create. So there is 8 lines which I'm able to create out of my dataset. And all of these lines are available inside a particular list.

00:51:55.000 --> 00:52:04.000
Simple. So now, this is the dataset, which I'm able to create. You must be able to see that we have some sort of a slash in slash in in between a data.

00:52:04.000 --> 00:52:14.000
So, obviously, as a part of your data cleaning operation, you have to clean all of these things, because this is not going to give me any kind of a value.

00:52:14.000 --> 00:52:24.000
With respect to our data, right? So, you may go ahead and perform maybe some sort of a cleaning operation. Maybe there will be some sort of a numerical values, which is not of your use.

00:52:24.000 --> 00:52:31.000
So, you can try to clean those data. Maybe dataset is available in some different languages. So, maybe you can go ahead again with the cleaning operation.

00:52:31.000 --> 00:52:45.000
So, there are a lot of, like, a data preprocessing operation. We try to perform, and which is true across all the applications, not just with this application, so whether you are trying to build a simple machine learning model or deep learning model.

00:52:45.000 --> 00:52:51.000
Or maybe you are, like, dealing with some sort of a data analytics, everywhere you will have to go through these kind of processes.

00:52:51.000 --> 00:52:57.000
Fine, guys? Yep. Okay, so let me ping you this code.

00:52:57.000 --> 00:53:03.000
Again, this code is a very simple one, but yeah, those who are not able to do it.

00:53:03.000 --> 00:53:09.000
I have pinged you this code inside your chat, so you can try to use this particular code.

00:53:09.000 --> 00:53:12.000
Fine. Before that, so I have, like, uh, created this clean data.

00:53:12.000 --> 00:53:23.000
Variable. In this dataset, there are overlap also. Yes, obviously, there is an overlap. You can cross-check manually if you want.

00:53:23.000 --> 00:53:33.000
So, maybe you can try to go at the end of this data. So, a skill they need to succeed in today. So, TODA. This is the only thing that it is able to capture.

00:53:33.000 --> 00:53:43.000
So, here, you will be able to find out. So, the skill they need to succeed in today. So, there is a hundred of overlap, right? 1.5 minutes went from 34 countries.

00:53:43.000 --> 00:53:50.000
You will be able to find out the same. So yeah, one more timely instrument from 34 countries. In a line number 1 as well. So, there is overlap.

00:53:50.000 --> 00:53:57.000
Right? There is overlap, I'm, like, trying to maintain between. Two sentences, so that it will be able to.

00:53:57.000 --> 00:54:02.000
Maintain a contextual information. It will be able to understand something like, uh.

00:54:02.000 --> 00:54:08.000
These two lines are connected to each other. Fine? Okay. So…

00:54:08.000 --> 00:54:14.000
No. Now, once we are able to create our chunks, and.

00:54:14.000 --> 00:54:18.000
We all understand that how we can try to create these chunks, a simple Python function, right? There are.

00:54:18.000 --> 00:54:27.000
Um, some inability libraries, which is available to all of us, so you can even try to use that one, but more or less.

00:54:27.000 --> 00:54:31.000
This is something that people are doing, even inside those libraries.

00:54:31.000 --> 00:54:37.000
So, okay, we are able to create this one. Now, what is our next step?

00:54:37.000 --> 00:54:42.000
So, our next step is to convert this entire dataset into embeddings.

00:54:42.000 --> 00:55:02.000
Fine? Into a numerical format, so we'll have to convert this data. Uh, which we have already done yesterday, right? So, we can try to use a URI API, we can try to use some models from Hugging Face, or maybe any other open source model, which is going to support our embedding, and I will be able to convert my dataset into a.

00:55:02.000 --> 00:55:15.000
Vector, right? So, into a vector. Okay, that's cool. So, let's go ahead, guys, and uh… let's try to convert this entire dataset.

00:55:15.000 --> 00:55:19.000
Into an embedding, into a vector space, which is again very, very simple.

00:55:19.000 --> 00:55:27.000
So, what I will do, I'll just go to Euron. And, uh, I'll go to Yuri API.

00:55:27.000 --> 00:55:32.000
Here, I'll go to a code example. And I'll try to copy this code.

00:55:32.000 --> 00:55:38.000
Simple. So, copy this code for a embedding and similarity, right? So, this is the code which has been given to me.

00:55:38.000 --> 00:55:48.000
Technically, we all understand this code, so in an API classes itself, we were able to understand that what is the meaning of a URL endpoint, and all the things which has been written over here.

00:55:48.000 --> 00:55:52.000
And today, we have already used it. So just try to copy this one, right? Copy this one.

00:55:52.000 --> 00:56:04.000
And maybe keep it here, yeah? Now, it requires an API key. Without API key, we can't use this piece of the code. So here, what we can do is that, that we can try to click on API keys.

00:56:04.000 --> 00:56:09.000
Fine? Uh, create an API key, and then let's try to create the API key.

00:56:09.000 --> 00:56:13.000
So this is my API key, which I am able to create.

00:56:13.000 --> 00:56:23.000
And, uh, just paste it over here. Paste it over here.

00:56:23.000 --> 00:56:33.000
Yeah. So, my API key is done, and this is the function which is going to take a data, which is eventually going to take a text.

00:56:33.000 --> 00:56:44.000
And, uh, it is going to give you the embedding. Fine, it is going to take a data, and it is going to give you the embedding. This is a very, very simple function that is already available.

00:56:44.000 --> 00:56:54.000
And no need to do anything. Literally no need to do anything. So, we can try to hit this particular, like, a function. So, here, execute this function, and we have this data, chunks we have.

00:56:54.000 --> 00:57:00.000
Now, from this chunk, I have to convert this entire data into an embedding by using.

00:57:00.000 --> 00:57:22.000
This Yuri API, yeah, by using this URI API. So, how we can do it? Let's… Understand? I think it's a very easy kind of a job, right? So, without any, like, a second thought, I believe we all will be able to do it. Right, guys?

00:57:22.000 --> 00:57:33.000
Yep. Can you copy and paste above code? Yeah, above code, I have copy and pasted, and this code is already available here. So, go to Euron, go to a Yuri.

00:57:33.000 --> 00:57:42.000
Api, and code example, you will be able to find out embedding. So that copy button we have given to you, so you can copy and paste directly. As simple as that.

00:57:42.000 --> 00:57:52.000
Okay, fine. So once we are able to, uh, call this generate embedding, and we have already used this function even yesterday, right? So even yesterday, so now we all know that.

00:57:52.000 --> 00:58:03.000
How it does. Now, here inside this one, so we are using our OpenAI-based model. So, again, this is a multilingual model that we are using. It supports hundreds of languages by default.

00:58:03.000 --> 00:58:13.000
Right? It already supports hundreds of languages, because while people was training this particular model, so obviously they have used a multilingual data set.

00:58:13.000 --> 00:58:23.000
But, uh, and again, one of the lightweighted, one of the fastest embedding models, and one of the low-cost embedding model you will be able to find out in a market.

00:58:23.000 --> 00:58:32.000
There are, I mean, hundreds of other embedding models which is available, right? Yesterday, I have used some model from a Hugging Face, a Quen model I have used from Hugging Face.

00:58:32.000 --> 00:58:41.000
So, you can even go ahead with that. Uh, that's completely fine. Now, this model is going to give you a vector size return of 1536.

00:58:41.000 --> 00:58:50.000
Right? 1,536 is the dimension of the one single vector it is going to return. And I believe we are aware about even that.

00:58:50.000 --> 00:58:57.000
Yes, everyone? We are aware about it, right? I think we have done that yesterday.

00:58:57.000 --> 00:59:13.000
Right? Okay, let's move forward. So, we have a chunk, we have a data. So, I don't think that we have to do much over here, so I will just run my, like, uh, you know, generate embedding through this chunks, one by one, one by one, one by one.

00:59:13.000 --> 00:59:18.000
And, uh, eventually, I will be able to get my final embedding.

00:59:18.000 --> 00:59:28.000
Yes? Yeah?

00:59:28.000 --> 00:59:36.000
Okay, so let's do it. So here, I'm going to write a code that for I in CH…

00:59:36.000 --> 00:59:43.000
U and K, so one by one, let's do the checking, and call this generate embedding function.

00:59:43.000 --> 00:59:54.000
Pass the value of i one by one, one by one, and then try to print the embedding. Or if I would like to, like, keep all of those embeddings, so I'll try to keep those embeddings somewhere.

00:59:54.000 --> 01:00:09.000
So, as you can see, it is, like, creating an embedding for sentence number 1, sentence number 2, sentence number 3, sentence number 4, 5, 6, 7, 8. So, I have, in total, 8 sentences. And for all of those sentences, it is able to create the embedding.

01:00:09.000 --> 01:00:25.000
So it is able to create the numerics, right? Done, everyone?

01:00:25.000 --> 01:00:33.000
Okay, most of you have done. Okay, that's cool. There's nothing, I'm just running through the chunks, and then eventually I'm trying to, like, uh, you know.

01:00:33.000 --> 01:00:50.000
Do the embeddings?

01:00:50.000 --> 01:01:00.000
Now, those who are not able to follow along so far, let me, uh, give you a copy and paste of this code, one by one, once again.

01:01:00.000 --> 01:01:09.000
So, first, install this. Then, install this.

01:01:09.000 --> 01:01:16.000
Then you have to take this data. So, you can take up bigger data, because I'm not able to copy and paste my whole data.

01:01:16.000 --> 01:01:25.000
Inside your Zoom, uh, because Zoom is having some limitation with respect to sending our data.

01:01:25.000 --> 01:01:36.000
Then you have to do this.

01:01:36.000 --> 01:01:43.000
Then this…

01:01:43.000 --> 01:01:56.000
Then you have to do this one. I'm removing my API key, so you can replace… it with your own API key.

01:01:56.000 --> 01:02:08.000
This one. And then, finally, this one.

01:02:08.000 --> 01:02:37.000
Okay, so till this point, is it done, guys? Yeah, shall they move ahead?

01:02:37.000 --> 01:02:53.000
Embedding means that data, they will give us a binary formula, is that correct? Uh, no, it's not correct. I think you should, uh, attend, uh, today's lecture, so please try to revisit yesterday's lecture.

01:02:53.000 --> 01:03:23.000
Okay.

01:03:42.000 --> 01:03:54.000
Hmm. Now, so, once we are able to generate this chunk, so we can now happily store this data into any of these databases. So, whether it's a quadrant, whether it's a pinecone, whether it's a.

01:03:54.000 --> 01:04:05.000
Chromadb, whether it's a Facebook AI similarity search, or any other databases which exist in my local, or maybe which is available in some other platform, right?

01:04:05.000 --> 01:04:11.000
Depends. So, I will be able to, like, store all of this dataset in anywhere.

01:04:11.000 --> 01:04:15.000
Anywhere that I want. So, fine.

01:04:15.000 --> 01:04:23.000
Guys, let's start doing it, yeah, one by one.

01:04:23.000 --> 01:04:29.000
So here, I'm just trying to generate the embeddings, and I'm just trying to, like, show you the print.

01:04:29.000 --> 01:04:41.000
So, in an ideal way, so I have to basically, uh, create a complete embedding list, and I have to create a meta-information, and then I have to go ahead and I have to store those data.

01:04:41.000 --> 01:04:48.000
So, let's re-modify this, uh, just modify this particular piece of the code. So, here.

01:04:48.000 --> 01:04:56.000
Let's write this code in this way. So. Idx and… CSUNK chunks.

01:04:56.000 --> 01:05:17.000
In… enumerated chunks. So, this is just the extension of the previous code I am writing. So, here I have written just chunks, and then I was, like, going through one by one, one by one, all of this data. So, here, what I'm trying to do, so I'm trying to, like, do the enumeration. So, what enumeration does, by the way? So, if we are trying to pass a list.

01:05:17.000 --> 01:05:25.000
So, enumeration will try to give a ID. I believe we all understand our meaning of enumeration inside a Python.

01:05:25.000 --> 01:05:32.000
Anyone, guys, who don't understand the meaning of enumeration inside the Python?

01:05:32.000 --> 01:05:38.000
Yeah, so let's suppose we have a list. Inside this list, we have SUDH.

01:05:38.000 --> 01:05:41.000
Sudh, or, like, something like this, like, this kind of a data we have.

01:05:41.000 --> 01:05:48.000
Now, if I'm trying to write for… I in, uh, enumeration.

01:05:48.000 --> 01:05:54.000
Enumination, and okay, unnecessary, it is time to produce. So, enumerate.

01:05:54.000 --> 01:06:05.000
And then print i. Print I…

01:06:05.000 --> 01:06:16.000
So what it does, so whatever data that we have inside the list, right, we have this, this, and this. So, basically, it will try to take this data, and it is going to return indexes as well. So this is what enumerator does.

01:06:16.000 --> 01:06:20.000
So, let's suppose we have a list of the data inside a chunks.

01:06:20.000 --> 01:06:28.000
So, for every list, it is going to return the IDs, as well as it is going to return the chunks. I'm just trying to build my meta information of the data.

01:06:28.000 --> 01:06:31.000
So that's the region. So, in that way, I'm trying to write.

01:06:31.000 --> 01:06:42.000
So here, it is going to return ID, and it is going to return chunks. This is the property of a enumerate, which I have already shown you, right? In this fashion, it is going to return the dataset, a basic Python command.

01:06:42.000 --> 01:06:49.000
Okay, so here… Well, unnecessary, it has generated a code once again.

01:06:49.000 --> 01:07:00.000
Finally. So here, what I will do is that, that I'm going to call a generate embedding function, and here I'm going to pass my chunk, means I'm going to pass my original data, this one.

01:07:00.000 --> 01:07:08.000
One by one. And let's suppose this is going to return me the vector. Vector means a numerical value, this one. It is going to return.

01:07:08.000 --> 01:07:17.000
And, uh, the second one, so here. Let's try to create one list, e-embedding.

01:07:17.000 --> 01:07:27.000
Underscore LIST, embedding list. So, a blank list I have created, and then let's try to create another list called as Meta.

01:07:27.000 --> 01:07:39.000
Again, keep it blank. So, there are two blank lists I have created. One is an embedding list, so where I'm going to keep all of these embeddings, which I'm trying to produce, and then one is a meta list, so where I'm going to keep.

01:07:39.000 --> 01:07:48.000
Maybe, uh, IDs, maybe, uh, textual data itself, start indexes, end indexes, all of such, like, information. Maybe I can try to store it over there.

01:07:48.000 --> 01:07:54.000
So here, we have our vector, right? We have a vector. So, here I am going to call.

01:07:54.000 --> 01:08:01.000
Embedding list, embedding list.append. And, uh, append what?

01:08:01.000 --> 01:08:17.000
So, append basically a vector. So, simple, whatever it is trying to generate, so just try to append it. But before appending it, so let's try to convert it into a proper type. So, as type, and then I'm going to write that, okay, so whenever you are trying to append it.

01:08:17.000 --> 01:08:25.000
Keep it inside a float 32-bit format. Numpycompatible, and along with, uh, Facebook AI.

01:08:25.000 --> 01:08:31.000
Similarly, search compatible. So, whenever you're trying to store it, just try to store it as a vector, 32 bits.

01:08:31.000 --> 01:08:39.000
Okay, that's cool. So this is going to basically keep on appending our data into this particular list. Each and every data, it is going to append.

01:08:39.000 --> 01:08:45.000
Now, we have to create our meta-information. So, I'm going to call meta.append, meta.

01:08:45.000 --> 01:08:50.000
Append. And, uh, here. So, I can try to append a ID.

01:08:50.000 --> 01:09:00.000
And I can try to append R. Text original data that we have. So this I'm trying to treat as a…

01:09:00.000 --> 01:09:05.000
Text data. So this is going to be the meta information. Now, execute it.

01:09:05.000 --> 01:09:09.000
Once you are going to execute it, it is going to create a vector.

01:09:09.000 --> 01:09:16.000
And it is going to create a… meta-information. And all of this information will be available inside the embedding list.

01:09:16.000 --> 01:09:23.000
And it will be available inside the meta. So now, if I'll go and check my embedding list.

01:09:23.000 --> 01:09:31.000
I have all the data, right, available in 432-bit format. And now, if I'm going to check my meta.

01:09:31.000 --> 01:09:38.000
So for all of these data, right, for all of these data, so we have ID0, data 0, and this was the text.

01:09:38.000 --> 01:09:51.000
Right? So, ID 1, this was the text. Id 2, this was a text. So, I'm just trying to maintain a proper metadata information about my dataset. So, this was our actual data, and uh… This is basically our respective.

01:09:51.000 --> 01:09:56.000
Conversion of those data. So, let me ping you this particular code, guys, to all of you.

01:09:56.000 --> 01:10:03.000
So this is going to my final data set, by the way.

01:10:03.000 --> 01:10:17.000
Making sense, guys? This is nothing new, so we have already, like, created that even before.

01:10:17.000 --> 01:10:23.000
Yeah? So I've already pinned you the code. Try to implement the same.

01:10:23.000 --> 01:10:29.000
So now we have a meta-information, and now we have a data which is available into a vector format.

01:10:29.000 --> 01:10:36.000
Fine, which is available into a vector format. Uh, now what we have to perform.

01:10:36.000 --> 01:10:50.000
So, here… We have this, uh, dataset, and if I'm going to check what is a type of.

01:10:50.000 --> 01:10:59.000
Type of this data. So, this dataset is available into a list format, because I have created a simple, plain list, and inside that list, I was trying to keep all of these data.

01:10:59.000 --> 01:11:08.000
So, let's try to convert this dataset into a NumPy vector format. So, to do that, I can try to call numpy.

01:11:08.000 --> 01:11:16.000
Dot VSTSEK, V is stack. And, uh, here, so I'm going to pass it.

01:11:16.000 --> 01:11:24.000
This entire list. So, as you can see now, that this entire list has been converted into a 2D vector.

01:11:24.000 --> 01:11:35.000
Right? 2d vector. So, just data insider data. So, even before that, so we had a list inside, we had an array. So, I'm just trying to convert that data into a NumPy-compatible format.

01:11:35.000 --> 01:11:46.000
So, we have now data of SAP 8. Into 8 rows 1536 columns. The length of the data is 1536, so that it is just trying to show you.

01:11:46.000 --> 01:11:50.000
So, let's try to store it into a variable called as XB.

01:11:50.000 --> 01:11:56.000
For now, let me bring you this code. Yeah? So now we are able to convert it.

01:11:56.000 --> 01:12:04.000
Now, we can try to send this data into a. Facebook AI Similarity Search.

01:12:04.000 --> 01:12:11.000
To do that, uh, we have to even call a normalization. So.

01:12:11.000 --> 01:12:19.000
Let's call the normalization. So, FAI. I think I have not done the import of, uh…

01:12:19.000 --> 01:12:28.000
Facebook AI Similarity Search. So, let's try to do an import of… import Facebook A similarity search. Just import it, guys, everyone.

01:12:28.000 --> 01:12:39.000
And once we are going to import it.

01:12:39.000 --> 01:12:46.000
Facebook AI Similarity Search dot… I can try to call normalize L2.

01:12:46.000 --> 01:12:52.000
And I can try to pass my data set. So, it will be able to normalize it.

01:12:52.000 --> 01:13:03.000
Name XB. Xb I have defined, right? Yeah.

01:13:03.000 --> 01:13:08.000
So, name XBEAM. Now, here, so we are just trying to perform the normalization operation.

01:13:08.000 --> 01:13:14.000
And uh… XB.

01:13:14.000 --> 01:13:23.000
Sip… OP1 is 1536. Now, that is going to be the dimension of my vector database.

01:13:23.000 --> 01:13:32.000
So I'm keeping it as D. I can even hardcode it, that's completely fine, but uh… Here.

01:13:32.000 --> 01:13:40.000
I'm just trying to find out the dimension from the dataset itself, yeah? So, for one dataset, dimension is basically 1536, and I need this dimension.

01:13:40.000 --> 01:13:48.000
To define. My total index dimension inside of Facebook AI similarity search.

01:13:48.000 --> 01:13:54.000
So here, what we can do is that, that we can try to call FAISS.

01:13:54.000 --> 01:14:06.000
Uh, there is something called as index, I-N-D-E-X. Index, and then… There is something called as index flat IP. So, index FLAT.

01:14:06.000 --> 01:14:16.000
Flat IP, yeah? So, index flat IP, and inside that, you are going to…

01:14:16.000 --> 01:14:24.000
Pass a dimension. So basically, this one is going to set a dimension for a particular indexes, a particular data, because.

01:14:24.000 --> 01:14:34.000
Inside this Facebook accessibility search, I can try to store a data with any of my dimension. So, maybe 2000 plus, 3000 plus, 5,000 plus.

01:14:34.000 --> 01:14:53.000
But yeah, so initially, you have to define the dimension that, okay, fine, so what is the dimension of your data set? Because your data set can be using maybe a… different, different models, and every model gives you a different, different dimension. So here, I'm going to set a dimension, and I'm going to call it as a index. Indx, index over here.

01:14:53.000 --> 01:15:02.000
So, just set a dimension, right? You can try to even hardcode it, there is no issue at all, so I can directly come over here, and I can write 1536.

01:15:02.000 --> 01:15:12.000
Because I know that 1536 is a dimension which my model is going to return, so I can even do this one. There is no, like, harm in that one. That's completely fine, yeah?

01:15:12.000 --> 01:15:22.000
And once you are able to create the indexes. Next step is index.add, and add all the data at a time, yeah?

01:15:22.000 --> 01:15:32.000
Index.add. Now, once you are going to call index.add, and I'm just trying to call my entire dataset this one, which is a NumPy array, or NumPy format, or numpy-compatible data.

01:15:32.000 --> 01:15:37.000
It will be able to store all of this data automatically. So let me ping you this code.

01:15:37.000 --> 01:15:46.000
So… What is D? D is nothing but a dimension of the data, so the dimension which your model is going to return. So, I have just hard-coded it over here.

01:15:46.000 --> 01:15:57.000
Or else you can try to take a D. From a data set itself. So I'm trying to find out the shape of the very first data, and then out of that, I'm trying to check what is the dimension. Otherwise, hardcode it, it's fine, I know that.

01:15:57.000 --> 01:16:10.000
My model is going to return 1536. So, this is something that you have to do. Now, this is a process, this is just one single line, where we are trying to add all the data.

01:16:10.000 --> 01:16:17.000
So, after this step. My dataset has been added. Now my dataset has been stored inside of Facebook, yeah, similarity search.

01:16:17.000 --> 01:16:25.000
So, stepwise, if you are going to ask me. Only these two lines of code is required to store our data.

01:16:25.000 --> 01:16:33.000
Only this, two-line. Above and before, we were trying to do just a data preprocessing.

01:16:33.000 --> 01:16:40.000
What is the line to store the data? Create the indexes, call add. That's it. And work done.

01:16:40.000 --> 01:16:47.000
Data is stored. Inside Facebook guys, similarity search. It's done.

01:16:47.000 --> 01:17:02.000
Making sense? Yeah? So, basically, it's in-memory as of now. It's available into our memory, it's available into a RAM as of now, by the way, yeah? I can try to even create a physical file, and I can try to even store these indexes.

01:17:02.000 --> 01:17:08.000
And I can try to store Amita information, which I'll do it now itself, don't worry.

01:17:08.000 --> 01:17:11.000
Which I'm going to do it. So, when I'm trying to call index.add.

01:17:11.000 --> 01:17:18.000
As of now, everything is in memory. It is not persisting my data into a hard disk.

01:17:18.000 --> 01:17:26.000
Into any kind of physical file, by the way. Everything is available into a in-memory. Now, so, only this line of code, guys. Just imagine.

01:17:26.000 --> 01:17:33.000
To store any kind of a data. Only this line of code is required. Create the indexes, or whatever dimension that you have.

01:17:33.000 --> 01:17:38.000
That you are able to get from the model. And then, call add.

01:17:38.000 --> 01:17:42.000
End of the story. Simple. Right?

01:17:42.000 --> 01:17:50.000
So we have, we have done a lot. Before this step, but yeah, all of those was just, uh, pre-processing.

01:17:50.000 --> 01:18:08.000
Of the data. This is the actual storage. Okay, now let's go ahead. And like I told you, that it's an in-memory, right? Let's suppose I would like to persist this entire indexes in a file system, right? In a file system, and apart from that, so I would like to persist my…

01:18:08.000 --> 01:18:20.000
Meta-information, because even this meta-information is available in a variable, so technically it's available into a memory as of now, right? So, once I'm going to restart my computer, or once I'm going to, you know, close this entire VS Code.

01:18:20.000 --> 01:18:29.000
After that, I have to re-execute, reload this entire thing. So, let's go ahead and let's try to store this entire information into some file.

01:18:29.000 --> 01:18:38.000
Yeah? Into some file. So, here, for index, let's suppose I'm going to create a variable, index underscore PATH, index underscore path variable.

01:18:38.000 --> 01:18:47.000
And, uh, I'm just trying to give a name, uh… So…

01:18:47.000 --> 01:19:01.000
Uh, so, just try to store the index of… So, the answer data, if AISS. So, this is going to be the file which I'm going to create, right? So, this is the name of the file, and this is the file extension. So, Facebook has similarity search.

01:19:01.000 --> 01:19:08.000
And over here, I'm going to store all of these indexes, right? All these vectors, by the way.

01:19:08.000 --> 01:19:15.000
And, uh, meta information. So, meta-information, let's suppose I'm going to create a metasudhansu.json.

01:19:15.000 --> 01:19:22.000
Or maybe JSON-L I can try to create, and I'm going to keep all those metadata.

01:19:22.000 --> 01:19:25.000
Means this one, right? This one. I can try to attach even date and time if I want.

01:19:25.000 --> 01:19:34.000
I can try to attach even a geographical location, because with some data, we do that, right? We can try to attach a latitude-longitude.

01:19:34.000 --> 01:19:38.000
And we does this kind of a things as well, right? While creating a meta-information.

01:19:38.000 --> 01:19:47.000
But case by case basis, it depends, yeah? So, what kind of a problem that we are going to solve? So, let's suppose I'm going to create two files.

01:19:47.000 --> 01:19:55.000
As of now, file path. In one file, so I'm going to store the indexes, and in one file, so I'm going to store my meta information. Okay, let's do it.

01:19:55.000 --> 01:20:02.000
Then. So, here. If we have to store, uh…

01:20:02.000 --> 01:20:09.000
Indexes, right? So I can try to simply call Facebook AI Similarity Search.

01:20:09.000 --> 01:20:15.000
Dot, uh, write… indexes, and then…

01:20:15.000 --> 01:20:29.000
This is my index variable. And this is the index path. This is the index path. Simple. Execute it, and if you will come here, you will be able to find out index underscore danshu, it has already created.

01:20:29.000 --> 01:20:32.000
A physical file, but you will not be able to read it out. So, if you will try to read it out.

01:20:32.000 --> 01:20:39.000
It will show you your information in, like, this way. Right? It's a…

01:20:39.000 --> 01:20:47.000
Serialized file, you will be able to find out. So technically, all of this data is available over here into a bytecode. It's a serialized one.

01:20:47.000 --> 01:20:51.000
And when you try to read the file. So you try to perform the deserialization.

01:20:51.000 --> 01:21:00.000
So here, we are able to create a physical file. Now, inside this physical file, I have all of these indexes, this one.

01:21:00.000 --> 01:21:13.000
So now I'm able to persist my data into a hard disk. Now, even if I'm going to close my computer, that's completely fine. Once I'm going to open it up, I don't have to go through all of those lengthy processes, which I have already done.

01:21:13.000 --> 01:21:20.000
So, I can directly start from this particular file, and I can start, like, you know, searching for the data.

01:21:20.000 --> 01:21:24.000
Yeah, so in a physical file, we are able to store this data, uh, as indexes.

01:21:24.000 --> 01:21:36.000
Let's suppose if I have to store our meta information as well. So, you can try to write the code, and you can try to, you know, uh… store all of this information, and that's completely fine.

01:21:36.000 --> 01:21:43.000
Is it making sense, guys, to all of us? So let me ping you this one.

01:21:43.000 --> 01:21:48.000
It's very simple. Facebook AI, similarity search, call it, and then call it, like, write indexes.

01:21:48.000 --> 01:22:02.000
Yeah? Okay. So, here, uh, let's try to import JSON. Import IMPORT.

01:22:02.000 --> 01:22:14.000
Json? And maybe operating system, I'm going to import. Let's suppose I'm trying to store a meta information, right? Uh, so meta information into a physical file.

01:22:14.000 --> 01:22:22.000
So I can try to write with open. And, uh…

01:22:22.000 --> 01:22:27.000
Metapath, right? Right?

01:22:27.000 --> 01:22:34.000
And then, one by one, one by one, write all of these information.

01:22:34.000 --> 01:22:40.000
So, we have this meta. And I'm going to write it down inside this.

01:22:40.000 --> 01:22:51.000
Pile. So, execute it, let me ping you this code. Now, here, if I'll come, so I have this meta information, right? The beautiful manor.

01:22:51.000 --> 01:22:58.000
Uh, whatever meta-information that I had, so ID and textual information. So, yeah, all of these informations are available to me.

01:22:58.000 --> 01:23:07.000
So, meta-information, I'm able to store, by the way, and uh… Even my vector, even my embeddings, I'm able to store it.

01:23:07.000 --> 01:23:12.000
Finally, guys, all of us are able to do it. Meta plus vector both?

01:23:12.000 --> 01:23:18.000
Yeah? So now it's available inside my hard disk. I'm able to create a physical file.

01:23:18.000 --> 01:23:23.000
So, now, even if I am going to close my entire system, if I'll come back.

01:23:23.000 --> 01:23:29.000
I will be able to get the exact same thing. Right? I will be able to get the exact same thing.

01:23:29.000 --> 01:23:35.000
So, storing is done. So, we are able to store our data set, that's cool.

01:23:35.000 --> 01:23:50.000
And now we have to perform a searching, right? Now we have to perform the search operation. So let's suppose if I'm going to, uh, like, write something like, who is the Hanshu? So, obviously, from that information, from that embedding.

01:23:50.000 --> 01:24:00.000
It must give me some answer, or it must give me some return, right? So, storage is done. Now it's time for, basically, a search operation.

01:24:00.000 --> 01:24:08.000
Yes? Is FAISS is a standard command? I mean, like, there is nothing called a standard, non-standard command, it's just a library, right?

01:24:08.000 --> 01:24:18.000
I think your Python is weak, you should revise your Python.

01:24:18.000 --> 01:24:28.000
Okay, so once we are able to do this, once we are able to store the information, now we have to basically perform a search operation.

01:24:28.000 --> 01:24:41.000
This is the next one, next thing that we have to do. So, we have to perform the search operation, so that I can write a query, and uh… it will be able to give me some result. For example, if I'm going to write a query.

01:24:41.000 --> 01:24:50.000
That, uh, uh, what was our mission of iNeuron, or what has happened in 2022, or maybe who is the Hancho Kumar?

01:24:50.000 --> 01:24:58.000
So, I believe those informations are already available in that particular data set, right? Those informations are already available.

01:24:58.000 --> 01:25:03.000
So, let's suppose if someone is going to write a query. So, let's suppose query is this one, right?

01:25:03.000 --> 01:25:12.000
So, first of all, I'll try to convert this query, convert this query into what? So, I'm going to convert this particular query into a embeddings.

01:25:12.000 --> 01:25:16.000
So, I'm going to follow the exact same thing that I have, like, done.

01:25:16.000 --> 01:25:25.000
Uh, even before, right? So even before. So here, I'm going to, like, generate the embeddings for this particular query.

01:25:25.000 --> 01:25:34.000
Simple, yeah? So, generate embedding. And, uh, once I'm going to generate the embedding, so I'm going to convert this one into a float32.

01:25:34.000 --> 01:25:49.000
Because I have done that for even, like, the… previous one, and then I can try to call a reshape, so that my dataset will be flat. So, now this is going to be my actual query. Let's suppose I'm going to name it as a queue.

01:25:49.000 --> 01:25:56.000
Okay, so once this is done, so this is my query, I'm able to convert it into, like, some normalized format, yeah?

01:25:56.000 --> 01:26:06.000
Then, just try to call Farsi normalize L2, and then try to pass a query over here. So that it will be able to calculate the norm.

01:26:06.000 --> 01:26:12.000
In our denominator, we had a normalization, right? So, maybe you can say that as an equilibrate distance. It will be able to calculate the.

01:26:12.000 --> 01:26:22.000
Norms over here, and… Uh, once this is done, so I can try to call index.search. Search-wise, so I'm trying to pass my query.

01:26:22.000 --> 01:26:29.000
Yeah, I'm trying to pass my query, and then I'm trying to pass a top K value.

01:26:29.000 --> 01:26:36.000
Means try to give me top 5 results, or maybe I can try to say that give me top 3 results, that's completely fine. So, this is basically a top K.

01:26:36.000 --> 01:26:43.000
So, whichever will be having a top 3 most, uh, like, uh, you know, close or, like, uh.

01:26:43.000 --> 01:26:54.000
The maximum similarity, so it is going to give me that result. So, index.search, uh, sorry, index.search, and it is going to give me the… entire result. So, let's see, yeah?

01:26:54.000 --> 01:27:08.000
So, it is, right? So, it is able to give me some sort of a result, by the way, and uh… index.searchwise, so I'm able to see some result, yeah? I'm able to see some result.

01:27:08.000 --> 01:27:13.000
So, it is giving me… Uh, array number 2.

01:27:13.000 --> 01:27:20.000
Ra number 1 and RA number, uh, 0 in general, right? So this is the result which it is trying to give it to me.

01:27:20.000 --> 01:27:29.000
Maybe I can try to write, like, uh, give me top 5. So, it is giving me array number 2, then 1, then 0, then 3, and then 5.

01:27:29.000 --> 01:27:38.000
And here is a. Score, basically, right? Here is a score, and in a…

01:27:38.000 --> 01:27:43.000
Descending order, right, in a descending order, so it is trying to give me the score.

01:27:43.000 --> 01:27:48.000
And, uh, for a particular score, it is trying to give me the array indexes.

01:27:48.000 --> 01:27:54.000
Now, anyone who can explain me this result, I believe we all can understand, like, it's a very easy one to understand it.

01:27:54.000 --> 01:28:06.000
But anyone who can give me the explanation?

01:28:06.000 --> 01:28:14.000
Yep. This source second index is the best, exactly. This is what it means, because similarity score is basically 0.56.

01:28:14.000 --> 01:28:25.000
Yeah? So, RA2 is best, then what is the second best? Second best is 1. What is the third best? Third best is basically 0. What is the fourth best? Fourth best is 3. And what is the fifth best?

01:28:25.000 --> 01:28:53.000
So, 50-based is, basically, 5. This is what it is trying to, like, give it to me.

01:28:53.000 --> 01:28:58.000
Yes?

01:28:58.000 --> 01:29:15.000
Okay, fine. So… Like, here, we are able to get this result. Now, maybe we can try to do a little bit more of coding, and we can try to see a result which will be human-readable, right? As of now, it is trying to give me, like, a cosine similarities score.

01:29:15.000 --> 01:29:19.000
And then after that, so it is trying to give me a respective.

01:29:19.000 --> 01:29:25.000
Indexes, right? That, okay, fine, so for this particular array index, this is the similarities code that we are able to find out.

01:29:25.000 --> 01:29:33.000
And this is the arrangement. Now, let's suppose we have to arrange this entire data, and we have to basically showcase that, okay, what is.

01:29:33.000 --> 01:29:43.000
Available at array index 2. I think even with respect to meta-information, I can try to, like, go and check, right? And even I can try to write a Python code.

01:29:43.000 --> 01:29:48.000
So, which will be able to print, because I have IDs even over here, right?

01:29:48.000 --> 01:29:53.000
So, RA2 means ID2. Are there general means? This one.

01:29:53.000 --> 01:30:11.000
Rfi means this one. Right? So, I can just try to do, uh, like, a little bit of Python coding, and I will be able to understand that, okay, so which line is matching with my line? So my input was what is the mission of iron, I believe, and this was background, they saw iron…

01:30:11.000 --> 01:30:16.000
As a lifeline opportunity to rise above their circumstances while this is a question, yeah.

01:30:16.000 --> 01:30:22.000
So… I think it is giving me, like, an accurate result, although…

01:30:22.000 --> 01:30:30.000
Mat score is 0.56. So, which is not closer to 1, but yeah.

01:30:30.000 --> 01:30:35.000
This is the most similar sentence which I'm able to get.

01:30:35.000 --> 01:30:40.000
Now, if I'm going to ask who is… Sudan Chu. Let's see.

01:30:40.000 --> 01:30:48.000
So, for who is the Anshu? The top score is, uh, fourth index, by the way.

01:30:48.000 --> 01:30:51.000
Yeah. So I believe it's a correct answer that I'm able to get.

01:30:51.000 --> 01:30:57.000
In my fourth sentence, this is something which was mentioned by the way.

01:30:57.000 --> 01:31:06.000
Right? Everyone? Yeah? So, we are able to get, uh, desired result, I believe.

01:31:06.000 --> 01:31:14.000
So now, if I have to ping you this code. Yeah. So here is the code, guys.

01:31:14.000 --> 01:31:21.000
Simple. So, now I'm able to store the information, and after storing the information, I'm able to even.

01:31:21.000 --> 01:31:50.000
Query the information, and it looks like that I'm able to get the correct result.

01:31:50.000 --> 01:31:57.000
My output values are different, since we have a same data, same model, and pretty much the same code should not have a result be same.

01:31:57.000 --> 01:32:06.000
Oh, I think just try to check your chug size, by the way, and your overlap size, so if your chunk size is different, if your overlap size is different.

01:32:06.000 --> 01:32:14.000
And if it is… Like, exactly the same data, then obviously results should be closer. Results should be closer, always be closer.

01:32:14.000 --> 01:32:35.000
If it is not, then obviously it will not.

01:32:35.000 --> 01:32:41.000
Okay, so someone is asking me a question that Farsi normalized L2 query embedding place plan, why we applied this one?

01:32:41.000 --> 01:32:50.000
Okay, so see, uh, when we are trying to call this, uh, normalize vector L2, right? So, what it does, let me, uh, use a pen.

01:32:50.000 --> 01:33:01.000
So, basically, what it is trying to perform, so whatever vector that we have taken, or whatever.

01:33:01.000 --> 01:33:09.000
Yeah, so whatever vector that we have taken over here, so what it will try to do is that, that it will try to find out.

01:33:09.000 --> 01:33:16.000
Basically, let's suppose this is my vector. X. So, for this vector X.

01:33:16.000 --> 01:33:24.000
It will try to find out normalization of a vector X, by the way, which is nothing but a summation of a x squared i.

01:33:24.000 --> 01:33:38.000
And which is going to return, technically, 1. So, here, it will try to normalize all the vector, so that L2 or L2 norms, so that the length of the vector is always going to be 1. Means, from our origin.

01:33:38.000 --> 01:33:48.000
Length is always going to be… 1. So this is the simple normalization technique that we try to apply, so that all of this will come into a same length.

01:33:48.000 --> 01:33:59.000
And, uh, then our similarity score calculation will be… easy. Yeah? So this is what this index flat IP always try to do.

01:33:59.000 --> 01:34:07.000
So, here, when I have called, if you have observed. I have called, basically, index flat IP.

01:34:07.000 --> 01:34:13.000
Now, what is the meaning of this IP, by the way? So, meaning of IP is nothing but a inner product search.

01:34:13.000 --> 01:34:28.000
So, by default, it is going to apply dot product similarity search, which is nothing but a cosine similarity such, it will be able to apply. If I'm going to call index flat IP.

01:34:28.000 --> 01:34:34.000
Fine, everyone? Yeah? So, by default, it is going to find out the similarity search.

01:34:34.000 --> 01:34:48.000
Means dot product it is going to find out, by the way.

01:34:48.000 --> 01:34:55.000
What was the VStack? It's a vertical stack, so it's a simple number formula, so where we are trying to flatten the data.

01:34:55.000 --> 01:35:06.000
Vertically.

01:35:06.000 --> 01:35:17.000
So, let's suppose some of you have a query with respect to normalization, so let me show you with respect to a NumPy array. So, let's suppose I'm going to consider a NumPy array over here.

01:35:17.000 --> 01:35:23.000
And, uh, inside this array, so let me take one small data.

01:35:23.000 --> 01:35:28.000
Uh, let's suppose we have, uh, 4 comma, 5 comma, 6 comma, 7 comma, 8.

01:35:28.000 --> 01:35:38.000
Something like this we have over here inside this. Numpyarray. Okay? Now, so, let's suppose I'm going to store it as a…

01:35:38.000 --> 01:35:41.000
Uh… That's the data, okay?

01:35:41.000 --> 01:35:46.000
So, as our test data over here. Now, when I'm going to call.

01:35:46.000 --> 01:35:53.000
Basically, uh, normalization on top of this data. First of all, let me convert this data into a flat 32.

01:35:53.000 --> 01:35:59.000
Yeah. So, flat 32. Now, if I'm going to show you my test data, so this is how my test dataset looks like.

01:35:59.000 --> 01:36:03.000
Yeah, that's what it looks like. So after data, there will be a floating one number.

01:36:03.000 --> 01:36:11.000
Now, here, if I'm going to call normalization, right? Here, if I'm going to call the normalization, so let's suppose numpy.

01:36:11.000 --> 01:36:15.000
Lineage… nom test.

01:36:15.000 --> 01:36:21.000
So, it is giving, basically, 13.78. Something like this, it is trying to, uh, give it to me.

01:36:21.000 --> 01:36:31.000
Uh, now, if I'm going to call FAI. Ss… SS.normalizeL2.

01:36:31.000 --> 01:36:38.000
And then, if I'm going to pass my test data. What this will try to return?

01:36:38.000 --> 01:36:43.000
So, here… Let me pass numpy.

01:36:43.000 --> 01:36:50.000
Dot… lineage… dot NOM test.

01:36:50.000 --> 01:36:55.000
Now it will come closer to 1. So this is the differences. So, see.

01:36:55.000 --> 01:37:01.000
I've taken one array. I had a random array, even with respect to a vector. I have taken that.

01:37:01.000 --> 01:37:11.000
Now, so if you are going to find out the norm, means if you are going to find out this one.

01:37:11.000 --> 01:37:17.000
Of this test. So, what does this mean? It simply means that that 4 square plus 5A square plus 6A square.

01:37:17.000 --> 01:37:24.000
Plus 7S squared, plus 8 squared. This is what it is going to return. Now, this is something that it is trying to return.

01:37:24.000 --> 01:37:31.000
This is a norm, right? This is a norm. Now, so when I'm trying to apply, uh…

01:37:31.000 --> 01:37:40.000
Normalization with L2. L2 is nothing but a regulation technique, right? So when I'm trying to call normalization with respect to a L2.

01:37:40.000 --> 01:37:46.000
So, with regularization. So, what it does is that, that it will… so here, length is equal to 13 for the same data, right?

01:37:46.000 --> 01:37:53.000
And here, so when I have called L2 on top of this one, so it has normalized each and every dataset.

01:37:53.000 --> 01:38:02.000
To a unit value, only 1. Right? Only one. So that, whenever I'm going to find out a cosine similarity, so as we.

01:38:02.000 --> 01:38:06.000
Know the formula, right? Cosine, similarity, let's suppose. So, cosine similarity is what.

01:38:06.000 --> 01:38:12.000
So, vector A, dot vector B divided by norm of vector A.

01:38:12.000 --> 01:38:23.000
Into norm of vector B. So, what we are trying to say is that by normalizing, let's make it 1, let's make it 1. So, technically, we are nullifying the entire.

01:38:23.000 --> 01:38:29.000
Denominator, so your cosine similarity score, you will be able to find out just by finding out the.

01:38:29.000 --> 01:38:37.000
Dot product, and this is what this IEP is doing. Index, so Farsi index flat IP that we have called, right? From a Farsi database.

01:38:37.000 --> 01:38:42.000
If you remember, so we have called what? So we have technically called.

01:38:42.000 --> 01:38:52.000
A library called as indexflatIP. So, technically, what it is trying to do, so it is trying to calculate index flat IP, inner product. Ip means inner product.

01:38:52.000 --> 01:38:55.000
So, it is just trying to calculate A cross A dot B.

01:38:55.000 --> 01:39:03.000
It is not supposed to calculate the denominator one. Reason is very simple. So, we have already normalized it. Normalized it means.

01:39:03.000 --> 01:39:12.000
Your denominator is always 1. Right? Your denominator is always 1. For any vector, right? For any vector, you are going to pass, after normalization, if you are going to calculate the norm.

01:39:12.000 --> 01:39:16.000
So after this L2, right, if you're going to calculate the norms, it will be 1.

01:39:16.000 --> 01:39:20.000
This is one, by the way, so it will be basically 1.

01:39:20.000 --> 01:39:30.000
So, 1 into 1 is going to be 1. Something divided by 1 is not going to affect anything, right? So this is the reason we are trying to call the normalization over here.

01:39:30.000 --> 01:39:36.000
And this is the… this is how, basically, this flat IP is going to work. So technically, it calculates just a.

01:39:36.000 --> 01:39:48.000
Inner product, IP, A.B, it is going to calculate. So, hope this part is fine, guys. Inner Flat IP is fine, and why we are trying to call this L2, by the way.

01:39:48.000 --> 01:39:54.000
That is also fine.

01:39:54.000 --> 01:40:05.000
Yeah, why we are doing it? Because we are just converting this denominator into 1, so that it is not going to affect it, and index flat IP, by default, it is going to calculate the dot of it.

01:40:05.000 --> 01:40:12.000
That was the whole idea. This is how this library has been built, by the way.

01:40:12.000 --> 01:40:22.000
Okay, so now we are able to do a query, and we are able to even store the information, plus we are able to find out, uh, best.

01:40:22.000 --> 01:40:30.000
One with respect to my query. So, which is going to be the best one? So now you can do a Python mapping, Python mapping of this result with respect to the meta information, and then you will be able to get the.

01:40:30.000 --> 01:40:41.000
Final result. That's cool. Now, this is one of the datasets, by the way, yeah? This is one of the datasets, by the way. Now, we have a lot of different, different data sets.

01:40:41.000 --> 01:40:50.000
Database. So, quadrant.

01:40:50.000 --> 01:40:56.000
Is one of the database, right? So, quadrant vector database, uh, we have.

01:40:56.000 --> 01:41:02.000
And, uh, we have, basically, yeah, so Quadrant tech. You have to go to a Quadrant tech.

01:41:02.000 --> 01:41:12.000
We have a pine cone, by the way. So, we have a pine cone, we have a quadrant.

01:41:12.000 --> 01:41:17.000
We have… ChromaDB?

01:41:17.000 --> 01:41:39.000
This one?

01:41:39.000 --> 01:41:49.000
And we have Waviate. Yeah, so we have so many different, different, different, different kind of databases which is available in the same segment.

01:41:49.000 --> 01:41:58.000
Now, some of this database is going to provide you even a managed hosting. Managed hosting means they have already hosted it over a cloud platform.

01:41:58.000 --> 01:42:06.000
Uh, you don't have to do anything, just go ahead and then, like, uh, do the installation and start storing your data set.

01:42:06.000 --> 01:42:12.000
So, let's suppose I'm going ahead with the quadrant, right? So, accept all cookies, and let me ping you this link.

01:42:12.000 --> 01:42:20.000
And this link will be available even inside your dashboard. So one by one, I'm pinging you a link of, uh…

01:42:20.000 --> 01:42:27.000
All of these databases. Yeah. So let's go ahead with the quadrant first.

01:42:27.000 --> 01:42:37.000
Now, I can try to click on login, and it should provide me a Google login, by the way, plus my free credit.

01:42:37.000 --> 01:42:41.000
Okay, so I'll just try to do a Google login, by the way.

01:42:41.000 --> 01:42:45.000
With respect to a quadrant.

01:42:45.000 --> 01:42:55.000
Alo? And this is a quadrant dashboard you will be able to find out. Very easy to log in.

01:42:55.000 --> 01:43:06.000
Don't have to create the account or anything, so it's simple, click on login and go ahead with the Google login. And you all will be able to log in inside the quadrant. It's a very, very simple, like, you know, system that people have given to you.

01:43:06.000 --> 01:43:17.000
So, where you can come and you can try to, you know, spin a machine. Basically, it will be a shared machine. You can go ahead with a dedicated machine as well, if you are going to pay up bills for that.

01:43:17.000 --> 01:43:24.000
But if you don't want to pay our bills, if you are just coming here for the experimentation, for learning purposes, then they are providing you enough.

01:43:24.000 --> 01:43:31.000
So, let's suppose here I'll go and try to create a cluster, right? So… your own vector.

01:43:31.000 --> 01:43:42.000
Or DB, right? Vector dB. So, by default, they're giving you one node and 4GB of a disk space, 1GB of the RAM, and then half of the virtual core CPU they're giving it to you.

01:43:42.000 --> 01:43:54.000
Plus, they're giving you AWS and Google corporate form integration, and into a multiple locations. So, if you are into a free cluster, if you'll go with a willing, then obviously feature will be more, and they have already listed on a feature over here.

01:43:54.000 --> 01:44:04.000
So, first of all, whenever you will come inside a quadrant, you have to create a cluster. So just give a name over here, any name XYZ you can try to give, and then click on create a free cluster.

01:44:04.000 --> 01:44:09.000
It will take maybe, like, 2-3 minutes of time, not more than that.

01:44:09.000 --> 01:44:16.000
And, uh, here, so it is giving you an API key. So, please make sure that you are saving this API key somewhere.

01:44:16.000 --> 01:44:28.000
Right? And it is going to give you even a sample Python code, by the way, right? Sample Python code, so that… and in sample Python code, there is nothing, just a URL, just an endpoint they have given to you.

01:44:28.000 --> 01:44:38.000
And they have attached your API key, so that you will be able to hit their instance. You will be able to hit their services, as simple as that.

01:44:38.000 --> 01:44:51.000
And, uh, that's the reason, so we have discussed about an API key in the very beginning. Because, again and again, you will see that we are using some of the services, and over there, people have exposed their entire services as an API key. With API key, by the way.

01:44:51.000 --> 01:44:57.000
Yeah? So maybe I can try to, like, copy this one, and I can try to keep it somewhere inside my system.

01:44:57.000 --> 01:45:07.000
So, let me create a new file. And let me name it as a… Q, D, R, A, and D quadrant, dot IPYNB.

01:45:07.000 --> 01:45:11.000
And create a code. I'm keeping each and everything over here.

01:45:11.000 --> 01:45:23.000
I have copied this quadrant client, by which I will be able to establish the connection between my system and a quadrant system, so… Let me select the kernel, same kernel I'm going to select.

01:45:23.000 --> 01:45:41.000
Store it, yeah? So, keep it, and then close it. As simple as that. And, uh, here, now I can see that my instance is ready, my cluster is ready, right? My cluster is ready. So, this is my end point that they have given to me. This is just a cluster ID, which has been given to me.

01:45:41.000 --> 01:45:46.000
These are the cluster, like, resources, uh, which they have given me in my free.

01:45:46.000 --> 01:46:00.000
Instance, by the way. And, uh, yeah, rest of the things are completely fine. Access the cluster, so I can try to click and… again, they are going to give me the sample code by which I will be able to access the cluster.

01:46:00.000 --> 01:46:05.000
And this is something… Which is our UI.

01:46:05.000 --> 01:46:10.000
Right? Which is a UI, click start, like, you can try to, like, you know.

01:46:10.000 --> 01:46:19.000
Do each and everything from here itself kind of a thing, right? So, from their UI itself, you will be able to perform all of these operations.

01:46:19.000 --> 01:46:25.000
So, here, let's suppose this is my… cluster, this is my database, right, and I have to…

01:46:25.000 --> 01:46:36.000
Send a data. I have to store a data here. So, how I will be able to store our data over here, let's try to understand.

01:46:36.000 --> 01:46:45.000
So, are you able to log in, guys? Are you able to create your API keys, and are you able to get your endpoint, everything?

01:46:45.000 --> 01:46:52.000
Yes?

01:46:52.000 --> 01:47:14.000
Yeah? Cluster means machine, yeah, set of machine, by the way. Cluster means multiple machines coming together.

01:47:14.000 --> 01:47:24.000
Right? So, a very simple configuration, as we can see, right? A very, very simple configuration, and now what we can do is that, that we can try to store the information.

01:47:24.000 --> 01:47:41.000
One by one.

01:47:41.000 --> 01:47:52.000
Okay, so let's start it, guys. So, first of all, go to your VS Code, and try to create a new tab, and here, so, you have to install a quadrant client.

01:47:52.000 --> 01:47:56.000
So unless we are not going to install a quadrant client.

01:47:56.000 --> 01:48:03.000
It will not be able to understand. So this one, by the way. So, this one we have to install, so pip install quadrant client, execute it.

01:48:03.000 --> 01:48:09.000
And I'm pinging you the same inside your chat. So people install Quadrant Client.

01:48:09.000 --> 01:48:20.000
So I need a compatible library, right? And once this is done, the code which I have copied and pasted, technically which was a URL and an API key, just execute it.

01:48:20.000 --> 01:48:27.000
Just execute it, and it will try to check the connection. So, here, collection is equals to blank.

01:48:27.000 --> 01:48:36.000
Which means I'm able to establish the communication. Maybe I can try to even print just a quadrant client variable, and uh… here, so it is giving me some…

01:48:36.000 --> 01:48:44.000
A hexadecimal code, it simply means that I'm able to establish the communication, yeah? I'm able to establish the communication.

01:48:44.000 --> 01:48:50.000
Now, so once this is done, once you are able to establish the communication.

01:48:50.000 --> 01:49:01.000
Now, we can try to store the information, a similar information that we have, like, uh… prepared before, right? So that we have prepared before, into this quadrant.

01:49:01.000 --> 01:49:07.000
Which is available in some of the cloud platform.

01:49:07.000 --> 01:49:16.000
Fine, shall we do it, guys? Everyone?

01:49:16.000 --> 01:49:29.000
Yes? Okay. Very easy. So, now we are not doing it in our local system, so now we are going to do it everything on our… a global system, yeah? So, in a cloud system, basically. So, our data will directly go inside the.

01:49:29.000 --> 01:49:35.000
Cloud system. So here, whenever you are going to store some sort of information inside the quadrant, so first of all, let's try to create the.

01:49:35.000 --> 01:49:47.000
Collection name, COACTION, collection underscore name. And I'm going to give a collection name is equal to stanchu underscore STURY story. So, this is the collection name which I'm going to give.

01:49:47.000 --> 01:49:55.000
So it means a table, right? You give a table name. So, similarly, I'm just trying to give a collection name over here. Nothing much.

01:49:55.000 --> 01:50:02.000
Yeah? Nothing much. At all. Now, here, so I'm going to call my quadrant client, uh…

01:50:02.000 --> 01:50:13.000
Quadrant client, this one that we have created, right, this quadrant client, because this is my… starting point, right? This is the point where I will be able to communicate, uh…

01:50:13.000 --> 01:50:18.000
From my local system to the quadrant system. So, quadrant client, I'm going to call.

01:50:18.000 --> 01:50:29.000
And quadrantClient. I can try to say, uh, recreate collection. So, recreate collection is a method which is already available.

01:50:29.000 --> 01:50:38.000
And then here, so we can try to give a collection name. So, collection name is equal to cancer story, so fine, we are trying to give that school.

01:50:38.000 --> 01:50:45.000
Now, once we are able to give a collection name over here, we can try to set our vector configuration.

01:50:45.000 --> 01:50:47.000
So vector configuration is nothing but the data that we are going to.

01:50:47.000 --> 01:50:55.000
A store, by the way, right? The data that we are going to store, so that is something that we have to give as a vector configuration.

01:50:55.000 --> 01:51:12.000
So, here, vector configuration-wise, we have to… Let me check its, uh, latest syntax.

01:51:12.000 --> 01:51:19.000
Okay, so latest syntax is basically MODE.

01:51:19.000 --> 01:51:28.000
Models.vectorparameter. Okay. So, vector configuration-wise, model.vector parameter is something that we have to call.

01:51:28.000 --> 01:51:36.000
And then we have to… Okay, let me import a model…

01:51:36.000 --> 01:51:43.000
As it is not able to resolve the dependencies. So there is something called as models.

01:51:43.000 --> 01:51:50.000
From… quadrant client, import models. Okay.

01:51:50.000 --> 01:52:01.000
So, models.vectorparameter, we have to give. So, these syntaxes are already mentioned even inside the documentation. So, again, no need to remember the syntaxes. Even I don't remember it, because there are, like.

01:52:01.000 --> 01:52:14.000
Hundreds of such databases which is available. Uh, so here, it is just asking me quadrant client, fine, and I'm giving collection name, and then I'm giving a… vector parameters. So my vector size is basically 1536, so I have given that.

01:52:14.000 --> 01:52:21.000
And, uh, then I can try to… Uh, give, basically.

01:52:21.000 --> 01:52:28.000
And so, after giving a size. Distance?

01:52:28.000 --> 01:52:41.000
Distnc, distance, so model distance cosine. So, whenever. It is going to perform this operation, so just go ahead with the cosine similarity, yeah. So, this is the collection. I'm going to create.

01:52:41.000 --> 01:52:51.000
Fine. So, this is going to create a database kind of a thing, where collection name is going to be my surround story night, and these are the parameters that, okay, so inside this.

01:52:51.000 --> 01:52:56.000
Like, table, or you can say collections. Whatever data you are going to store.

01:52:56.000 --> 01:53:02.000
Size of the vector is going to be 1536, and whenever you are trying to perform the similarity search.

01:53:02.000 --> 01:53:29.000
Just try to use a cosine similarity search. Simple. This is what it means, right? This is what it means. So, once we are able to create this collection, so maybe we can go back and we can try to refresh, and we can try to check.

01:53:29.000 --> 01:53:40.000
Yeah. So now you will be able to see your collection name. So once you will click on this cluster UI, so this is going to show you our UI for your own cluster, right, for your cluster that you have created.

01:53:40.000 --> 01:53:44.000
And here, so you will be able to see a collection name.

01:53:44.000 --> 01:53:57.000
Yeah? Collection name, status is equal to green. Segment sorting is completely fine, and then size is name is default, size is basically 1536, and distance is cosine.

01:53:57.000 --> 01:54:05.000
It means whatever data which I'm going to insert into this collection, it is going to follow this property. This is what it means, by the way, yeah? This is what it means.

01:54:05.000 --> 01:54:14.000
So, making sense, guys? Yeah? So, as of now, there is no graph which is available, that's fine.

01:54:14.000 --> 01:54:25.000
No need to data set collection. Yeah.

01:54:25.000 --> 01:54:31.000
A simple collection I have created, fine. Now, so once I'm able to create the collection.

01:54:31.000 --> 01:54:39.000
Right? Once I'm able to create the collection. So, I can try to store a data inside this one, yeah? I can try to store a data inside this particular collection.

01:54:39.000 --> 01:54:46.000
So, let's go ahead, let's try to store our data inside this collection, because that is the next step for all of us, by the way.

01:54:46.000 --> 01:54:51.000
Yep. So, let's try to upload our.

01:54:51.000 --> 01:54:57.000
Chunks with the embeddings, yeah? Let's try to, like, uh… uploaded chunks with the embeddings.

01:54:57.000 --> 01:55:10.000
So, here, what I will do is that, that, uh… Let's try to prepare our data.

01:55:10.000 --> 01:55:17.000
Inside of… something called as points.

01:55:17.000 --> 01:55:22.000
List. Okay, so above code, fine.

01:55:22.000 --> 01:55:30.000
So dig it. This is actually a single line of a code. I have written it into a multiple lines, so those who are getting confused.

01:55:30.000 --> 01:55:35.000
It's not confusing at all, and this code is coming from a quadrant.

01:55:35.000 --> 01:55:46.000
Itself. So, quadrant documentation itself. So, whenever you will try to create the collection, so you have to give a collection name, plus you have to give the configuration of that particular collection, which is clearly visible, right?

01:55:46.000 --> 01:55:53.000
Which is, uh, clearly visible over here. Inside the collection itself, inside the collection, yeah?

01:55:53.000 --> 01:55:56.000
So everything is clearly visible over here, that whatever I have set.

01:55:56.000 --> 01:56:07.000
So all of these parameters are available in this place. Now, so, let's try to prepare the data so that I can dump this data. So, I'm going to prepare all of this data, and I'm going to keep it inside a points.

01:56:07.000 --> 01:56:11.000
List, yeah? So that's the reason I've created a point as a blank list.

01:56:11.000 --> 01:56:20.000
Now here, so in terms of preparing a dataset, so for… Uh, I in, let's suppose I'm going to write enumerate.

01:56:20.000 --> 01:56:27.000
And, uh, here, so I'm going to provide a JIP of, basically, CHU.

01:56:27.000 --> 01:56:38.000
Chung's, and I'm going to provide the embedding. Let's suppose. And, uh, this I'm going to change. It is going to return me IDX, so let's suppose.

01:56:38.000 --> 01:56:47.000
Means the ID. And then it should return me…

01:56:47.000 --> 01:56:59.000
Chunk? And embedding. Okay.

01:56:59.000 --> 01:57:07.000
Fine. So, uh, this is, uh, this is something which I'm going to take. So, I'm going to take, basically, a chunks, as you can see.

01:57:07.000 --> 01:57:18.000
And what is my chunks, by the way? My chunks is gone.

01:57:18.000 --> 01:57:26.000
Let me see… Chung says my meta, by the way. Sorry, I was wondering that I'm doing the same thing in the same file.

01:57:26.000 --> 01:57:31.000
Okay, leave it. I have to create it once again. This is a separate file I have created, right?

01:57:31.000 --> 01:57:37.000
So, let me create my chunks, guys.

01:57:37.000 --> 01:57:48.000
I have to do it once again. Copy my data…

01:57:48.000 --> 01:58:05.000
Hmm. Same code I have to write.

01:58:05.000 --> 01:58:12.000
So, here… Data…

01:58:12.000 --> 01:58:33.000
Data. Fine.

01:58:33.000 --> 01:58:41.000
Let me keep it, like… 300 and 100 of overlap.

01:58:41.000 --> 01:58:45.000
Okay, same as before, by the way.

01:58:45.000 --> 01:58:51.000
So fine, guys, do it once again in this file. So, whatever we have done in terms of preparing the data, right?

01:58:51.000 --> 01:58:58.000
So, I'm just doing it once again in this particular file, because I have changed the file. So, previous file was different, this file is different.

01:58:58.000 --> 01:59:06.000
So it's not available. I'm able to create a chunks. Now, once I'm able to create the chunks, I have to convert this entire data into an embeddings.

01:59:06.000 --> 01:59:13.000
So, after doing this, I can try to copy the exact embedding code from here.

01:59:13.000 --> 01:59:24.000
So, fine, and then I'm going to call the embedding.

01:59:24.000 --> 01:59:31.000
Okay. So, it should be able to do an embedding and store it inside the…

01:59:31.000 --> 01:59:37.000
Maybe EMB? List…

01:59:37.000 --> 01:59:46.000
Uh, remove everything, not required. Generate embedding.

01:59:46.000 --> 01:59:51.000
Of I…

01:59:51.000 --> 01:59:56.000
Emb.append.

01:59:56.000 --> 02:00:03.000
Okay. Uh, what? Happened to…

02:00:03.000 --> 02:00:17.000
Key error data. I have not even written a data.

02:00:17.000 --> 02:00:25.000
Enumeration, we have to remove.

02:00:25.000 --> 02:00:31.000
Yeah, so I'm just trying to convert… chunk is available to me, now I'm converting my entire dataset into, uh, embeddings.

02:00:31.000 --> 02:00:38.000
So simple, like, the previous step, uh… So now, embedding is available to me.

02:00:38.000 --> 02:00:47.000
Yeah, embedding is available to me, as you can see. Now I have to, like, uh, you know, convert this entire list, because this is the list.

02:00:47.000 --> 02:00:57.000
So, this operation we have done. Right?

02:00:57.000 --> 02:01:02.000
This operation we have done. So, same kind of operation, we can try to perform even over here.

02:01:02.000 --> 02:01:06.000
So that I will be able to convert my entire data into.

02:01:06.000 --> 02:01:13.000
I'll compatible one. So, here… Poor…

02:01:13.000 --> 02:01:26.000
Item in… I can write embedding data.

02:01:26.000 --> 02:01:42.000
Or just try to call numpy. Adid? Embedding list.

02:01:42.000 --> 02:01:51.000
Yeah, so now it's converted.

02:01:51.000 --> 02:01:59.000
So this is our data, guys, we have prepared even last time, right? Exact same data we have to prepare even this particular time. Uh, so our embedding is ready.

02:01:59.000 --> 02:02:09.000
And, uh, our chunk is ready. These two things are ready, and for embeddings, so I'm using Yuri API, you can try to use any of the other API, that's completely fine. So let me ping you this code.

02:02:09.000 --> 02:02:15.000
This code is nothing different, this code is same, uh, that I have used even in my previous example.

02:02:15.000 --> 02:02:25.000
So, once my embedding is available, now what I will do… so, now I'm good to… like a go-ahead with my data dump inside a quadrant.

02:02:25.000 --> 02:02:29.000
So let's go ahead and let's try to do the data dump inside the quadrant.

02:02:29.000 --> 02:02:41.000
Now, to do a data dump inside a quadrant. So, let's suppose I'm going to prepare the data. So, let's suppose there is a variable called as points variable, a list, where I'm going to keep all the prepared data.

02:02:41.000 --> 02:02:47.000
And, uh, here, so inside this particular list, I'm going to keep.

02:02:47.000 --> 02:02:52.000
Enumerate chunks? Let me remove this one.

02:02:52.000 --> 02:02:58.000
Jip off chunks and embeddings. Again, remove autocompletion.

02:02:58.000 --> 02:03:05.000
Id chunks and…

02:03:05.000 --> 02:03:12.000
Embed. Okay. No.

02:03:12.000 --> 02:03:18.000
So, this is something that we are trying to do. Points.append means inside this list, try to append. Append what?

02:03:18.000 --> 02:03:27.000
So, model.point structure, so try to append the ID. So, we know that for every record, it is going to give me the ID. So, just try to generate the ID.

02:03:27.000 --> 02:03:35.000
Then, uh, try to call embedding.asTypeFlow32 to a list, so this is going to be the vector.

02:03:35.000 --> 02:03:40.000
And then, here I'm trying to store even the meta information. Even last time.

02:03:40.000 --> 02:03:47.000
We have stored our meta-information, and we have stored the vector, uh, separately in those separate files, so here I'm trying to send a payload all together.

02:03:47.000 --> 02:03:54.000
So, execute this one, and now just try to check up points, your points. Just try to check that one.

02:03:54.000 --> 02:03:56.000
So, this is the data which I have ended up creating.

02:03:56.000 --> 02:04:01.000
Out of this point structure. So, this is one data, right? Id 0.

02:04:01.000 --> 02:04:09.000
This is the vector of this data, and then, if you will come this side, right, you will be able to find out even a textual information.

02:04:09.000 --> 02:04:17.000
Let me copy this entire dataset, it's two hues, so I will be able to show you that what is the data that we have prepared.

02:04:17.000 --> 02:04:21.000
So, see, this is the kind of a dataset that we have.

02:04:21.000 --> 02:04:27.000
Technically are prepared, right? This is the kind of a dataset that we have technically prepared over here.

02:04:27.000 --> 02:04:32.000
And this is the dataset that we are going to store it inside my vector databases.

02:04:32.000 --> 02:04:39.000
Along with the textual information, along with this meta information, as a payload, as you can see, right?

02:04:39.000 --> 02:04:44.000
My English data. So along with this payload, along with this meta information.

02:04:44.000 --> 02:04:56.000
So here, the code that we have written is nothing much, by the way. So, we are just preparing our dataset, which is completely visible to you. So once my data set has been prepared, let me ping you this code.

02:04:56.000 --> 02:05:06.000
Right? Once my dataset has been prepared. Now I'm good to, like, send this data to my quadrant, to my cloud database. So here, I can try to call simply.

02:05:06.000 --> 02:05:17.000
Uh, quadrant client. So, QDRNT, quadrant client, and I can try to call absurd, basically, there is a function called as absurd inside a quadrant.

02:05:17.000 --> 02:05:26.000
Databases that these people have written. And you have to mention a collection name. So, in which collection you would like to absorb this data? Because there is a.

02:05:26.000 --> 02:05:30.000
Millions of collections you can try to create, right? Millions of collection for the different purposes.

02:05:30.000 --> 02:05:38.000
So, in which collection, you have to absorb the data, and then… Give me the data. So, here, the point…

02:05:38.000 --> 02:05:42.000
Is equal to points. The data that we have prepared, and now executed.

02:05:42.000 --> 02:05:47.000
So now it is sending all of my data, right? Now it is sending all of my data.

02:05:47.000 --> 02:05:52.000
To the quadrant. Now, if I'll go and check my cloud, right?

02:05:52.000 --> 02:05:58.000
So, here, I am able to find out all the points. So, point number 0.

02:05:58.000 --> 02:06:07.000
Right? So this was my text, by the way. This is basically, like, uh… vector length, and here, in between, so it is able to store the.

02:06:07.000 --> 02:06:15.000
Vector, yeah? So, this is the data. Again, this is the data. All of this data has been stored over here.

02:06:15.000 --> 02:06:23.000
Are you able to get it, guys? Are you able to see it?

02:06:23.000 --> 02:06:40.000
Yep.

02:06:40.000 --> 02:06:51.000
Fine? Is there any option to check the logs? Yeah, everything you will be able to see it. So this is the standard, like, a portal that they have created, so we're…

02:06:51.000 --> 02:07:02.000
They are trying to, like, you know, build more and more features, but even now, so you will be able to see each and everything, and again, so you will be able to, like, see an option called as Find Similar, so if I'm going to click over here.

02:07:02.000 --> 02:07:14.000
Find similar with respect to ID 0. So, with respect to ID, like a 0, there is some, like, similarity we have over here, here, here. So it is… so you will be able to find the similarity even.

02:07:14.000 --> 02:07:19.000
Uh, here itself. And many more things, right? So even with the help of code, you will be able to do it, even without the code.

02:07:19.000 --> 02:07:26.000
You all will be able to do it. So, this is the data that we are able to insert. Very simple.

02:07:26.000 --> 02:07:34.000
Right? So now my dataset is available into a quadrant. Once data set is available into a quadrant, I can even try to do a query.

02:07:34.000 --> 02:07:44.000
Right? So, one is to… Like, send a data, or store our data. Second is to query our data, so I can try to query even from here, right? Even from here, as you can see.

02:07:44.000 --> 02:07:50.000
So, if I'm going to ask, like, who is… Sudhan Shum. So, what is our…

02:07:50.000 --> 02:07:55.000
Let me…

02:07:55.000 --> 02:08:02.000
Okay, so they are not giving you a direct option, they're giving you just an ID or something, but no.

02:08:02.000 --> 02:08:14.000
Who is Sudhan Shu? No, they're not giving you this query kind of option directly, because they don't have an embeddings, right? So, they will not be able to generate the embeddings. Let's do a query from a coding site itself.

02:08:14.000 --> 02:08:21.000
So let's suppose I have a query, right? Query. That, uh, who?

02:08:21.000 --> 02:08:25.000
Is… Fine? So this is the query that I have.

02:08:25.000 --> 02:08:32.000
And, uh, I have to find out a similar kind of a record which is available into my quadrant. The record which I have already sent.

02:08:32.000 --> 02:08:38.000
So again, same process, same procedure we are going to follow. So, first of all, we'll try to.

02:08:38.000 --> 02:08:46.000
Embed this query, uh, by call, calling, uh. Generate embedding. So, here I'm going to pass my query.

02:08:46.000 --> 02:08:52.000
Which is going to give me the embedding.

02:08:52.000 --> 02:08:59.000
Query, so this is going to generate embeddings for me. So, once my embedding has been generated.

02:08:59.000 --> 02:09:04.000
Let me store it somewhere. So, here…

02:09:04.000 --> 02:09:09.000
Query, underscore, response.

02:09:09.000 --> 02:09:21.000
Yeah. Now, so, once my response is available, like, once this particular response is available to me, uh, what I can do is that, that numpy.

02:09:21.000 --> 02:09:27.000
Numpy.array. And, uh, here, so query…

02:09:27.000 --> 02:09:35.000
Response, and dot… As time floor 32, okay?

02:09:35.000 --> 02:09:44.000
So I can try to call it as a… query, vector.

02:09:44.000 --> 02:09:54.000
Anyhow, it was available into a similar format. Okay. So, this is the dataset which is available to me. Now, I can try to call quadrant…

02:09:54.000 --> 02:09:59.000
Qd? Qdrant, quadrant Client.

02:09:59.000 --> 02:10:03.000
Dot search. So there is a search function they have already given to you, right?

02:10:03.000 --> 02:10:06.000
So you can try to, like, do a search operation over here.

02:10:06.000 --> 02:10:11.000
It's not to do a search operation, you have to give a collection name. So, in which collection you are trying to search.

02:10:11.000 --> 02:10:20.000
So, basically, you are trying to search, let's suppose, into a… so the Hanshu story, right? So, that is a collection name, maybe you can try to hardcode it if you want.

02:10:20.000 --> 02:10:34.000
S-u-d-h-n-s-h-u underscore S-T-R-Y. So the answer is story. So, in this one, you are trying to do the… such. And, uh, then you are trying to send this query vector, so this vector you are trying to send it with the search.

02:10:34.000 --> 02:10:41.000
Limit is equals to 5 with payload is equals to true, means whenever it is, like, uh, giving me a response, give me a payload as well.

02:10:41.000 --> 02:10:50.000
Now execute it, and let's see. So, top 5 I'm looking for, right? So, who is Sudhanchu? That was my query.

02:10:50.000 --> 02:11:01.000
Post down to is my query, okay? That's cool. Uh, I'm trying to search inside this collection, Stanshua Story, and the top 5 result. If I'm looking for top 3, I can make it top 3, otherwise top 5.

02:11:01.000 --> 02:11:08.000
This is the data which I'm sending, right? And I'm saying that, that, okay, so just give me a return with a payload. With payload means?

02:11:08.000 --> 02:11:12.000
Your textual information, so that I can read it as a human being, right?

02:11:12.000 --> 02:11:20.000
So, here, it is returning you the very first one as a ID6, then ID4, then ID5, then ID3, then ID1.

02:11:20.000 --> 02:11:25.000
Yeah? Id1. And here, so you will be able to see a cosine similarity score as well.

02:11:25.000 --> 02:11:36.000
So, with respect to my query, who is Sudhanshu? So, basically, this ID6 dataset is more relevant. So, here is a similarity score, 54% of the similarity score.

02:11:36.000 --> 02:11:43.000
And, uh, here is a… line. So, you can just go ahead and you can try to even cross-check this particular one.

02:11:43.000 --> 02:11:50.000
So we are able to store our data, and we are able to even do a top-K search on top of the data.

02:11:50.000 --> 02:11:59.000
Instead of making sense, guys, to all of us? Yeah? The quadrant?

02:11:59.000 --> 02:12:10.000
Yes? So, similar to FAESS. I don't think that there is some differences. Much of differences, right guys?

02:12:10.000 --> 02:12:22.000
Yeah? Right? So, the only matter of fact is that, that I'm trying to use a database, which is available over a cloud. I'm not doing any kind of a setup, by the way, in my local system.

02:12:22.000 --> 02:12:31.000
I'm not going to do any kind of a setup. This database is already available over a cloud, so I have just, like, taken a URL and started sending a data. As simple as that.

02:12:31.000 --> 02:12:39.000
And if I have to do some sort of a query, I will be able to do a query, and someone else is managing my entire database for me.

02:12:39.000 --> 02:12:50.000
We missed a normalization here. No, so here, you don't have to go out with the normalization. Here, it is handling it by default. So, when I have… Created my quadrant instances. I have already written cosine, right?

02:12:50.000 --> 02:12:55.000
So, it will be able to do a math automatically. So here we have written a cosine.

02:12:55.000 --> 02:13:05.000
Right? Distance is cosine. So model distance is cosine, so by default, it will be able to do this vector A dot vector B divided by norm of vector A vector B.

02:13:05.000 --> 02:13:11.000
Which is ideally a formula of cosines. It will be able to do it automatically.

02:13:11.000 --> 02:13:34.000
Yeah? In case of FAISS, so there is a function which is, like, a flat, index flat IP, so it means inner product, right? So, that function has been designed in that way, that, okay, fine, so give me an inner product, and if you would like to normalize it, normalize it.

02:13:34.000 --> 02:13:51.000
I'm noticing my question also, but there was no response. Till now. So, your database is not giving you a response? This is what you're trying to say?

02:13:51.000 --> 02:14:01.000
Yeah. Can we use something else in distances? Yeah. Many thing, actually. Many thing. Uh, we can use it in the distances, which I'll try to reveal in upcoming classes.

02:14:01.000 --> 02:14:05.000
Again, there are multiple ways to store the data. Let's suppose my data record is.

02:14:05.000 --> 02:14:09.000
In millions. So there is a concept called as a cluster.

02:14:09.000 --> 02:14:21.000
Right? So we try to create a cluster, and we try to, you know, give a centroid of the cluster, and then with the help of centroid of the cluster, it will try to optimize the entire search operation. So there are so many things.

02:14:21.000 --> 02:14:26.000
That you will be able to find out, uh, in terms of storing a data, in terms of performing a search with respect to the data.

02:14:26.000 --> 02:14:51.000
Which, we will, like, keep on learning in our upcoming classes. There are so many things to learn. We have just started, right?

02:14:51.000 --> 02:14:56.000
Please paste the line of code. And don't worry, I'm going to send you anyhow the entire code.

02:14:56.000 --> 02:14:59.000
Right, so this is the code, guys, the last line of the code.

02:14:59.000 --> 02:15:10.000
Yeah? Which is, like, used for search. Now, even if you will go and check this, uh, quadrant, uh… official, uh…

02:15:10.000 --> 02:15:25.000
Documentation, right? You will be able to find out the exact same thing.

02:15:25.000 --> 02:15:47.000
Yep. And it's very easy, by the way, right? So they have prepared the documentation, and quite information they have given inside this documentation, that how they are doing it, what they are doing it, right? So, a step-by-step, a step-by-step, you will be able to find out, but it's not different. So now, if you will go ahead with the documentation, uh, you will be able to find out that it's, like.

02:15:47.000 --> 02:15:53.000
Very simple, and I'm able to do it, because now you are in a position where you are able to understand each and everything.

02:15:53.000 --> 02:16:04.000
Yeah? And then CoreLogic, core concept. If you're able to understand, then this documentation is not going to be difficult at all. Not just this one, I would say.

02:16:04.000 --> 02:16:08.000
Doesn't matter which one you are going to pick and choose, everyone will look like the same.

02:16:08.000 --> 02:16:19.000
So, in my upcoming classes, obviously, I'll be talking about a pinecone, I will be talking about a ChromaDB, I will be talking about a Waviate, by the way, and all of these operations around these databases.

02:16:19.000 --> 02:16:28.000
Will try to attach this databases with a complete data cleaning and data preprocessing pipeline, because I believe.

02:16:28.000 --> 02:16:35.000
Somewhere, like, uh… Uh, when we try to learn these things, right? So, somewhere we missed out, uh.

02:16:35.000 --> 02:16:42.000
This entire data pipeline, which is a core thing, which is a core thing for any kind of a project.

02:16:42.000 --> 02:16:55.000
That you are going to build across an industry. So, going forward in my upcoming classes, we'll try to establish the complete pipeline, end-to-end, right, with respect to a different, different variety of the data, so maybe we'll try to ingest some of the data from a S3 bucket.

02:16:55.000 --> 02:17:08.000
Some data will try to consider it from maybe a PDF, basically, PDF file, or maybe a Word document, maybe from an Excel sheet. So, it means variety of the data sources we are going to consider, not just one, right?

02:17:08.000 --> 02:17:17.000
So, variety of the data sources we are going to consider. We'll try to pull those data, build the entire pipeline, clean those data, then convert those data into an embeddings.

02:17:17.000 --> 02:17:22.000
And, uh, we'll try maybe at least 10,000 plus records, right?

02:17:22.000 --> 02:17:38.000
Then, you will be able to see the real game. With 4 or 5 datasets, you will not be able to see the real game. It's just for the learning purposes.

02:17:38.000 --> 02:17:42.000
Sir, does all of this that we studied also comes in data analysis, data science, everything, actually, everything.

02:17:42.000 --> 02:17:51.000
See, there is no, like, a line in between our concepts, right? This doesn't come inside this one or that one.

02:17:51.000 --> 02:17:58.000
When we are the part of industry, right? So, it doesn't matter what we know, what we don't know.

02:17:58.000 --> 02:18:06.000
Now, always, like, a matter of only one thing, that, that whether we are able to solve our current problem in a best possible manner or not.

02:18:06.000 --> 02:18:15.000
So, fine, guys, with this, I'm done with today's class. By the way, yeah? So, next class, we are going to have, not next weekend.

02:18:15.000 --> 02:18:20.000
But next to next weekend, because I have already made an announcement multiple times since last week.

02:18:20.000 --> 02:18:30.000
That, uh, next week on 23rd and 24th, right? So next week, 23rd and 24th, I will be on leave. I have already made an announcement.

02:18:30.000 --> 02:18:35.000
Uh, yesterday. Even a last week, Sunday, I have made an announcement.

02:18:35.000 --> 02:18:51.000
And again, I'm going to make an announcement inside your group. I have already made an announcement, I believe, one time in a group, but yeah, I'll make announcement once again. So, next week, I'm not available. Next weekend, Saturday and Sunday, I'm not available, so there is no class next weekend. You can plan accordingly.

02:18:51.000 --> 02:18:58.000
And, uh, next to next week. So once we are going to be back, we will start from the same place where we are leaving.

02:18:58.000 --> 02:19:02.000
And, uh, by the time I'm going to upload a recording.

02:19:02.000 --> 02:19:08.000
I'm going to send Ivana assignment. So, I'm going to upload an assignment so that you can try to.

02:19:08.000 --> 02:19:12.000
Solve a couple of quotients from those assignments. Some of the use cases, you can try to explore.

02:19:12.000 --> 02:19:23.000
Plus, I'll try to attach some of the research-driven things as well, so that you can go ahead and you can try to do some sort of a research around a learning that we are trying to do.

02:19:23.000 --> 02:19:34.000
Yeah? Fine days? And yes, so we are going to start an interview series. So once I will be back from a vacation, so we are going to start with the.

02:19:34.000 --> 02:19:41.000
Interview series, so anyone who will be interested in an interview series, so please come and join that interview series. It is going to be very much interesting.

02:19:41.000 --> 02:19:45.000
I'm not going to discuss any topic in depth at all.

02:19:45.000 --> 02:19:52.000
It will be a question-answering kind of around, and a lot of storytelling with respect to a project, a lot of storytelling with respect to a resume and interview and whiteboarding.

02:19:52.000 --> 02:20:02.000
By the way, yeah? But no core concept. The way I used to discuss a core concept into my live class lectures, regular lectures, so interview series is not going to happen in that way.

02:20:02.000 --> 02:20:06.000
Interview humans? Only interview pattern they are going to follow, yeah?

02:20:06.000 --> 02:20:12.000
From every aspect. But it is… it will be an amazing one. It will be an amazing one, and all of you are going to like it.

02:20:12.000 --> 02:20:15.000
So that is going to start from, like, 25th of August.

02:20:15.000 --> 02:20:19.000
Yesterday, we have made an announcement for full-stack development as well.

02:20:19.000 --> 02:20:28.000
And, uh, there is a data structure algorithm which we are starting. So, this batch will be taken care by Ramindra. Ramindra is.

02:20:28.000 --> 02:20:38.000
I think I have already discussed in my study's class, I believe. But yeah, let me repeat it once again. So, he's a very nice guy, an IT grad, and then he's going to join Google next month itself. He has already cracked a Google.

02:20:38.000 --> 02:20:45.000
And he's having, like, a lot of experiences in data science, ML, AI, NLP, and again.

02:20:45.000 --> 02:20:50.000
Programming languages and data shell algorithm by default, and system design by default.

02:20:50.000 --> 02:21:01.000
So, he's one of the great person, and he's going to start his class from 14th of September, so we have a month of time. Those who would like to learn data structural algorithm, Python.

02:21:01.000 --> 02:21:11.000
You can go ahead with this, and a full-stack development. So this, we are starting in Hindi. So, lectures we are going to deliver in Hindi as of now.

02:21:11.000 --> 02:21:15.000
Again, so lecture will be delivered by a mentor called as Ajay. Amazing guy.

02:21:15.000 --> 02:21:21.000
Uh, he's having a complete hands-on, he's still working in a project with a different company.

02:21:21.000 --> 02:21:36.000
And as a full-time, and then as a part-time, so he's going to dedicate his Saturday and Sunday with Euron, and he's going to deliver a lecture for entire full-stack BEF development. And that, too, in a modern way, with AI and barcoding and everything.

02:21:36.000 --> 02:21:48.000
So this is something that, uh, he is going to deliver. So if anyone is interested, and that too in Hindi, right? So, this lecture is going to happen in Hindi, so you can come and join this particular lecture.

02:21:48.000 --> 02:21:55.000
That's the reason, so, we recommend everyone as a Euron+. So, if you have a Euron+, we'll keep on launching multiple things, and you can join any of those.

02:21:55.000 --> 02:22:02.000
Live batches. So, just, uh, announcement. For all of you.

02:22:02.000 --> 02:22:10.000
So what he will teach? Who? Ajay or Ramindran?

02:22:10.000 --> 02:22:18.000
Can we pull data from the conference page and create the search tool? Yes, obviously we can do it.

02:22:18.000 --> 02:22:31.000
So, L2 mentioned that you have mentioned today is similar to the L2 that we had in ML algorithm. Uh, formula-wise, it's, uh… Not same, actually.

02:22:31.000 --> 02:22:40.000
Why not English? I mean, like, uh, there are demand from the people, so we have decided to go ahead with one batch in Hindi. We have, like, English in three different batches, right?

02:22:40.000 --> 02:22:45.000
Will in future, we'll try to bring it in English as well.

02:22:45.000 --> 02:22:54.000
Do we have any content or bootcamp on PySpark? Uh, not now, so there is a batch. I'm trying to prepare the content for that one.

02:22:54.000 --> 02:22:57.000
Once it will be done, then it will be available. But as of now.

02:22:57.000 --> 02:23:12.000
No. Can we send me the whole code for the cordant? Yeah, so I'm going to upload this code, uh, once I'm going to upload this recording, right? That will be available in next, like, a 3-4 hour itself.

02:23:12.000 --> 02:23:17.000
Inside your dashboard, so you will be able to download this code, and you will be able to, you know, do the experimentation.

02:23:17.000 --> 02:23:27.000
I'll upload it, I'll upload everything, I'll upload even the assignment for you today.

02:23:27.000 --> 02:23:32.000
Data science ka Hindi bhai ka, so dicte hain, time melega tuajay ka.

02:23:32.000 --> 02:23:43.000
Okay, fine guys, so, uh, let's take a break for 3 to 4 minutes, and after a break, so we are going to start a doubt clearing. So, those who is having any kind of a doubt, those who would like to.

02:23:43.000 --> 02:23:55.000
Share their screen, they can share their screen. And one more thing, guys, so I was, uh, just, just a suggestion, I mean, like, just a, uh… a regular… not a regular discussion, I would say, just some sort of a…

02:23:55.000 --> 02:24:06.000
Out-of-the-box discussion. So, how about starting a young Euron? Young Euron means where we can teach AI and data science and web development and all those technological stuff.

02:24:06.000 --> 02:24:13.000
To our kids. What about that? What is your perspective? I'm just trying to understand the perspective, by the way.

02:24:13.000 --> 02:24:24.000
From the larger audience. Yeah? So what do you feel? I think it's required, because, see, uh, 3-4 year situation was different.

02:24:24.000 --> 02:24:30.000
Right. Uh, since a very, very young age, we were not very much inclined towards a technology or programming and all those things.

02:24:30.000 --> 02:24:39.000
But I believe in an age of AI, so when AI is becoming a mainstream game, even in the schools and colleges, mostly let's talk about schools, right?

02:24:39.000 --> 02:24:53.000
So I have seen that people have started using AI to do multiple things, right? Starting from teachers to students, and again, AI, uh… For example, let's take an example of publicity. So, they have, like, made AI available to everyone.

02:24:53.000 --> 02:25:00.000
Who's having an Airda subscription, right? And Dave for a study, even for India, so they have released a dashboard, so where you can do all the financial analysis.

02:25:00.000 --> 02:25:11.000
Right? Of the data. So I think… AI, uh, even for our kids, it's becoming, uh, mainstream, so keeping that in our mind, I'm thinking of, you know.

02:25:11.000 --> 02:25:22.000
Uh, AI included in your kid's syllabus? Yeah, so, uh, UAE, it's included. China, they have made it mandatory, right? Even for our kids of 6th grade, so they are supposed to learn AI, and they have to do the implementation.

02:25:22.000 --> 02:25:28.000
Usa, so I think a couple of, like, weeks or months back, there was, uh.

02:25:28.000 --> 02:25:32.000
Rule which has been passed, and presidential order which has been passed.

02:25:32.000 --> 02:25:43.000
Where they have made it monetary. But yeah, in India, so they have not made it mandatory, so this is where this eduTech segment comes into a picture. I think we have to do something.

02:25:43.000 --> 02:25:52.000
Hardly teachers of the primary education was about AI. Believe me, go to a college. You will see a different reality. Hardly teachers in a college knows about AI.

02:25:52.000 --> 02:26:01.000
I mean, like, they know about AI, right? But, I mean, like, it's like, uh, on a very different level.

02:26:01.000 --> 02:26:07.000
Situation is not that great, um… Uh, in terms of education.

02:26:07.000 --> 02:26:10.000
Well, I think it's a good idea, right guys? Yeah? We should start a cohort.

02:26:10.000 --> 02:26:19.000
Basically, cohort means live classes. For our kids. Maybe, like, 1 hour, 1 hour, 1 hour, 3 hours a week kind of thing.

02:26:19.000 --> 02:26:41.000
Okay, so that was something… because I was, uh, day 4 yesterday, I was talking to, uh, like, my team, I was discussing with my team about the same thing, that, okay, I think we have a capability, we have a platform, we have everything. So, I think it's the right time for us to, you know, touch that segment as well, because I think it's a need of an R for most of us, even for our kids.

02:26:41.000 --> 02:26:53.000
And other countries are doing it. Even in India, there are some edutag platforms who are trying to do the same thing, right? But there are very less, there are very less. Maybe in next one year, we'll be able to see more and more Avotech platform.

02:26:53.000 --> 02:26:59.000
But I think we have a capability, so… We should do.

02:26:59.000 --> 02:27:08.000
Getting this big data, I can teach everything live, I don't have any kind of an issue. And believe me, I, like, you know, I like live classes.

02:27:08.000 --> 02:27:16.000
More than my recorded one. Uh, because recorded one is a little bit boring, and again, retention… see, even there is a platform called as Udemy, right?

02:27:16.000 --> 02:27:23.000
You will be able to find out every kind of a course, literally every kind of a courses you will be able to find out, and believe me.

02:27:23.000 --> 02:27:32.000
We all have taken some Udemy courses, yes guys? Yeah? We all have spent maybe, like, a 400, 400 to 400 rupees on 5, 10 courses, at least on Udemy.

02:27:32.000 --> 02:27:45.000
Yeah? Right? We all have purchased those courses, and just try to recall that how much percentage of those courses you have completed. Udami itself claims.

02:27:45.000 --> 02:27:51.000
That my retention rate is, like, not more than 2%, 2.5%, or maybe sometimes 1.5%.

02:27:51.000 --> 02:28:05.000
Like in some of the quarter. It simply means that that, uh… You know, uh, see, courses are available, contents are available, even whatever I'm trying to teach in a class, or not just me, maybe some other mentor are trying to teach in the class, right?

02:28:05.000 --> 02:28:15.000
So, they are not trying to innovate something. I'm not trying to innovate something over here, right? For example, today, I discussed about Facebook similarity such, and then Quadrant.

02:28:15.000 --> 02:28:19.000
So, it's not like it's been, like, developed by me or discovered by me.

02:28:19.000 --> 02:28:28.000
It was already there, right? Content was already there. I have structured it, I have just built a story around it, and I'm trying to deliver it, and then you guys are enjoying it, and you guys are able to learn it.

02:28:28.000 --> 02:28:35.000
Now, contents-wise, contents are available. Enough contents are available on YouTube and everywhere, every platform.

02:28:35.000 --> 02:28:44.000
But somewhere, those contents, people are not coming for the content. Somewhere, I believe that education is all about a discipline and determination.

02:28:44.000 --> 02:29:08.000
Right? And this is where I believe this live class comes into a picture. It brings a discipline, right? That, okay, at this point of a time, I have to sit inside the class, and then there will be a mentor, I will go, I will try to do a… to-and-fro kind of a communication, right? So, and that will make your learning more productive, because we all have our courses, multiple platform, right?

02:29:08.000 --> 02:29:17.000
We all know the reality. Even in my childhood, childhood means 7, 8 years back, right, when I was in a very initial stage of my career.

02:29:17.000 --> 02:29:24.000
I used to purchase a lot of courses on Udemy. And believe me, maybe I have purchased 50, 60 courses, I don't know, right?

02:29:24.000 --> 02:29:32.000
And… I don't remember that I have even… I was able to complete one course by 10%.

02:29:32.000 --> 02:29:44.000
I was not able to complete it, right? Because the only thing which was lagging is a discipline, and we are not that disciplined enough. And again, it's not very interesting, right? You're watching just a recording.

02:29:44.000 --> 02:29:57.000
Obviously, like, we can go and watch a movie, because a movie gives us a dopamine hit, it entertain us, so obviously we can sit for 2-hour, three hours, we can finish an entire movie. But, same, you can't apply with the courses, by the way.

02:29:57.000 --> 02:30:02.000
So… I'll keep on launching most of the courses in live mode.

02:30:02.000 --> 02:30:12.000
Going forward. So now I'm planning even for kids. Uh, we are trying to onboard more and more number of mentors. If you would like to, like, you know.

02:30:12.000 --> 02:30:19.000
Contribute as a mentor. If you are good in terms of storytelling, doesn't matter which language, it's fine.

02:30:19.000 --> 02:30:26.000
Even if you're coming from a regional language background, that's okay, but you are supposed to be a good, very good storyteller.

02:30:26.000 --> 02:30:36.000
Right? In depth, right? In depth. So, uh, you can, you can just send me your recording, maybe of one hour, one and a half hour, topic of your choice, that's completely fine.

02:30:36.000 --> 02:30:41.000
And, uh, yeah, so you can join your own, that's completely fine, as a mentor.

02:30:41.000 --> 02:30:47.000
Part-time only, so we are onboarding as of now, just a part-time. Uh, in every segment, right?

02:30:47.000 --> 02:30:54.000
So maybe that is going to open up a new opportunity for you.

02:30:54.000 --> 02:31:00.000
Okay. Okay, fine, guys.

02:31:00.000 --> 02:31:08.000
Let's not take a break. Let's start the route clearing. It's already late. So, I'll not take a break.

02:31:08.000 --> 02:31:17.000
Okay, so I'm just going to lower your hand, and once again, guys, those who is having a doubt, so please raise your hand one by one. Those who would like to share their screen, so ping me in a chat.

02:31:17.000 --> 02:31:25.000
I'll add you as a panelist. I'll call out your name, and you can start asking the questions, yeah?

02:31:25.000 --> 02:31:30.000
So, Ramiz, yeah, go ahead first.

02:31:30.000 --> 02:31:31.000
Hi, hi. Mhm.

02:31:31.000 --> 02:31:38.000
Hi, sir, thanks for taking session today. Uh, so I have a couple of the notes from VictorDB. Uh, so when you offset the data into quadrant, right, and uh…

02:31:38.000 --> 02:31:44.000
Uh, do we receive the data, consume the data, incremental patient, how are we going to manage the data?

02:31:44.000 --> 02:31:45.000
So, for example, today we are appending the data, right? Tomorrow, we can receive some other file.

02:31:45.000 --> 02:31:49.000
Mm-hmm.

02:31:49.000 --> 02:31:50.000
So, how are we going to maintain, uh, periodically? In quadrant database 3.

02:31:50.000 --> 02:31:54.000
Hmm.

02:31:54.000 --> 02:32:02.000
Okay, so basically, you can try to attach a tags with that one, so the payload that you are trying to create, right? So along with the payload, so you can try to send, uh, timestamps.

02:32:02.000 --> 02:32:10.000
Over there, and just a flag, flag, basically. You can try to send one single flag over there, and with the help of flag, you will be able to maintain it.

02:32:10.000 --> 02:32:16.000
Okay, so is there any possibility to overwrite it, uh, to overwrite means, uh.

02:32:16.000 --> 02:32:18.000
Uh, if we get the same kind of data on the CanRoom.

02:32:18.000 --> 02:32:33.000
Yeah, so there is… there is something called a concept of deduplication. So, basically, in case of deduplication, if you're going to enable it, uh, what it will do is, so if there is a duplicate data which is already available, automatically it will try to match it, and then it will try to discard it. It will not try to store it once again.

02:32:33.000 --> 02:32:40.000
So, you can try to go ahead with the deduplication. Even in Facebook AI similarity such, there is a concept called deduplication, which is already available.

02:32:40.000 --> 02:32:41.000
Yes.

02:32:41.000 --> 02:32:48.000
Reduplication. Okay, okay, fine. My second doubt is, uh, you have sold on function iPad, something, right? Can you please explain once again, sir?

02:32:48.000 --> 02:32:49.000
But, uh, I think the specific PIAS CPU, right? Pias notebook.

02:32:49.000 --> 02:32:54.000
Which show?

02:32:54.000 --> 02:32:55.000
Okay, let me share my screen. Which one, which one? Tell me.

02:32:55.000 --> 02:32:59.000
So you have a spline on… the… yeah.

02:32:59.000 --> 02:33:03.000
Ip, internal… internal flat IP. He's talking about.

02:33:03.000 --> 02:33:06.000
Yeah, flat IP, yeah, that functions. Yeah.

02:33:06.000 --> 02:33:07.000
Another product.

02:33:07.000 --> 02:33:14.000
Okay, so flat IP, this one. So this function is coming from… this function is technically coming from this one. This library itself. Facebook has you, like, it says library, someone has created, right?

02:33:14.000 --> 02:33:33.000
And we have done the installation of that. So this function is coming from that. Now, what it does, so basically, it is going to take an inner product. Ip means inner product, by the way. Inner product of what? So, index. Index means what? Index means you're embeddings, right? So, you are trying to flatten the embedding. Flatten means you are trying to convert that into a one-dimension.

02:33:33.000 --> 02:33:39.000
And then you are trying to find out the inner product. So, they have just named it in that way.

02:33:39.000 --> 02:33:41.000
Technically, this is what we are doing, right? See? Uh, let's suppose I'm going to take some data. So, this is my embedding list.

02:33:41.000 --> 02:33:48.000
Mm-hmm.

02:33:48.000 --> 02:33:49.000
Okay.

02:33:49.000 --> 02:33:58.000
This is my… embedding list. Now, how it will try to store it? This is my embedding list. Night. I'll try to extract only one data out of this one.

02:33:58.000 --> 02:33:59.000
So, zero to indexes, right? This one? So I'll try to extract this one. Okay.

02:33:59.000 --> 02:34:07.000
Yes, yes, yes.

02:34:07.000 --> 02:34:08.000
Battlemet?

02:34:08.000 --> 02:34:16.000
So, here, index flat IP. So, yeah, so it is flat IP, and now, so, whenever we are… we'll be having index number 2, so let's suppose we have a…

02:34:16.000 --> 02:34:24.000
Uh, this one, and we have basically this one. This one. Now what I will do, I'll try to do a dot, right? So, numpy dot.

02:34:24.000 --> 02:34:32.000
Dot, and dot product of, basically. Or another product of this.

02:34:32.000 --> 02:34:35.000
And this we will be… we will try to perform, right?

02:34:35.000 --> 02:34:37.000
Yes.

02:34:37.000 --> 02:34:43.000
This is what it means. In this flat IP. So they have just created as a function.

02:34:43.000 --> 02:34:49.000
Simple, right? And they're saying that, okay, fine, so whenever you're trying to create that, uh, indexes.

02:34:49.000 --> 02:34:56.000
So, your index size should be 1536, because I know that my index size is going to be 1536, right?

02:34:56.000 --> 02:34:57.000
If I'm… and if I'm going to use some different model, then my index size will be different.

02:34:57.000 --> 02:35:02.000
Yeah, yeah, great truth.

02:35:02.000 --> 02:35:08.000
Yeah, as of now, I'm trying to use this OpenAI model, right? Small case model I'm trying to use, and what is a vector size it is going to return me?

02:35:08.000 --> 02:35:16.000
1536, so that's the region, so I have given that. Okay, fine, so length of any vector is going to be 1536. For example, yesterday I have shown you a Quen model.

02:35:16.000 --> 02:35:23.000
If you remember. Now. Uh, Hugging Face. So, yesterday I've shown you, basically, this Quen model.

02:35:23.000 --> 02:35:32.000
And for Quen model, a different, different, like, parameters, QU. Or I can search by EM bidding. So, instead of we talked about this one. Now.

02:35:32.000 --> 02:35:36.000
So here, our dimension was what? 1024, right? If I'm going to use this model, dimension was what? 25360?

02:35:36.000 --> 02:35:41.000
Is…

02:35:41.000 --> 02:35:44.000
If I'm going to use this model, 4 billion parameter dimension is this one.

02:35:44.000 --> 02:35:53.000
So if I'm going to use, let's suppose, this model, right? So, whatever vector it is going to produce, what will be the size of that vector? So, size of that vector is going to be 1524, 1024.

02:35:53.000 --> 02:35:54.000
Yeah, corrective.

02:35:54.000 --> 02:36:00.000
Yeah, so, same. You can try to… so I have hard-coded this value, you can try to even.

02:36:00.000 --> 02:36:06.000
Call this vector, right, you can even try to call this vector, one of these vectors, and then you can try to check.

02:36:06.000 --> 02:36:10.000
So, I can try to even. Check in this way, right? So this .shaped… shape is what? 1536. I can try to pass this data over there.

02:36:10.000 --> 02:36:16.000
Mm-hmm.

02:36:16.000 --> 02:36:25.000
Okay, okay, sure. Yeah, yeah, okay. So then, uh, yeah, actually, my next note is that, right, when we are.

02:36:25.000 --> 02:36:31.000
So, interacting with LLM, right? Maybe the security base is the drawback, potential impact.

02:36:31.000 --> 02:36:42.000
So, I think I have seen some video, but when we use the rack technique, it might have situated, but how do we say it is really secure?

02:36:42.000 --> 02:36:45.000
If you are going to use the right technique. You tell them.

02:36:45.000 --> 02:36:53.000
Oh, see, security layer will not be guaranteed by your, uh, like, uh, you know, execution layer or wherever you're trying to create the, like, a rack, right?

02:36:53.000 --> 02:37:02.000
So, it depends upon, first of all, authorization, it depends upon how you are trying to secure your private data set, means encryption, by the way.

02:37:02.000 --> 02:37:07.000
Plus, on a hardware layer on our application layer, how you're trying to, like, you know, keep the security.

02:37:07.000 --> 02:37:22.000
So, security is not just a matter of RAG. Yeah, so why people are talking about it inside the industry? Because.

02:37:22.000 --> 02:37:23.000
Miss… Okay.

02:37:23.000 --> 02:37:34.000
Uh, let's suppose, uh, you are trying to build an ROG application. Now, what you do, by the way, so you try to take your private data, you try to convert that into embeddings, and then you try to store it into some of the databases. For example, we have stored it into these databases, right? Quadrant databases today itself, right? In this one. Or maybe into our Facebook ASMI research databases.

02:37:34.000 --> 02:37:43.000
Now, let's suppose if quadrant database is not providing you a security, if somewhere there is a leak in their login or in their data encryption itself, right?

02:37:43.000 --> 02:37:48.000
The entire set of the data that you have uploaded over here will be compromised.

02:37:48.000 --> 02:37:49.000
So, security is not like you will try to build it with RAG.

02:37:49.000 --> 02:37:53.000
Mm-hmm. Okay.

02:37:53.000 --> 02:37:57.000
On top of that, you will have to build a layer of the security.

02:37:57.000 --> 02:38:00.000
This is what we do with all the applications.

02:38:00.000 --> 02:38:04.000
But anyhow, the data is going to diverse, right? The traversal from…

02:38:04.000 --> 02:38:13.000
No, for example, no, no. For example, let's suppose I'm using a Facebook personality search, right? Let's suppose I'm not using any cloud-based, this one. I'm using this one, right?

02:38:13.000 --> 02:38:22.000
And let's suppose I have basically hosted my Facebook AI similarity search on my EC2 instances.

02:38:22.000 --> 02:38:23.000
Okay.

02:38:23.000 --> 02:38:34.000
On my own Institute instances. Yeah? In that case, my instance is mine, the entire machine is mine, and if I'm going to upload the data, if I'm going to embed the data, no one will be having an access, unless and until I'm not going to give an access, unless and until.

02:38:34.000 --> 02:38:37.000
I'm not going to create the bridge. Over there.

02:38:37.000 --> 02:38:43.000
Yeah, but anyhow, right? Anyhow, this is the numerical thing, but if we want to repent the statement.

02:38:43.000 --> 02:38:51.000
Can we go to get the help from LLM, right? By the time the… what our data… decide data is going to traversal from, uh, VectorDB to.

02:38:51.000 --> 02:38:54.000
Uh, LLM model, sir. There is some significant drawback, right, for the security base.

02:38:54.000 --> 02:39:02.000
No, no, no, again, again. So there are many open source models which is available. Open source LLMs which is available, right? A good one, I would say, right?

02:39:02.000 --> 02:39:03.000
Well, yeah.

02:39:03.000 --> 02:39:09.000
So, no one is… no one is stopping you, by the way. No one is stopping you to host your LLM, right? Host your LLM.

02:39:09.000 --> 02:39:10.000
Mm-hmm.

02:39:10.000 --> 02:39:16.000
Plus, host your own data, which is available into an embedding format, right? Which is available into a vector format.

02:39:16.000 --> 02:39:23.000
On your own machine, so maybe EC2 or maybe in a bare metal, or in any other machine.

02:39:23.000 --> 02:39:24.000
Okay.

02:39:24.000 --> 02:39:32.000
So, let's suppose each LLM is available in my server, even data is available in my server, so I'm not sending any of my data to the LLM, so how there will be a data breach at all?

02:39:32.000 --> 02:39:37.000
And this is also, I have shown it to you. So, see, uh, I don't know, like, whether you have seen this video or not.

02:39:37.000 --> 02:39:38.000
Um, let me open it up. So, I think one, two days back.

02:39:38.000 --> 02:39:59.000
Yeah. So you want… so you want to be insult the LLM model in our local, but does it need some internet search or something, right? Audible?

02:39:59.000 --> 02:40:00.000
Yeah.

02:40:00.000 --> 02:40:09.000
Hmm. No, not at all. So, not local. Maybe you can add to install it into your own server. So, your own GPT API, yeah. So if you'll go through this video, right? So, I have already provided even a documentation, and in this entire video, I have shown that, that how you can try to take a big LLM, big LLM is a 20 billion parameter model. Chatgpt model I'm talking about, right?

02:40:09.000 --> 02:40:10.000
And how you will be able to host this model and expose it as an API. See? And with the help of curl.

02:40:10.000 --> 02:40:16.000
Yeah.

02:40:16.000 --> 02:40:17.000
Right? With the help of curl, how you will be able to hit it. So, and that too, I'm doing it, this inferencing on a GPU, by the way.

02:40:17.000 --> 02:40:22.000
Mm-hmm.

02:40:22.000 --> 02:40:25.000
And I've already provided a documentation for that. Yeah? So how you will be able to… how you will be able to, you know, do the setup, and this is how hosting happens, basically.

02:40:25.000 --> 02:40:31.000
Yeah, yeah.

02:40:31.000 --> 02:40:39.000
For any models, for any model inferencing. So, let's suppose I'm hosting this model on my instance. Now, there is no breach.

02:40:39.000 --> 02:40:51.000
Yeah, but yeah, I understood, totally agree. It is a 20 billion parameter. Whatever the knowledge does it have, it can… do it. But if, suppose if I'm going to ask question, uh, for example, so what is a two-day information? Is there any today information?

02:40:51.000 --> 02:40:52.000
Hmm. Hmm.

02:40:52.000 --> 02:41:00.000
Anyhow, there is some network traffic over there, right? For example, studio, what news is going on today? Can you get it from some Google?

02:41:00.000 --> 02:41:04.000
So, anyhow, anyhow, those real-time search operations that you are talking about, right? So, those will not be handled by your learned model.

02:41:04.000 --> 02:41:08.000
Yeah.

02:41:08.000 --> 02:41:14.000
These models are basically something which has learned till some duration, or till some date, right?

02:41:14.000 --> 02:41:15.000
Yeah.

02:41:15.000 --> 02:41:22.000
So, anyhow, that will be not answered. So, what you do is that, that you try to append a real-time search API, for example, a server API, right? I'm going to append it.

02:41:22.000 --> 02:41:23.000
Mm-hmm.

02:41:23.000 --> 02:41:37.000
And whatever Serpa API is going to return, I just used to give to this model. This model tried to rephrase it, and then give it to me as a, you know, polished answer. So, you have to integrate a Serper API, and there will not be data breach in any cases.

02:41:37.000 --> 02:41:38.000
Yeah, yeah, kind of… yeah.

02:41:38.000 --> 02:41:51.000
Right. So, you are sending some different, you know, question to the Surfer API. Serper API is trying to bring those answers from the internet, and then… you are trying to do some sort of a rephrasing with the help of model, which you have hosted on your platform.

02:41:51.000 --> 02:41:58.000
Well, Coco, yeah, so in that case, it's my own platform. If I ask any web-related question, it does not return, right?

02:41:58.000 --> 02:41:59.000
No, so obviously, like, it won't be having a real-time search interfa functionalities.

02:41:59.000 --> 02:42:11.000
Maybe whatever information? Yeah. All right, got it all. But in the… especially the department, the chat GPT at all, it is going to interfere with the SARP API and Wikipedia or some other thing.

02:42:11.000 --> 02:42:12.000
Is it also positive? Yeah.

02:42:12.000 --> 02:42:19.000
Exactly, exactly. So they have a… they have a… even in a URI, if you will go and check, right, so if you will go to a uran.

02:42:19.000 --> 02:42:30.000
Uh, EURON. And here we have done the same thing. So, here, if you'll go to Yuri, and let's suppose if you are going to switch on your web search.

02:42:30.000 --> 02:42:31.000
Mm-hmm. Yeah.

02:42:31.000 --> 02:42:40.000
So we have given you this option, Web Search Write. This one. So if you're going to switch on this web search option, by default it will be disabled, and it is… if I'm going to ask me, tell me the, uh, weather or news.

02:42:40.000 --> 02:42:49.000
From Bangalore, right? As I stay in Bangalore. Now, it will hit… so I'm using GPT Nano 5, or any model I'm going to use, it doesn't matter at all, right?

02:42:49.000 --> 02:42:50.000
So what it will do, it is trying to call a server API, it is trying to see search websites.

02:42:50.000 --> 02:42:55.000
Yeah.

02:42:55.000 --> 02:43:01.000
Right? It is trying to search all of these websites, and now it will try to, like, bring a data for me sometime.

02:43:01.000 --> 02:43:09.000
Yeah, yeah. Okay, got it. Sir, and the final one… yeah, I understood.

02:43:09.000 --> 02:43:10.000
Hmm.

02:43:10.000 --> 02:43:15.000
Yeah, see, so now… see, our latest news, today's news itself, it is able to… Uh, like a search, and if I'm going to, like, a click, I will be able to even verify the date, time, and everything, right? So…

02:43:15.000 --> 02:43:22.000
This is the content which I'm able to get it. So here, this is not the model which is responding back.

02:43:22.000 --> 02:43:23.000
Hmm.

02:43:23.000 --> 02:43:29.000
Right? The model which is responding back to me is basically my real-time API. What this model is trying to do? This model is trying to format the data.

02:43:29.000 --> 02:43:31.000
For me. And then show it to me in a human-readable format, basically.

02:43:31.000 --> 02:43:38.000
Okay. Yeah. Yes, is there a pending completely, that is.

02:43:38.000 --> 02:43:39.000
Yeah.

02:43:39.000 --> 02:43:43.000
And, you know, sir, and one more final question, right, is a genetic real question. Uh, so, uh, we… I have already talked about the pagination, right? We have the 10K rows over there.

02:43:43.000 --> 02:43:49.000
Mm-hmm.

02:43:49.000 --> 02:43:53.000
What happened in my scenario? When we iterate one by one.

02:43:53.000 --> 02:43:59.000
Uh, but each iteration, we are getting one API call and extracting the thousand rows, 1K rows.

02:43:59.000 --> 02:44:00.000
Hmm. Hmm.

02:44:00.000 --> 02:44:08.000
But based on the query parameter values. So, in this case, what happened over there? The call or 6th call, we got the timeout issue.

02:44:08.000 --> 02:44:14.000
Eap timeout issue, we are placing an error like Pilot 3.

02:44:14.000 --> 02:44:15.000
Uh, so, what might be the reason? Because let us check with our server team as well. So, our server team as well.

02:44:15.000 --> 02:44:20.000
Okay.

02:44:20.000 --> 02:44:24.000
But they told that there is… the lock is not captured over there.

02:44:24.000 --> 02:44:28.000
The Pindrata, but in our instance, we are getting that kind of error.

02:44:28.000 --> 02:44:37.000
So, is there any, uh, any reasons why, uh, server doesn't have any, uh, log capture on the pipe node 3K, sir?

02:44:37.000 --> 02:44:48.000
Oh, law, capture, maybe you can try to do one thing, you can try to… maybe you are… you're, like… When you're doing a pagination, so you are trying to set thousand as a, like, in one go.

02:44:48.000 --> 02:44:53.000
1000th as a response, right? So it means 1000 recorders should be able to fetch it.

02:44:53.000 --> 02:45:01.000
No, Paramo, page initial, like, beginning of the Facebook data. Facebook, right? But I'm not sure how they are controlling the pagination at all.

02:45:01.000 --> 02:45:10.000
Uh, we are calling that URL and extorting the data. Maybe, uh, overall, it can return, uh, it can return the 10K rows or something.

02:45:10.000 --> 02:45:16.000
But one business. For example, so let us go to search with one yellow B. Yellow B means it's a line of business.

02:45:16.000 --> 02:45:21.000
If you are going to get the particular web data, it can extort the 10K rho or 20K rows.

02:45:21.000 --> 02:45:30.000
But in our instance, we are also iterating one by one. For each iteration, we are going to extract the 1000 rows, sir.

02:45:30.000 --> 02:45:31.000
No, just, just keep it, keep it minimum. Maybe keep it, like, 100, so that it will not be…

02:45:31.000 --> 02:45:44.000
So, what… Yeah, we tried, we tried. 500 as well, we tried with that. What happened? I mean, on the 5th or 6th iteration, continuously, when we… it is going to keep the API call multiple times.

02:45:44.000 --> 02:45:50.000
Uh, put our 60 times, some time is failure. It's not for regularly. Sometime, uh, we got a failure.

02:45:50.000 --> 02:45:55.000
Maybe in the morning time and the rush time is getting failure, sir.

02:45:55.000 --> 02:45:56.000
But to the… yeah.

02:45:56.000 --> 02:46:09.000
Ideally, it should not be, maybe, like, because if you are reducing the number of the record, it should not… Timeout simply means that system is… your client is trying to, like, send a request to the server, and server is not able to respond back. That is the…

02:46:09.000 --> 02:46:10.000
Kind of… Oh, yeah.

02:46:10.000 --> 02:46:17.000
Very simple meaning of a timeout that we all understand, right? And it happens, so if there will be a bottleneck in terms of a network IO means in the.

02:46:17.000 --> 02:46:23.000
Stipulated time period, if it is not able to respond back. So maybe you can ask your, like, backend team to increase your.

02:46:23.000 --> 02:46:28.000
Timeout limit, by the way, because that is something which we try to set custom, right? So, maybe they can try to, like, reset their maximum tries.

02:46:28.000 --> 02:46:32.000
Mm-hmm.

02:46:32.000 --> 02:46:34.000
So that is, again, another parameter that we try to set every time.

02:46:34.000 --> 02:46:39.000
Yeah, yeah, we, we, yeah, we made the customized code retry option, right? For every 10 seconds.

02:46:39.000 --> 02:46:49.000
We try with the three times, you know, we put some while loop or something, and we retry the three times, even though… but sometimes it succeeded, sometimes it's failure again.

02:46:49.000 --> 02:46:52.000
But it's not getting the permanent solution that… So I'm not sure what is a problem.

02:46:52.000 --> 02:47:09.000
That is… that is… that is… yeah, so maybe then I'll have to look into the code, because that is… these are the possible solution, right? So we try to… and from the backend, not from your side. So, from the back end, so if they have implemented maximum tries, and then, like, uh, per timeout, what should be the timeline, or for total timeout, so what should be the timeline?

02:47:09.000 --> 02:47:16.000
And then a data control, means number of data that we are trying to fetch. These are the way by which we can solve it.

02:47:16.000 --> 02:47:18.000
Otherwise, we'll have to look into the code, really. And plus, your server capacity.

02:47:18.000 --> 02:47:22.000
Yeah, yeah.

02:47:22.000 --> 02:47:28.000
The server that you're trying to hit, right, so whether this server is capable enough to handle these things or not, that also matters, right?

02:47:28.000 --> 02:47:29.000
Yeah, cut it…

02:47:29.000 --> 02:47:39.000
Because if server itself is creating a… your hardware itself is creating a bottleneck, then there will be a… because timeout simply means that I'm not able to respond back, and I'm… why I'm not able to respond back? Maybe I'm not able to compute.

02:47:39.000 --> 02:47:41.000
Mm-hmm, you are not able to extract it, yes, correct. The specific time.

02:47:41.000 --> 02:47:51.000
We are not able to compute, we are not able to extract it right. There can be a n number of things. So, again, it's not just about the code, I would say. Maybe we'll have to look into the hardware configuration as well.

02:47:51.000 --> 02:47:56.000
And the load on that hardware configuration.

02:47:56.000 --> 02:47:57.000
Yeah.

02:47:57.000 --> 02:48:03.000
Okay, okay, yeah, sounds good, sir. But it sounds interesting, but we made a call, you know, with the Facebook team as well, server team.

02:48:03.000 --> 02:48:04.000
Mm-hmm.

02:48:04.000 --> 02:48:16.000
Support team as well, but they convinced us we didn't get any, uh, lock at our end, so maybe we are going to drill some further justification on Monday, that's… Yeah, let us convey the different ways, and we are dealing with the problems.

02:48:16.000 --> 02:48:26.000
Yeah, yeah, thanks, thanks. In between, Ravi, please go ahead with the question. Second one is Navoneeth.

02:48:26.000 --> 02:48:29.000
Yeah, sir, I want to share the screen.

02:48:29.000 --> 02:48:39.000
Yeah, allow. So yeah, first, Ravi, you can go ahead with the question, then Navneet, you can go ahead with the question.

02:48:39.000 --> 02:48:40.000
Yeah, Ravi, what is your question? Okay. Mm-hmm, okay.

02:48:40.000 --> 02:48:49.000
So, regarding creation of an environment, I have a doubt. So I want to share a screen. So, here I'm not getting an option to share this.

02:48:49.000 --> 02:48:55.000
Sure, sure, I'm promoting you, Ravi. You will not get an option. Yeah, Namnee, what is your question? Would you like to share the screen?

02:48:55.000 --> 02:48:56.000
Ah, yes, yes.

02:48:56.000 --> 02:49:04.000
Okay, fine. So, I'm allowing you to share the screen, and Uday, what is your question? Would you like to share the screen? Anyone, guys, who would like to share their screen?

02:49:04.000 --> 02:49:05.000
I'll add you as a panelist. Okay, okay.

02:49:05.000 --> 02:49:06.000
Yeah, yeah, I want to… I want to share my screen. I… I have fixed my problem.

02:49:06.000 --> 02:49:07.000
Nathan… naser question.

02:49:07.000 --> 02:49:10.000
Yeah, I would like to.

02:49:10.000 --> 02:49:11.000
But just one, uh, doubt I have, just why I was facing issues.

02:49:11.000 --> 02:49:16.000
Okay, okay. While not an issue? Share your screen, please, yeah. Ranjeet, would you like to share the screen?

02:49:16.000 --> 02:49:17.000
Yeah, I would like to share it.

02:49:17.000 --> 02:49:21.000
Share screen ni kann mojo.

02:49:21.000 --> 02:49:23.000
Okay, what they would tell you? Oh.

02:49:23.000 --> 02:49:27.000
Uh, sir, actually, uh, your own plus may upgrade the other man.

02:49:27.000 --> 02:49:28.000
Uh, what barrier containers can there be pelleto? I'd like to thank you, both Puria.

02:49:28.000 --> 02:49:33.000
Uh-huh. Thank you, thank you.

02:49:33.000 --> 02:49:38.000
So, MCP wallah jo hai po me peraatabi aapne jo deliver.

02:49:38.000 --> 02:49:40.000
Mm-hmm, mm-hmm.

02:49:40.000 --> 02:49:53.000
Sir, uh, Hamari use case may MCP just mujay, uh, patakar nata ki keisterike Sam implement kasakt hain.

02:49:53.000 --> 02:49:54.000
Hmm.

02:49:54.000 --> 02:50:02.000
Chatbot ganaya hai, aur rah hum look goosekar hain. It's no different, different service now hug a…

02:50:02.000 --> 02:50:03.000
Hmm, hmm. Hmm. Tiga, Tiger?

02:50:03.000 --> 02:50:13.000
Hr-related policies, Si karke humne integrate koi sa. Elastic database use K aware.

02:50:13.000 --> 02:50:14.000
Tiger, too good?

02:50:14.000 --> 02:50:25.000
So, uh, Ishme. Mcpu.

02:50:25.000 --> 02:50:26.000
Hmm, hmm.

02:50:26.000 --> 02:50:33.000
Cloudier, or OpenAI mevon nicha dikhne lakhtah maraara agent? Ah.

02:50:33.000 --> 02:50:42.000
Karti hai au firu. Workflow help.

02:50:42.000 --> 02:50:43.000
Hmm, hmm.

02:50:43.000 --> 02:50:47.000
Wo implement.

02:50:47.000 --> 02:51:01.000
Hello, MCP Ektona Beach Manai Baholk creditworth MCP ga. I'll tell you the reality, basically. What reality about MCP. So, nowadays, uh, people are talking about MCPs.

02:51:01.000 --> 02:51:11.000
A2a protocol, A2A protocol, A2A protocol.

02:51:11.000 --> 02:51:41.000
You can give an access to of any application to this MCP, and MCP is ayaga, jazab cold liho, jazap logic lipoge.

02:51:41.000 --> 02:51:42.000
Hmm.

02:51:42.000 --> 02:51:49.000
Technically, agent bhai karte hai. Mcp protocol.

02:51:49.000 --> 02:51:57.000
And, uh, ye Babal utah kuch…

02:51:57.000 --> 02:52:07.000
Influencer Baha Jada Huchay hai. Right. Uh, our influencer will be rather hi, basically, woe category hai basically, just go kuch fare ini parta hai ki.

02:52:07.000 --> 02:52:17.000
Likes and views arang gini aare. All likes and reviews out there, Neurology, but… hai.

02:52:17.000 --> 02:52:46.000
Mcp ki uten hi ka hani. Mcp katham. Back-to-back sublagoon MCB port open kar dia. Toh rator aapko de mole legaka, ki har ek tool. Karsa ho, sab kendar wo MCP wala, ek functionality.

02:52:46.000 --> 02:52:47.000
Indeed.

02:52:47.000 --> 02:52:56.000
He is like implementation the under, yam lo karne. Agent-to-agent Baj, agent matlab kehab home agent pra hangy aaphlog aapko apo saunya, it's nothing but just a function. Check, a function with a LLM capability, that's it.

02:52:56.000 --> 02:53:15.000
Well, right? Actually, masakush bin nahi hai. Toh, MCP bhi Raturat aya, aturat geya, now those influences are not even talking about MCPs, and agar aap ja humseho ghana, ki bahi MCP karin batadho.

02:53:15.000 --> 02:53:33.000
So, that is the reality.

02:53:33.000 --> 02:53:40.000
Wo video to banana yun ko. Okay, but… dig it.

02:53:40.000 --> 02:53:49.000
But over 11, or 11, CJ haem? Your core fundamentals, eh.

02:53:49.000 --> 02:53:58.000
Do you think? Mcp. But actually, my fundamentals.

02:53:58.000 --> 02:54:07.000
But yes, because of the… so much of accessibility of social media, right, so much of social awareness.

02:54:07.000 --> 02:54:09.000
Poison ka kam biker. Right.

02:54:09.000 --> 02:54:14.000
Also, actually, client C requirement ID ki, uh, isku spell to… school presentation.

02:54:14.000 --> 02:54:19.000
Client… client… client…

02:54:19.000 --> 02:54:23.000
Agar…

02:54:23.000 --> 02:54:26.000
Seh ye gay.

02:54:26.000 --> 02:54:38.000
Rupin… Belisi ko.

02:54:38.000 --> 02:54:52.000
I'll take another AI application dali huh? Usy mein seh application ut halo, aur wahapara de Khai humanki jo MCP inspector hai. Waha parek toolko aap kasi exposed karoge, aur ne it to fira aap cloude kendar kasi aapkun ko expose kar, okay? Taki?

02:54:52.000 --> 02:55:01.000
No, Cloudy LLM access karta hai, right. Ab MCP banakaram kush tool dal rahin. Kuchy bhi calculation akuj bhi logic karne ke liye.

02:55:01.000 --> 02:55:08.000
Custom tool banayak ya. Right. Or, data laga, and then wohage LLM keyword.

02:55:08.000 --> 02:55:12.000
Gotcha. Okay.

02:55:12.000 --> 02:55:17.000
Something like that. Mcb, thus example banakit dikhay hui aapko, us MCP wallet tutorial kendar, usme MCP inspector bhi, usme cloud A. Dono ka integration dihya.

02:55:17.000 --> 02:55:23.000
Huh.

02:55:23.000 --> 02:55:24.000
Right. Sir, eh?

02:55:24.000 --> 02:55:27.000
Right. This audio project, man. Pura could basically be the other way?

02:55:27.000 --> 02:55:32.000
Thank you, Bhutanatha. Jisei Hamara ape jo hamara application hai. Uh, tarike seh haiki…

02:55:32.000 --> 02:55:40.000
Hmm.

02:55:40.000 --> 02:55:41.000
Hmm.

02:55:41.000 --> 02:55:48.000
Ki jaise how to… what are the HR policies for XYZ company?

02:55:48.000 --> 02:56:03.000
Huh, huh. Apka aapka karughe, apig function banaoge, just come to tool both hai, MCP tool, bolte, right? Apek function lihoge, jahapar aapki jo HR policies hogi.

02:56:03.000 --> 02:56:07.000
Okay? Now, let's suppose ki aapka ek chatbot kudka banner hua.

02:56:07.000 --> 02:56:17.000
Right.

02:56:17.000 --> 02:56:18.000
Like…

02:56:18.000 --> 02:56:24.000
Ap API ligtoona. Right. Url aki woke hot hai, abo URL specific ho, mat lavo neutral hoga. Koi bhi programming language ko, consume kar saktah hai.

02:56:24.000 --> 02:56:25.000
Right. G.

02:56:25.000 --> 02:56:33.000
To get MCPB CA protocol here. Simple. Mcp tool may convert kar dia, toh job software, jobhi tool.

02:56:33.000 --> 02:56:39.000
Mcp endpoint is, yeah, wahapara kolkar sakte ho. This is what it means.

02:56:39.000 --> 02:56:46.000
Actually, okay. Okay, okay.

02:56:46.000 --> 02:56:47.000
No, oh.

02:56:47.000 --> 02:56:58.000
Tks or Macbat tray karuna, Ikar questionta sar mira.

02:56:58.000 --> 02:56:59.000
Hmm. Hmm, hmm.

02:56:59.000 --> 02:57:06.000
Knn wo use kathai? Part memory ranking vague ragar ke… Of course, hai.

02:57:06.000 --> 02:57:13.000
Similar use cases as well pay. Both are categories, joking, similar type ki hain.

02:57:13.000 --> 02:57:14.000
To have already relevancy jo hai wo… keyword-based hogel.

02:57:14.000 --> 02:57:18.000
Hmm, hmm.

02:57:18.000 --> 02:57:19.000
Hmm.

02:57:19.000 --> 02:57:23.000
Hai. The room booking hot yogi amare aap mein.

02:57:23.000 --> 02:57:27.000
Hmm. Mm-hmm.

02:57:27.000 --> 02:57:29.000
A member of how to book a seat. I'm searching for a…

02:57:29.000 --> 02:57:32.000
Hmm.

02:57:32.000 --> 02:57:40.000
Room booking ni lichunga, jab ki how to book a seat for myself is also… sentimentally, Zoom booking mehi?

02:57:40.000 --> 02:57:49.000
Elastics has by default ka karta hai, keyword to keyword karta hai woh. Think hai.

02:57:49.000 --> 02:57:53.000
Elastic, right? Now, embedding usi ke uppartaina, ki embedding jo habapura kapura match kaweit ni karta hai.

02:57:53.000 --> 02:58:00.000
Right.

02:58:00.000 --> 02:58:06.000
Right? Java aapane chode se data ako booth high dimension medall di ya. High Dimension Aldiya.

02:58:06.000 --> 02:58:17.000
It will never wait for a complete. Identification.

02:58:17.000 --> 02:58:18.000
Hmm.

02:58:18.000 --> 02:58:25.000
Scale ho gi hai. Toho 1536.

02:58:25.000 --> 02:58:35.000
Hmm.

02:58:35.000 --> 02:58:36.000
Right.

02:58:36.000 --> 02:58:43.000
Ek dida again. Toh, obviously, jab dimension mere ballah hoga.

02:58:43.000 --> 02:58:49.000
Don't magical anime, or accuracy of magical anime, jada me kawasani hoagi.

02:58:49.000 --> 02:58:50.000
Great.

02:58:50.000 --> 02:59:03.000
That's a fundamental, right? Toh, obviously, they are shifting towards this embedding.

02:59:03.000 --> 02:59:11.000
Uh, sir, Abhi Matlam… Uh, may you get it? How to book a room johy?

02:59:11.000 --> 02:59:12.000
Hmm.

02:59:12.000 --> 02:59:16.000
Or, uh, Hamarajo document database may put a rag mein. Meeting room meeting booking, ase karke guch hai.

02:59:16.000 --> 02:59:21.000
Mm-hmm, hmm. Hmm, hmm.

02:59:21.000 --> 02:59:29.000
But how to book a seat be… sentiment to weak classmates Anarchy. We document Anarchy and Maripas.

02:59:29.000 --> 02:59:30.000
Hmm, hmm.

02:59:30.000 --> 02:59:39.000
So, semantic contextual understanding, Joanna. Agar mein DevOps training muja search karna hai.

02:59:39.000 --> 02:59:40.000
Mm-hmm, hmm. Hmm.

02:59:40.000 --> 02:59:45.000
The word keyword voidal hai room meeting wala hai, tos mein room ya meeting honahi chai. Jab yeh do word utte hab bekind me, k, and then use kota us mein.

02:59:45.000 --> 02:59:52.000
Hmm. Hmm.

02:59:52.000 --> 02:59:53.000
Hmm, hmm. Mm, hmm.

02:59:53.000 --> 02:59:58.000
So, Abhar user room meeting to naidale. Kara.

02:59:58.000 --> 02:59:59.000
Mm-hmm.

02:59:59.000 --> 03:00:09.000
Contextual donke sentiment jo hai contextual ya semantic. Understanding the Bultne Shad.

03:00:09.000 --> 03:00:10.000
Hmm, hmm.

03:00:10.000 --> 03:00:17.000
Wordke semantics samach ke… room meeting…

03:00:17.000 --> 03:00:18.000
Huh, huh, huh. Hmm.

03:00:18.000 --> 03:00:26.000
Booking wala yana jihada. Relevant document. Toh, is my relevance, bohot cases mein hotahay ki agar wohi keyword nahi dalah hai jo rag document mein hai.

03:00:26.000 --> 03:00:28.000
Mm-hmm.

03:00:28.000 --> 03:00:39.000
Semantics here, auske, contexto ini, wahap relevancy sa bhot ka mujapi.

03:00:39.000 --> 03:00:40.000
Hmm.

03:00:40.000 --> 03:00:46.000
But it's a keyword, huh? What other sentiment, uh, AK je se hoagar, balay keyword amare ragmen nabi ho.

03:00:46.000 --> 03:00:56.000
But agar sentiment wahi pariho, to… will document relevant sub-super VEI, toh iski contexto semantic understanding hum kesema hai, kar.

03:00:56.000 --> 03:00:58.000
Problem, Colossa.

03:00:58.000 --> 03:01:03.000
Uh, Eric, we're gonna talk about that thing. Uh, just domain dije.

03:01:03.000 --> 03:01:09.000
Mm-hmm.

03:01:09.000 --> 03:01:39.000
Yes, sir, major problem haemat club.

03:02:37.000 --> 03:03:07.000
Um…

03:03:29.000 --> 03:03:42.000
When we are sending this request, basically. So, egg solution jo humblogone is ko initial tray kyata with some of our use cases. Johanno build karne kosis karate.

03:03:42.000 --> 03:03:51.000
Model ki pass.

03:03:51.000 --> 03:03:55.000
Gotcha.

03:03:55.000 --> 03:04:08.000
Like, give me all the possible permutation and combination. Kind of Manuska intent yatha, basically. Ki, give me all the possible permutation and combination of this, uh, sentence.

03:04:08.000 --> 03:04:22.000
Yeah, jitane bhi is keen meaning ho sakte hai. Toh, basically, try to give me that, and then usuke through Hamlo search karate, but again, wo search heavy oya tayko ki, let's suppose ki aapne ek simple sentence ek dala, and then uska jo hai uske apne pahach multiple.

03:04:22.000 --> 03:04:37.000
Permutation combination benali hai. Toho into 5X so, yeah. Toh wo search bhiap karyga, toap ka 5x search query johe, wohapar bahi aata hai, toh, in terms of, like, a compute and in terms of akaja latency hai, umaha par ingi jaatai, toh, this is one of the approach which I remember we have applied.

03:04:37.000 --> 03:04:52.000
Uh, apart from Hamlog, Malakushku's rule-basedander. But, uh, this was the major implementation that we have done. Okay, before sending for the retrieval, let's send to the LLM and generate all the possible.

03:04:52.000 --> 03:05:04.000
Output means possible phrases out of this sentence. For example, agaram bolneki, uh, can you book a room? Right, and agar wo office second test mehito, can you book a meeting room?

03:05:04.000 --> 03:05:15.000
Can you book a meeting room? So it's kind of a position combination, but work around it, Matlab, and it was not a linear solution. Linear solution, Matlab.

03:05:15.000 --> 03:05:19.000
Ka.

03:05:19.000 --> 03:05:29.000
We have already built that solution. Hamlohuna EFS malabh kyata, ek use case haul build karate us kyandar. So, we were trying to solve it, and yehi workaround hamlohone usmein ni kalata.

03:05:29.000 --> 03:05:33.000
Good advice, implementation kyata based on the observation, but huh, this is one of the workarounds that you can think of. Ki, send your data, mental, send your query before sending.

03:05:33.000 --> 03:05:38.000
Okay.

03:05:38.000 --> 03:05:47.000
To an embedding vector, sent to the LLM, ask it to create a multiple query around it, and then which context we have sent kara, opponent documentar.

03:05:47.000 --> 03:05:49.000
Right. Right.

03:05:49.000 --> 03:05:55.000
Kiss direction mein. Lega. Right.

03:05:55.000 --> 03:06:00.000
Uh, right.

03:06:00.000 --> 03:06:01.000
Right.

03:06:01.000 --> 03:06:10.000
So, what we were doing, so we were trying to append our context, we were trying to append a memory, sending to the LLMs, it will try to… because LLM subset best in terms of handling a multi-languages.

03:06:10.000 --> 03:06:16.000
Uh, plus, uh, in terms of generating a multiple, like, uh, you know, queries out of it.

03:06:16.000 --> 03:06:17.000
Right.

03:06:17.000 --> 03:06:31.000
Right, those were… we were sending to the LLMs with our context and with the memory. Generally, Amlo, we have tried with the memory, but again, there is not sufficient memory, let's suppose ya baak kar rah meeting room ke bar hai mein. Take care. Toski ain miras mein morning ya bajada.

03:06:31.000 --> 03:06:32.000
So in that case, we were trying to even send append memory plus context and sending it to LLM, and then just say return arata.

03:06:32.000 --> 03:06:38.000
Great.

03:06:38.000 --> 03:06:43.000
We are converting that into an embedding, and then going for the search.

03:06:43.000 --> 03:06:44.000
Hmm, hmm. Hmm.

03:06:44.000 --> 03:06:50.000
Right, so trichoruma is, sir, I think… do web search uti hai.

03:06:50.000 --> 03:06:51.000
Hmm.

03:06:51.000 --> 03:06:58.000
Meg, POC Bananada, and take me meth thesiske… of Neil Yibanaratha.

03:06:58.000 --> 03:06:59.000
Hmm.

03:06:59.000 --> 03:07:03.000
You do web search hoti hain. Jokia hai.

03:07:03.000 --> 03:07:07.000
Hmm. Hmm.

03:07:07.000 --> 03:07:25.000
Ishkoga restrict karna hai for a particular region, or yehuta matap?

03:07:25.000 --> 03:07:26.000
Like…

03:07:26.000 --> 03:07:44.000
Uh, traffic, traffic, traffic, inbound or outbound control karate. Solution, right? Ki… So, inbound workar a set kart logina, ki is country ka, ya fir ye IP address johai yafir east system sa johyme kare, aur mere esport pahitnaker ko ini kar pahika, us country seh.

03:07:44.000 --> 03:07:49.000
Oh, sorry, web search kese matlab hotay matlab.

03:07:49.000 --> 03:08:03.000
Bill says, though, like, altogether, aapka bohot fundamental hai. Basically, aap search karteho wala gala pages, sala gala index. It's like a… very different kind of a, like, a system that Google has created.

03:08:03.000 --> 03:08:09.000
Okay.

03:08:09.000 --> 03:08:10.000
Actually, Larry Pitch, uh, okay, my research paper, they…

03:08:10.000 --> 03:08:19.000
Uh… Ah, CloudFront will be regional blocking concept, exactly. Cloudfront aka CD and app use kare, nah. Cloudfront CD Inc.

03:08:19.000 --> 03:08:26.000
Dig it. The wampa blocker sector. There are multiple ways on a server side.

03:08:26.000 --> 03:08:35.000
Okay, sir. Sir, actually, uh… architect-related, system design aapka job, or…

03:08:35.000 --> 03:08:36.000
Dsa StartCare. To Matlav agar architect.

03:08:36.000 --> 03:08:42.000
Hmm, hmm.

03:08:42.000 --> 03:08:49.000
Taravjana Gulhay, AI Full Stack Architect of. So, system design, DSA.

03:08:49.000 --> 03:08:50.000
Or… I think DevOps, it's more important than that.

03:08:50.000 --> 03:09:08.000
Toh system design. Because component plus real-time system design, ke matabahi humne ye problem solve kiya hain, that to add a scale kia hai. And then I know ki.

03:09:08.000 --> 03:09:18.000
So… system designer… system design is a core concept.

03:09:18.000 --> 03:09:21.000
Okay. Well, Apka start KM, sir.

03:09:21.000 --> 03:09:35.000
I think data science architecture and system design, uh, sorry, data science architecture wala, uskea humne ye bash launch kiata, toh, I'll start putting up some, like, recordings there.

03:09:35.000 --> 03:09:49.000
As a roof system design vertical dihara tan method was interesting as well, apne both interesting.

03:09:49.000 --> 03:09:50.000
To live the live batch reg.

03:09:50.000 --> 03:10:00.000
Hai. Who recorded value, hybrid value. Time ni will para recording kami.

03:10:00.000 --> 03:10:07.000
And in separate, a separate, separate.

03:10:07.000 --> 03:10:11.000
Opo data science system is AI, basically.

03:10:11.000 --> 03:10:14.000
But will we have a complete new initiative?

03:10:14.000 --> 03:10:22.000
The thing, eh?

03:10:22.000 --> 03:10:28.000
Well, HLD or low-level design aapna prior, you reset kap nos mo.

03:10:28.000 --> 03:10:34.000
Tops are completely done, like, I'll say. Okay, we'll see. Take care.

03:10:34.000 --> 03:10:38.000
Okay, so… hmm, thank you. Uh, Uskar? Ah, Mukesh, I think… who is sharing the screen? Navneet, right?

03:10:38.000 --> 03:10:43.000
I…

03:10:43.000 --> 03:10:51.000
Okay, Ravit Teja is sharing her screen. Vaniti is sharing her screen. Ranjit, I think you have even asked for me to, like, share the screen, so please share the screen.

03:10:51.000 --> 03:10:52.000
Okay, so one by one by one. So, let's start closing your, like, doubts.

03:10:52.000 --> 03:10:55.000
Yeah.

03:10:55.000 --> 03:10:56.000
I think it will be quick. So… Mm-hmm, okay.

03:10:56.000 --> 03:11:07.000
While creating an environment, I'm facing an issue. So here, here I'm unable to see this kind of environment when I create it.

03:11:07.000 --> 03:11:15.000
Okay, fine, Ravi. So, give me a remote control?

03:11:15.000 --> 03:11:16.000
Yeah. Let me do it. Conda… create hyphen n.

03:11:16.000 --> 03:11:20.000
Hello! Hi.

03:11:20.000 --> 03:11:27.000
Test… Python.

03:11:27.000 --> 03:11:36.000
Is equals to 3.10.

03:11:36.000 --> 03:11:42.000
I think you have already created the environment, like, I can see some derived, but fine.

03:11:42.000 --> 03:12:12.000
How do you ever listen to that?

03:12:19.000 --> 03:12:24.000
Okay, so in between, uh… okay, so installation is going on in Ravi's screen.

03:12:24.000 --> 03:12:26.000
Okay, Navneet, what is your issue?

03:12:26.000 --> 03:12:34.000
So, actually, uh… Uh, this one, I'm trying to install, uh, this, uh, deploy this.

03:12:34.000 --> 03:12:35.000
Okay. Okay. What is the error?

03:12:35.000 --> 03:12:42.000
The PPA, so what some data is coming, so… excited with the status 1, 2, 7, something is coming.

03:12:42.000 --> 03:12:51.000
Unicorn command node, UVCon, command not found. So you have, I think, mentioned UVCon in a capital U, I believe.

03:12:51.000 --> 03:12:57.000
Yeah, so it's a capital U, so just go ahead and check your UVicon command.

03:12:57.000 --> 03:13:04.000
Okay, let me close our Ravi's. You got your issue, Navneet, by the way. So here, Ravi, I think, uh.

03:13:04.000 --> 03:13:08.000
Environment has been created, so now if I have to use it, so conda, activate.

03:13:08.000 --> 03:13:15.000
A-e-t-i-v-a-t, activate, and the environment name, which is test. So now you will be able to see a test environment.

03:13:15.000 --> 03:13:19.000
So, see, it has started using it. Now, let's suppose if I have to change a kernel.

03:13:19.000 --> 03:13:31.000
So, select another kernel. And Python environment.

03:13:31.000 --> 03:13:39.000
Virtual, and uh… Must have created a test environment, by the way.

03:13:39.000 --> 03:14:09.000
Select another kernel.

03:14:17.000 --> 03:14:25.000
So, why it is not showing me the environment which I have created.

03:14:25.000 --> 03:14:34.000
Okay.

03:14:34.000 --> 03:14:53.000
Do you drive conda environment? Best…

03:14:53.000 --> 03:15:07.000
This thing, Jupiter server…

03:15:07.000 --> 03:15:37.000
Mm-hmm, mm-hmm, mm-hmm.

03:15:39.000 --> 03:15:48.000
Uh, no need. In Render Platform, go to Settings.

03:15:48.000 --> 03:15:52.000
This is, uh…

03:15:52.000 --> 03:15:58.000
Settings down left side. Events down.

03:15:58.000 --> 03:16:01.000
This one? No, okay.

03:16:01.000 --> 03:16:08.000
There, uh, start, start command they are to search.

03:16:08.000 --> 03:16:22.000
Don't. Yeah, here, Capsio is their edit and change it.

03:16:22.000 --> 03:16:29.000
Uh, don't edit is there.

03:16:29.000 --> 03:16:30.000
No, no, start command input box down, there is an edit, right?

03:16:30.000 --> 03:16:34.000
No edit option is not there.

03:16:34.000 --> 03:16:37.000
This one?

03:16:37.000 --> 03:16:43.000
Just the little benchmark.

03:16:43.000 --> 03:16:44.000
Irritoxin not coming, na?

03:16:44.000 --> 03:16:50.000
You know, a box, that input box downside, right, rights and right corner, downside, edit is there now.

03:16:50.000 --> 03:16:51.000
Uh, this one, this one, yes. Okay.

03:16:51.000 --> 03:17:01.000
Upon, up on.

03:17:01.000 --> 03:17:02.000
Okay, can you…

03:17:02.000 --> 03:17:07.000
Yeah.

03:17:07.000 --> 03:17:18.000
Yeah, you need to deploy again, I think. Uh, this building.

03:17:18.000 --> 03:17:48.000
No, no, no, no.

03:18:24.000 --> 03:18:25.000
Yeah, yes.

03:18:25.000 --> 03:18:33.000
Okay, so Namili, this was fixed? Okay, okay. So, anyone else? I think multiple people can share their screen, so while I'm resolving a doubt from others, right, so other people can also share their screen.

03:18:33.000 --> 03:18:39.000
And anyone can select to, like, uh, select and see any other screens.

03:18:39.000 --> 03:18:50.000
That is possible in this webinar setting.

03:18:50.000 --> 03:18:55.000
Sorry, uh, what is the question, Anjit? Sorry, Arman, right?

03:18:55.000 --> 03:19:01.000
Those texts that you have shown that for you to register.

03:19:01.000 --> 03:19:02.000
Good form of dog love. So, am I audible now?

03:19:02.000 --> 03:19:08.000
Not able to understand your question, by the way. Yeah, you're audible.

03:19:08.000 --> 03:19:16.000
So, I was asking about the pre-processing step that you have just done in this lecture about the… After the generating the embedding part.

03:19:16.000 --> 03:19:21.000
So that is necessary, or we can skip some of them.

03:19:21.000 --> 03:19:22.000
Yes, yes.

03:19:22.000 --> 03:19:28.000
Pre-processing, you were saying, right? So, actually, in a real life, you will add more. So, you can't escape it, you will keep on adding more and more, because.

03:19:28.000 --> 03:19:36.000
It's not like you will be able to get a polished and a structured data. So, it will be, like, uh, keep on increasing it.

03:19:36.000 --> 03:19:43.000
Okay, answer one follow-up question in what… in… recently that you have told about the difference in annuals that we can.

03:19:43.000 --> 03:19:51.000
A given input. For example, booking a suite or something. So, in that case, how to handle that situation?

03:19:51.000 --> 03:19:56.000
Are there deep explanations or not? Not now, maybe in later stage.

03:19:56.000 --> 03:19:58.000
Okay, that may be… Okay.

03:19:58.000 --> 03:20:02.000
In later stage, you can add a deep explanation, put up, like, how can we handle that situation?

03:20:02.000 --> 03:20:06.000
Hmm, exactly, exactly. We'll try to bring some of the cases for that.

03:20:06.000 --> 03:20:12.000
But yeah, like, I think I have already talked about the solution that we were trying to build.

03:20:12.000 --> 03:20:14.000
Right, and the approach that we have applied for that one.

03:20:14.000 --> 03:20:15.000
And then lastly.

03:20:15.000 --> 03:20:23.000
Not the best one, but yeah. So, it was giving us some sort of a better result.

03:20:23.000 --> 03:20:30.000
Also, we're not talking about our AG masters. Have you completed that, or… Some parts are still the meaning.

03:20:30.000 --> 03:20:33.000
Now, RG Master, I have already completed it. So, RG Master is closed.

03:20:33.000 --> 03:20:37.000
Awesome.

03:20:37.000 --> 03:20:38.000
Sir Rancho?

03:20:38.000 --> 03:20:45.000
Yeah. Uh, Ravi, I think… yeah, so I think there is, there is some issue with, uh, your path, because it is not able to recognize.

03:20:45.000 --> 03:20:55.000
Maybe while installing a Conda, you have set some… path for a conda in a different directory. So, in some D drive, I think I can see.

03:20:55.000 --> 03:21:01.000
You have done, so it is not able to… I think organized in a…

03:21:01.000 --> 03:21:07.000
Proper directory, and because of that, it is giving you an issue.

03:21:07.000 --> 03:21:08.000
Uh, sir, can you see my screen?

03:21:08.000 --> 03:21:16.000
Just a minute, uh, yeah, I can see. I'm solving Ravi's problem, then I'll come back to you.

03:21:16.000 --> 03:21:35.000
Okay, let's do one thing. Mmm…

03:21:35.000 --> 03:22:05.000
So you have just messed up in your system with the… file path. That's an issue.

03:22:08.000 --> 03:22:38.000
Python 3.1 is not available, okay, not an issue, we'll download it.

03:23:19.000 --> 03:23:22.000
Yeah, Nolid, what is your, uh, what is your problem?

03:23:22.000 --> 03:23:28.000
So that, again, error is coming.

03:23:28.000 --> 03:23:29.000
Yes. A hair.

03:23:29.000 --> 03:23:34.000
No need, right? No, no. I'm talking about Damnit, basically.

03:23:34.000 --> 03:23:36.000
So again, error is coming. What is the error this time?

03:23:36.000 --> 03:23:38.000
Excited with status 1 on this.

03:23:38.000 --> 03:23:46.000
Uh, that is not an error, by the way, so that is just a message. Now, error has changed. Previous error was different. Previous error was UVCon error, now error has changed.

03:23:46.000 --> 03:23:48.000
Again, the fail, it will come, no?

03:23:48.000 --> 03:23:54.000
Fine, but error has changed. The mistake that you have been doing before, it is not the same.

03:23:54.000 --> 03:24:06.000
Yeah, before it was different, now it is different.

03:24:06.000 --> 03:24:28.000
Just a minute, I'm solving Ravi's problem.

03:24:28.000 --> 03:24:58.000
Okay, so…

03:25:13.000 --> 03:25:16.000
You have to live the full path for Python 3.1. And it will be 310.

03:25:16.000 --> 03:25:23.000
He has not set his system path, so because of that, it's giving a lot of issue, not just one.

03:25:23.000 --> 03:25:24.000
Isconda path is not correct, it's somewhere in a D drive or something.

03:25:24.000 --> 03:25:28.000
Yep.

03:25:28.000 --> 03:25:29.000
Well, he has just, like, messed up with the entire system itself.

03:25:29.000 --> 03:25:33.000
Farn them?

03:25:33.000 --> 03:25:40.000
Yeah, you have to pull, like, full path, like, the absolute path for it.

03:25:40.000 --> 03:25:52.000
Program file, maybe somewhere in a user or something. Um…

03:25:52.000 --> 03:25:57.000
Nick, because sometimes, uh, it is in the roaming, or sometimes it gets into the program.

03:25:57.000 --> 03:26:02.000
Users, so yeah, so…

03:26:02.000 --> 03:26:11.000
C drive, then maybe…

03:26:11.000 --> 03:26:17.000
I don't know what is his name. Musically, maybe this one, I'm assuming.

03:26:17.000 --> 03:26:24.000
And then… Anakunda… 3… okay.

03:26:24.000 --> 03:26:31.000
And then somewhere, you know… ENVs?

03:26:31.000 --> 03:26:38.000
Envs…

03:26:38.000 --> 03:26:42.000
This is a vector DB, I think that is the way in which that you are looking for.

03:26:42.000 --> 03:26:48.000
The third one from the… from the lower side, yep.

03:26:48.000 --> 03:26:54.000
Yeah, these are the ENVs he has created, and Python executable.

03:26:54.000 --> 03:27:01.000
But still, I am looking for a Python execute table, miniconda, fine.

03:27:01.000 --> 03:27:07.000
We have local, not here. Users…

03:27:07.000 --> 03:27:14.000
And then… Username…

03:27:14.000 --> 03:27:19.000
And then app data.

03:27:19.000 --> 03:27:39.000
There is app data, okay. So, here is app data. Then local…

03:27:39.000 --> 03:28:09.000
And programs…

03:28:32.000 --> 03:28:40.000
Ooh, there is a space. Okay, do one thing, Ravi. A lot of, like, issues you have already created in your system.

03:28:40.000 --> 03:28:46.000
Uh, just, just close everything, and use this environment, current one. That's better.

03:28:46.000 --> 03:28:53.000
Yeah, because in your system, so again, I have to handle your space issue, which you have already created in your system.

03:28:53.000 --> 03:28:58.000
A lot of, lot of things. So it's better to use this environment, and then let's do one thing.

03:28:58.000 --> 03:29:08.000
Uninstall your VS Code, uninstall the complete Conda. Uninstall the complete Python, because even Python-wise, I can see…

03:29:08.000 --> 03:29:18.000
That there are multiple Python versions which has been created. So, 3.11, 3.13, 3.9, 3.10, so all of this version has been created.

03:29:18.000 --> 03:29:27.000
Just wipe out everything, and then do a proper setup. Your system is literally like a mess. It is not able to recognize even a condo.

03:29:27.000 --> 03:29:31.000
Yeah, so just wipe out everything, and for now, you can try to use the same environment. That's fine, it will work.

03:29:31.000 --> 03:29:33.000
Anyhow. Yeah, yeah, just, just uninstall, uninstall everything.

03:29:33.000 --> 03:29:35.000
Okay.

03:29:35.000 --> 03:29:38.000
Sometimes, yeah.

03:29:38.000 --> 03:29:40.000
Yeah, yes.

03:29:40.000 --> 03:29:49.000
Yeah, there is a workaround, I can fix the issue, because I was able to see the location, but again, unnecessarily, it will give you a problem again and again and again. So, not just today.

03:29:49.000 --> 03:29:56.000
Today, I'll fix it, but again, tomorrow we will come with the same thing, though it's better, just wipe out the system and do the installation once again.

03:29:56.000 --> 03:29:57.000
Yeah, okay, shoot.

03:29:57.000 --> 03:30:03.000
Yeah, okay. Yeah, Navneet. Next one. So, what is the issue that you are facing.

03:30:03.000 --> 03:30:09.000
Common troubleshooting your delays, this is running files. Show me the file, line number 8, Ubicorn, okay.

03:30:09.000 --> 03:30:13.000
And… what is the deployment that you're trying to do, by the way?

03:30:13.000 --> 03:30:17.000
On the Sage API, that first, uh, second class you…

03:30:17.000 --> 03:30:26.000
Give me the control, give me control. Where is your, like, repository?

03:30:26.000 --> 03:30:27.000
This is…

03:30:27.000 --> 03:30:34.000
This is the repository, right? Udme requirement, test.py file, testing. By fighting. So, which file you are deploying? Test out or testing?

03:30:34.000 --> 03:30:38.000
Both testing.f… Using this thing?

03:30:38.000 --> 03:30:40.000
Sorry?

03:30:40.000 --> 03:30:52.000
Testing.file.

03:30:52.000 --> 03:31:22.000
We have two men find… this is fine, no directory.

03:33:53.000 --> 03:33:58.000
Okay, so in between, Akhtar, what is your issue?

03:33:58.000 --> 03:34:06.000
Uh, yes, actually… Um, actually, I have fixed that issue. The one I was getting here…

03:34:06.000 --> 03:34:07.000
I mean, I wanted to understand that what is… what was the issue here?

03:34:07.000 --> 03:34:10.000
Okay.

03:34:10.000 --> 03:34:13.000
I ran this command. And then…

03:34:13.000 --> 03:34:19.000
Nothing. Command looks fine to me.

03:34:19.000 --> 03:34:20.000
Yeah, so command looks fine, so I think it should work.

03:34:20.000 --> 03:34:23.000
Yeah.

03:34:23.000 --> 03:34:31.000
I'm just…

03:34:31.000 --> 03:34:32.000
Mm-hmm. Mm-hmm.

03:34:32.000 --> 03:34:39.000
So…

03:34:39.000 --> 03:34:48.000
No, no, so you… so in Jupyter Node, we will not be able to accept it. So, in a terminal only, it will be able to accept it.

03:34:48.000 --> 03:34:50.000
Mm-hmm, exactly, exactly. That's the correct way, actually. Hmm.

03:34:50.000 --> 03:34:55.000
Install Honigabad, no?

03:34:55.000 --> 03:35:04.000
Your users are… I don't think Ocean environment kita. Jo, environment issues are ata.

03:35:04.000 --> 03:35:05.000
Hmm. Hmm.

03:35:05.000 --> 03:35:12.000
You have the OP team, operator anaconda. So because of the… again, I searched on ChatGPT, and it, uh, told me that don't create the.

03:35:12.000 --> 03:35:15.000
Environment is that it's OTP folder. But I was not able to change, because here, folded structure, I'm not able to understand in Mac.

03:35:15.000 --> 03:35:21.000
Hmm.

03:35:21.000 --> 03:35:27.000
No, no, it's fine. So it is taking, by default, the path it has selected at the time of installation of software, right?

03:35:27.000 --> 03:35:28.000
So if you're using a condo, so whenever it has all condas, so that was a path.

03:35:28.000 --> 03:35:30.000
Hmm.

03:35:30.000 --> 03:35:41.000
Uh, because this is what it is trying to show you, OPT and a Conda 3 environment, right? So that is the default path that you have selected, or it has taken. Maybe this is the default setting of your system.

03:35:41.000 --> 03:35:42.000
Then it's fine, it's fine, leave it.

03:35:42.000 --> 03:35:48.000
By default, by default, it was taken. But it was not allowing me to install. So, again, I asked to ChatGPT, and it, uh…

03:35:48.000 --> 03:35:56.000
Uh, so they showed me one command to change this path itself. So somehow, it was somewhere I had fired that one. This one, I believe.

03:35:56.000 --> 03:36:02.000
Mm-hmm. But it's saying no such file directory.

03:36:02.000 --> 03:36:03.000
But now you're… now you're able to create the environment, right?

03:36:03.000 --> 03:36:04.000
Someone… here I am. Yeah. Uh, somewhere at your…

03:36:04.000 --> 03:36:07.000
That is, I have, I have, uh, fixed now, but I just wanted to understand that how I can change the environment itself. Like, for example, if I am updating.

03:36:07.000 --> 03:36:18.000
Okay. Because if you have to… if you have to change the environment, right? So, let's suppose, uh, you are in which environment is of now? Base environment.

03:36:18.000 --> 03:36:22.000
Not sure that… how can I… how can I see this?

03:36:22.000 --> 03:36:34.000
Okay, let's come down. Okay, fine. So, you are basically into a V environment, virtual environment, which name is basically a base environment. And again, in your, like, editor, left-hand side, uh, V environment, and then.

03:36:34.000 --> 03:36:36.000
Uh, virtual environment is… it is trying to showcase, yeah. So, just write conda deactivate.

03:36:36.000 --> 03:36:41.000
Listen.

03:36:41.000 --> 03:36:46.000
Does right Condor deactivate, it will deactivate all the environments. And that is your actual base environment, deactivate.

03:36:46.000 --> 03:36:50.000
So, every time I have to, uh…

03:36:50.000 --> 03:37:00.000
Activate the environment, yeah. So now you are into no environment. Now if you have to go into a base environment, so maybe you can try to give an environment name, and then it will eventually get into that environment.

03:37:00.000 --> 03:37:02.000
How can I… how can I, um…

03:37:02.000 --> 03:37:07.000
So, conda activate, and then entire environment path, the above one that you are able to see, right?

03:37:07.000 --> 03:37:14.000
Above one, the above one. Yeah, this one.

03:37:14.000 --> 03:37:15.000
I believe this one I…

03:37:15.000 --> 03:37:20.000
No, no, not this, not this. No, no, no, that is for a creation, right? It is trying to create once again, so…

03:37:20.000 --> 03:37:21.000
They're just a reponder… conda, then activate.

03:37:21.000 --> 03:37:27.000
That is one of creation. The command that you are able to see above, the command that you are able to see above already.

03:37:27.000 --> 03:37:29.000
Okay, this one, okay, condo activity at this one, okay. The command yourself how to copy-paste, right?

03:37:29.000 --> 03:37:34.000
Yeah. Why? Yeah, only command, only command, not dollar sign.

03:37:34.000 --> 03:37:46.000
Okay, okay. So every time once I will work… I'll be working on, uh, using the conda, then I have to activate.

03:37:46.000 --> 03:37:49.000
And if it is not in use, then I have to deactivate it.

03:37:49.000 --> 03:37:51.000
Yes, yeah, yeah, simple.

03:37:51.000 --> 03:37:57.000
Okay, that is one thing. And since it is Mac, no, yesterday.

03:37:57.000 --> 03:38:02.000
While I was checking this. This one, okay.

03:38:02.000 --> 03:38:08.000
So, because of this use… because of huge, uh, interpretation of this data.

03:38:08.000 --> 03:38:14.000
It was… started giving issues. So, some, like, GPU issues will start coming.

03:38:14.000 --> 03:38:16.000
I asked for ChatGPT, and he suggested me to, like, do that.

03:38:16.000 --> 03:38:19.000
Yeah, keep it, keep it CPU, yeah.

03:38:19.000 --> 03:38:30.000
So, I use this command. So, my doubt is. That, uh, for the next, like, upcoming classes, like, uh, whatever the, uh, things that we are going to perform.

03:38:30.000 --> 03:38:33.000
So, my system will handle it, or… I need two, Michael.

03:38:33.000 --> 03:38:41.000
Your system will not be able to handle or anyone's system is not be able to handle the heavy load. Wherever we need a GPU inferencing.

03:38:41.000 --> 03:38:45.000
At that point over time, anyhow, we are going ahead with the cloud.

03:38:45.000 --> 03:38:46.000
Okay.

03:38:46.000 --> 03:38:53.000
So no one is having a system which will be able to handle, like, inferencing with the heavy load, like a 20 billion, 120 billion kind of a things.

03:38:53.000 --> 03:39:01.000
So, forget about it, like, whether it's a CPU GPU is fine, even though if you have a small GPUs, it is not going to be very much useful.

03:39:01.000 --> 03:39:05.000
It was giving me exceptions, like, the MPS kind of exception, so, like.

03:39:05.000 --> 03:39:07.000
Yeah, by default, it was running into… it was looking for the code name.

03:39:07.000 --> 03:39:15.000
So I checked this command, and it was saying that empty server like that, so I… now I tested it, and it worked fine. There is no issue.

03:39:15.000 --> 03:39:16.000
For now, but today I was facing this issue, so I…

03:39:16.000 --> 03:39:26.000
Hmm, hmm. It was… it was looking for actually a Kuda, but your, like, hardware is not compatible with that, so that's the reason. Now, you have set it up as a CPU, so it'll work.

03:39:26.000 --> 03:39:31.000
Yeah, so, uh, our CPU is karne it to usme, processing to slow jaga.

03:39:31.000 --> 03:39:32.000
Obviously, hmm.

03:39:32.000 --> 03:39:39.000
So, commande, aapko saif past second lagada.

03:39:39.000 --> 03:39:47.000
Hmm.

03:39:47.000 --> 03:39:48.000
Hmm.

03:39:48.000 --> 03:39:54.000
Our fear major, uh… environment, base environment jab Python layerang. 3.13.

03:39:54.000 --> 03:39:59.000
Hmm.

03:39:59.000 --> 03:40:01.000
So, yeah, Pandra second mikskuto, Jara. Karata.

03:40:01.000 --> 03:40:07.000
Hmm.

03:40:07.000 --> 03:40:18.000
So, result na dias amico.

03:40:18.000 --> 03:40:22.000
Uto depend karai.

03:40:22.000 --> 03:40:29.000
So, like, in time, both Adaliyah, again, it's good news.

03:40:29.000 --> 03:40:40.000
Possible. Generally.

03:40:40.000 --> 03:41:10.000
It's like a folder, yeah, jawapusco library, call karte ho, import karte ho, tap kya karte host folder mein jatta hai. Auruska supporting file ko le kyata hai. Ita nahi yo, thai environment ka matla, buskel ahu shuta bin USA.

03:41:13.000 --> 03:41:21.000
Laga. Meripas.

03:41:21.000 --> 03:41:26.000
My Python karonga abhi ye jaldi sales ku toga.

03:41:26.000 --> 03:41:33.000
Okay, I checked earlier. Seemo jaya.

03:41:33.000 --> 03:41:43.000
Mein. Environment, we impact ya.

03:41:43.000 --> 03:41:53.000
Belgolang. Mmm, we will know.

03:41:53.000 --> 03:41:56.000
Cpu conjunction jaara hoga. Many things, right?

03:41:56.000 --> 03:41:59.000
Midwest process Jada Kushner.

03:41:59.000 --> 03:42:13.000
Back-end process, background process, ball var, ni yoga. So, that is not an issue. Environment issue with high nigga, USA.

03:42:13.000 --> 03:42:14.000
So, is key… Iska your directory, yaha pe kasi find karong.

03:42:14.000 --> 03:42:17.000
Hmm…

03:42:17.000 --> 03:42:23.000
My upper, by default, you've got a Python scenario.

03:42:23.000 --> 03:42:27.000
So, Agarma apnee ist me jang yang.

03:42:27.000 --> 03:42:35.000
Aapko.

03:42:35.000 --> 03:42:38.000
The job may install kiya mahap anachaya.

03:42:38.000 --> 03:42:47.000
Exactly. Aapke system user kendar kein yoga.

03:42:47.000 --> 03:42:48.000
Exactly. You know, Kundakan dari aapka ENV kake Hoga.

03:42:48.000 --> 03:42:54.000
Load kerkar account.

03:42:54.000 --> 03:43:02.000
I know Gunda Distribution, Anokonda 3, bin Python.

03:43:02.000 --> 03:43:10.000
Thank you, sir. Kitne mat laba.

03:43:10.000 --> 03:43:22.000
There will match data science may put up dehogen. Matthews. By the way. Well…

03:43:22.000 --> 03:43:34.000
Batau. Is a name Matthew, so…

03:43:34.000 --> 03:43:35.000
Uh, we'll schedule… huh.

03:43:35.000 --> 03:43:38.000
But anyway, like.

03:43:38.000 --> 03:43:54.000
Hardly 30 seconds.i bustara sehi. So don't worry about it. Johi Matthews were never long ago, say.

03:43:54.000 --> 03:44:00.000
But ideally, I don't say those terms as a myth.

03:44:00.000 --> 03:44:01.000
Hmm.

03:44:01.000 --> 03:44:16.000
I will just recall it, I will just re-explore it. That's pretty much obvious.

03:44:16.000 --> 03:44:23.000
But it's a comment down to recall curling, if you're saying.

03:44:23.000 --> 03:44:24.000
Uh, Egbarikol karleta, mein.

03:44:24.000 --> 03:44:35.000
Ah, exactly. So class… dig in. Well, what I meant to you?

03:44:35.000 --> 03:44:40.000
Okay, okay, take it then.

03:44:40.000 --> 03:44:44.000
Yeah.

03:44:44.000 --> 03:44:45.000
Ish.

03:44:45.000 --> 03:44:47.000
Okay, so just… ignorant, ignorant, ignite. So, Nadeem Gah Hogya, eh, one minute, one minute, just give me a second.

03:44:47.000 --> 03:44:52.000
Yeah, I said, aren't you?

03:44:52.000 --> 03:44:55.000
I will solve one by one. So, you are… Ranjit, right? Yeah, Ranjit.

03:44:55.000 --> 03:45:01.000
Indeed. Yes. Yeah.

03:45:01.000 --> 03:45:03.000
Can you see my machine?

03:45:03.000 --> 03:45:04.000
Okay, thank you, sir.

03:45:04.000 --> 03:45:07.000
Yeah, you are also sharing this one, right? Render.

03:45:07.000 --> 03:45:13.000
Hey, uh, it's a small issue, but I don't know why it's not recognizing requirements.txt.

03:45:13.000 --> 03:45:18.000
I mean, I just… I didn't change anything in your code.

03:45:18.000 --> 03:45:19.000
So it is just to see.

03:45:19.000 --> 03:45:26.000
Okay, can you please… can you… R-E-Q-U-I-R-E-M-E-N-D-S dot CXD. Can you please, uh, show me your repository?

03:45:26.000 --> 03:45:30.000
This is exactly the same as… I haven't done any change.

03:45:30.000 --> 03:45:33.000
Okay, no. So, basically, your directory is different, I can see that.

03:45:33.000 --> 03:45:35.000
And in that is the app.

03:45:35.000 --> 03:45:40.000
The MAI inside that, you have an API testing, and inside that there is a testing.py file, and there is a directory change, and it is not able to organize it. Go to render. I'll show you. I'll tell you how to do it.

03:45:40.000 --> 03:45:47.000
Uh-huh.

03:45:47.000 --> 03:45:48.000
Go to new, go to new, go to new. Leave it, leave everything. Let's do anew.

03:45:48.000 --> 03:45:52.000
Okay, so… and…

03:45:52.000 --> 03:45:59.000
Yeah, go to new, web service. You have folder inside folder. Select the first one, yeah.

03:45:59.000 --> 03:46:06.000
So, the first one, first one, first one? No, no, no, repository, repository, yeah. Sorry, the first one? Okay. Now, so, Janae, come down, come down.

03:46:06.000 --> 03:46:10.000
Fine. So, Gen AI, and then main, and then root directory.

03:46:10.000 --> 03:46:20.000
Uh, okay. So, basically, inside your root directory, you have to set that one, API underscore that directory, right? Can you please go back?

03:46:20.000 --> 03:46:27.000
To your repo? So, you have a GenAI, and then you have your main, and then API underscore testing.

03:46:27.000 --> 03:46:37.000
So, just copy this directory name.

03:46:37.000 --> 03:46:46.000
Hmm. Now delete testing.py file. Just keep API.testing. Yeah, delete testing.py.

03:46:46.000 --> 03:46:55.000
Delete, delete. Yes. No, no, no, no, no, just keep API testing. Api underscore testing, just keep that. Control-j, Ctrl-J, undo.

03:46:55.000 --> 03:47:01.000
And do it, yeah. Just to test slash testing.py, just delete that much.

03:47:01.000 --> 03:47:10.000
Now, yeah, delete slash, delete slash as well. Forward slash? Okay, so now, see, build command is requirements.txt, right? And it is available at which location? Api testing.

03:47:10.000 --> 03:47:13.000
Oh. Uh huh.

03:47:13.000 --> 03:47:20.000
So, this is the actual location. Now, give your UConn command.

03:47:20.000 --> 03:47:28.000
Uvcon command, a start command, give a start command. No, no, no, no, no, no, go back, go up, up, up, up, up. Yeah, give us start command.

03:47:28.000 --> 03:47:29.000
No, no, down, down, down. After, after requirement.txt, there is another tab, right? Start command tab. Start command.

03:47:29.000 --> 03:47:38.000
Where do you start?

03:47:38.000 --> 03:47:39.000
Oh, yeah, yeah, okay, here, here.

03:47:39.000 --> 03:47:46.000
Yeah. Start command, start command. No, no, go down. Next, next, next, yeah, start coming, yes. So, what is the start command? Unicorn, sorry, unicorn is the start command, UVicon.

03:47:46.000 --> 03:47:49.000
Uvcon, and what is your file name? So, your file name is testing file name.

03:47:49.000 --> 03:47:50.000
Testing you with God.

03:47:50.000 --> 03:47:57.000
So, UVCon Space Testing. Colon, app.

03:47:57.000 --> 03:48:07.000
Hyphen hyphen host? Yeah, so, uh, host is 0.0.0.

03:48:07.000 --> 03:48:13.000
Yeah, space, hyphen hyphen port.

03:48:13.000 --> 03:48:15.000
Give a port number. Select free.

03:48:15.000 --> 03:48:22.000
Okay.

03:48:22.000 --> 03:48:24.000
Yeah, free, free, free one, free one. No, no, no, no, free, free.

03:48:24.000 --> 03:48:25.000
Oh, yeah, I told you, yeah.

03:48:25.000 --> 03:48:32.000
Yes, yeah. Click that, then click on deploy. It should work.

03:48:32.000 --> 03:48:34.000
Okay, ready to deploy? Yeah, down, yeah, okay.

03:48:34.000 --> 03:48:44.000
The last button, the last button. The plug-in service.

03:48:44.000 --> 03:48:49.000
Yeah, so this time, at least it will not give you, like, a requirement.txt issue, maybe, like.

03:48:49.000 --> 03:48:51.000
Another issue it may give you, I don't know, but… Let's check. We'll wait for that.

03:48:51.000 --> 03:48:53.000
Okay. Hmm.

03:48:53.000 --> 03:48:56.000
Okay, so, uh, Navrith? Uh, what is your… still facing the issue, or is it done?

03:48:56.000 --> 03:49:02.000
Yes. No, so it's going on the same.

03:49:02.000 --> 03:49:10.000
Same issue, okay, what is the issue? Common may troubles with this got unexpected extra argument, okay?

03:49:10.000 --> 03:49:31.000
It should not give you that. Got…

03:49:31.000 --> 03:49:38.000
No. I mean, like, we had given, uh…

03:49:38.000 --> 03:49:39.000
Correct one.

03:49:39.000 --> 03:49:43.000
Uh, here not given the variable dash dash hostname.

03:49:43.000 --> 03:49:45.000
So, yeah, we can't test app. Oh, ho, sorry, sorry, sorry. I forgot to give a host name.

03:49:45.000 --> 03:49:51.000
Yeah, yeah. Yep.

03:49:51.000 --> 03:49:52.000
Yep.

03:49:52.000 --> 03:50:00.000
That was a mistake. Hyphan-host. Sorry. Yeah, I was assuming that I have done that, but…

03:50:00.000 --> 03:50:09.000
Hi, I made a mistake, okay. No, fine, not an issue. Go with the again deployment. So, here… Um, yeah, it has started deploying.

03:50:09.000 --> 03:50:12.000
Okay, that was the only mistake, nothing else. Anjit, I think, yeah, it's working, it's working now, I think. So do slash talks, DOCS docs, slash doc.

03:50:12.000 --> 03:50:17.000
So… But…

03:50:17.000 --> 03:50:23.000
So your API is live, now you can just use a, like this on Swagger UI.

03:50:23.000 --> 03:50:33.000
Yeah, it's… yeah, it's running, see? You are able to see your endpoint, right? So your user ID and your delete and update, you are able to see it.

03:50:33.000 --> 03:50:34.000
Update. Yeah, so put code and delete. Yeah, so with the API endpoint.

03:50:34.000 --> 03:50:40.000
Yeah, delete, and put. Update, uh…

03:50:40.000 --> 03:50:42.000
So… so how do I know it's working?

03:50:42.000 --> 03:50:50.000
It is working. The way you have tested it in local, do it in the same way. Now it's live, so anyone can test it, and even you can test it.

03:50:50.000 --> 03:50:51.000
So the way you have tested it in local, right? By sending a request.

03:50:51.000 --> 03:50:52.000
Okay, so… Yeah.

03:50:52.000 --> 03:50:58.000
Maybe you can click on put and then send a request from here itself.

03:50:58.000 --> 03:50:59.000
Yeah, put… and then try it out. Click on try it out.

03:50:59.000 --> 03:51:02.000
If I just put… okay…

03:51:02.000 --> 03:51:09.000
Yeah, then send a user ID. User ID, so the user ID is something which is required, right? Send user ID. So, maybe one. Send one, because I think one user ID was there.

03:51:09.000 --> 03:51:13.000
So, and… Okay.

03:51:13.000 --> 03:51:17.000
Yeah, send one, right? And then send it, send the request.

03:51:17.000 --> 03:51:21.000
It'll give you 200 response. Execute.

03:51:21.000 --> 03:51:23.000
Now, see? So, what is the response? User 200, user updated successfully, right?

03:51:23.000 --> 03:51:29.000
Yeah, 200. Uh, yes.

03:51:29.000 --> 03:51:32.000
Hmm. So, I mean, it's working.

03:51:32.000 --> 03:51:36.000
So, if somebody else needs to check it, so… what URL?

03:51:36.000 --> 03:51:41.000
You just have to share the above one, the URL that you are able to see in render, right? So you can give the same URL.

03:51:41.000 --> 03:51:42.000
In this… ice.

03:51:42.000 --> 03:51:53.000
No, not this one. The base URL. Not this one, not this one. So, the render URL. Go to the render.

03:51:53.000 --> 03:51:58.000
Uh… No.

03:51:58.000 --> 03:51:59.000
Oh, uh, this one. This year. Okay.

03:51:59.000 --> 03:52:04.000
The place where you have deployed, the place, yeah, here. This URL, yeah, or maybe you can go up, go up, go up a little bit.

03:52:04.000 --> 03:52:11.000
Up, up, up, up in the page. No, not in this one, not in console. Up in the render page.

03:52:11.000 --> 03:52:12.000
Up in the interface, huh. This one, yeah.

03:52:12.000 --> 03:52:18.000
Yeah, yeah, now you can see that, right? Url. So just copy that URL, yeah, give it, share with anyone, yeah.

03:52:18.000 --> 03:52:25.000
Oh, I see. So now, but it's… okay, they need to…

03:52:25.000 --> 03:52:26.000
Yeah.

03:52:26.000 --> 03:52:32.000
Yeah. So, yeah, so this is basically an API URL, so basically this is the endpoint. Now, at docs, so there is a Swagger UI. If someone would like to test it through a postman or something.

03:52:32.000 --> 03:52:34.000
Then that only URL is required. This docs is not required.

03:52:34.000 --> 03:52:39.000
Okay. Okay. Okay.

03:52:39.000 --> 03:52:40.000
Yep, yep, thanks, things, thanks. I think, Ranjit, even your problem is solved, right?

03:52:40.000 --> 03:52:45.000
And thank you very much, I appreciate your help.

03:52:45.000 --> 03:52:46.000
Yes, yes, yeah, yeah.

03:52:46.000 --> 03:52:52.000
Yeah, I mean, like, there was no problem. I have just missed the iPhone iPhone host, so… You know, Ranjean's problem is solved, I think Navne's problem is solved, right?

03:52:52.000 --> 03:52:55.000
Yeah, yes, yes, solved.

03:52:55.000 --> 03:52:57.000
Can I go through? Okay.

03:52:57.000 --> 03:52:58.000
Uh, can I ask next? Just one question.

03:52:58.000 --> 03:53:04.000
Okay, great. Yeah, please go ahead, yeah, please go ahead. Yeah.

03:53:04.000 --> 03:53:05.000
Launcher, can I ask the question? I have just one question.

03:53:05.000 --> 03:53:06.000
Settings are.

03:53:06.000 --> 03:53:07.000
Yeah. Yeah, yeah, please go ahead, please go ahead.

03:53:07.000 --> 03:53:09.000
So, this one, uh… yeah, having Conda, like, whenever I'm trying to create it, giving issues.

03:53:09.000 --> 03:53:16.000
Um.

03:53:16.000 --> 03:53:17.000
Okay?

03:53:17.000 --> 03:53:23.000
So, was that I just followed your lecture, not I followed, like, no… Same, really.

03:53:23.000 --> 03:53:26.000
Okay, so you are… you're not able to do it, right?

03:53:26.000 --> 03:53:27.000
No, no, don't do an environment creation inside Jupyter Notebook. Open up your terminal. Inside the terminal, you have to do it.

03:53:27.000 --> 03:53:34.000
Yeah, no, sir.

03:53:34.000 --> 03:53:35.000
Yeah, inside terminal, you have to do this. So, give me a remote control.

03:53:35.000 --> 03:53:39.000
Okay?

03:53:39.000 --> 03:53:40.000
Yeah, yeah.

03:53:40.000 --> 03:53:45.000
Give me control, and remove these patches. I can see, like, some…

03:53:45.000 --> 03:53:48.000
I think these are Zoom.

03:53:48.000 --> 03:53:54.000
Yeah, so just remove these patches. I… Give me, give me control and leave it, leave it.

03:53:54.000 --> 03:53:55.000
Just… just remove the patches, so here you have to do it, basically.

03:53:55.000 --> 03:53:58.000
Yeah, I've given them.

03:53:58.000 --> 03:53:59.000
Uh, remove this chat bar and everything, if you can mini… Yeah.

03:53:59.000 --> 03:54:06.000
Yeah, let me… give me one sec, one sec.

03:54:06.000 --> 03:54:07.000
Yes, go ahead, please.

03:54:07.000 --> 03:54:09.000
Um, uh, main virtual answer, can I ask the question? Okay, so when we did this, uh, you know, FAIS.indexflatiphip IP.

03:54:09.000 --> 03:54:15.000
Yeah.

03:54:15.000 --> 03:54:16.000
Mm-hmm.

03:54:16.000 --> 03:54:27.000
Right? So, what exactly we did was, like, we… accumulated or calculated the dot product of the vectors among themselves.

03:54:27.000 --> 03:54:33.000
No? So, basically, it simply means that, that whenever you will do the search.

03:54:33.000 --> 03:54:34.000
It will call this function. That is what it means, with this data.

03:54:34.000 --> 03:54:38.000
Okay.

03:54:38.000 --> 03:54:41.000
Okay, so whatever I'm going to search… Uh, that is going to make a dot product of the vectors, uh, with this one.

03:54:41.000 --> 03:54:46.000
Hmm.

03:54:46.000 --> 03:54:51.000
Yeah, exactly. With this one, yes. In terms of doing a searching operation, yeah.

03:54:51.000 --> 03:54:52.000
Usually, it's a nomenclature that we are trying to set, that, okay, fine, so I'm trying to store our data into you.

03:54:52.000 --> 03:54:57.000
Because of this. Okay, so basic…

03:54:57.000 --> 03:55:01.000
And, uh, whenever I'll come for the search operation, so please make sure that, you know.

03:55:01.000 --> 03:55:02.000
Uh, do a search by using the dot, uh, like, dot product of it.

03:55:02.000 --> 03:55:06.000
All you're… download it. Downloaded.

03:55:06.000 --> 03:55:10.000
Order. So, index is nothing but just an object for this, uh, function.

03:55:10.000 --> 03:55:12.000
Exactly. It's a object reference for this one, yes.

03:55:12.000 --> 03:55:17.000
Got it, got it. Okay, actually, I just got a bit confused, because in search, we have not used it.

03:55:17.000 --> 03:55:18.000
Here, J.

03:55:18.000 --> 03:55:19.000
But here, we were using… Yeah, got it.

03:55:19.000 --> 03:55:24.000
Because, yeah, because at the time of the story itself, we have given that one, right? So… it will be able to understand automatically.

03:55:24.000 --> 03:55:30.000
Got it, got it, thank you. Uh, and uh, Sundajuk, one quick suggestion regarding the doubt clearing.

03:55:30.000 --> 03:55:31.000
Can we do a segregation, like, uh, you know, if people have just questions?

03:55:31.000 --> 03:55:36.000
Mm-hmm.

03:55:36.000 --> 03:55:37.000
They can ask first, and then we can move to the technical or more configuration.

03:55:37.000 --> 03:55:46.000
Mm-hmm. Oh, we can… we can do it, because, yeah, so we can close the questions, uh, for, uh, like, uh, in a fast, postal manner. Yeah, we can do it. We can do it, I think.

03:55:46.000 --> 03:55:54.000
Yep, yep. Because, like, although it was very interesting for me, I was… I was trying to troubleshoot with you, and, you know, help you.

03:55:54.000 --> 03:55:55.000
Yep.

03:55:55.000 --> 03:56:00.000
You will learn a lot, believe me. You will learn a lot. Because, see, everyone is having a different system, they have done something very different in their system.

03:56:00.000 --> 03:56:04.000
Some different folder. So, even if you just look at it, right? Believe me, it's a learning.

03:56:04.000 --> 03:56:10.000
Yeah, I agree, but actually, the problem is I am logging in from US for these classes.

03:56:10.000 --> 03:56:11.000
So, it is… yeah, it's get around, like, 3 AM already in the morning.

03:56:11.000 --> 03:56:14.000
Okay, okay.

03:56:14.000 --> 03:56:20.000
Oh, then fine, I can understand that, fine, I'll do one thing, so from next class onwards.

03:56:20.000 --> 03:56:25.000
Uh, when I started out clearing, so first of all, I closed the question, only questions, and then I'll close the screen sharing part.

03:56:25.000 --> 03:56:27.000
Got it. Yep, thank you so much for that. Thank you.

03:56:27.000 --> 03:56:36.000
Yep, yep, take it, yep. Yeah, yeah. So Conda, uh, Mukesh, it is not able to organize, so please install the conda, first of all.

03:56:36.000 --> 03:56:37.000
And if you have done that… already done that?

03:56:37.000 --> 03:56:45.000
I installed this one. Yeah, yeah, I… I was stating that, like, where I have installed that one.

03:56:45.000 --> 03:56:46.000
Okay.

03:56:46.000 --> 03:56:52.000
Yeah, here, if you see, and created also, like, my name, or, uh, VectorDV under.

03:56:52.000 --> 03:56:53.000
Env.

03:56:53.000 --> 03:56:59.000
Hmm, conda, Python. Conda Python? This is not a default directory.

03:56:59.000 --> 03:57:03.000
I'm just giving. Ah, okay. I have given…

03:57:03.000 --> 03:57:04.000
Okay.

03:57:04.000 --> 03:57:15.000
No, no, no, no, no, no, no, no, no. So, that is the issue. You have changed the directory name while doing the installation, and that is the reason your VS Code is not able to organize. Just do one thing, uh, go on remove file.

03:57:15.000 --> 03:57:26.000
Or delete. Uh, let me do conda.

03:57:26.000 --> 03:57:52.000
Hmm.

03:57:52.000 --> 03:58:02.000
Yeah, Andrava, so what is your query? Other people can also share their screen, guys. So, people can share a multiple screen all together. I can check everyone's screen.

03:58:02.000 --> 03:58:08.000
Yeah, and Raba, so if you can start sharing your screen, I think you have paused your screen sharing.

03:58:08.000 --> 03:58:12.000
So everyone can share their screen together, guys. I can see your screens.

03:58:12.000 --> 03:58:14.000
Multiple screens at a time. Yeah.

03:58:14.000 --> 03:58:23.000
Yeah, hi, Sudan. Hope I'm audible. So, basically, this is a very, you know, basic level question. I think I already know what the reason is.

03:58:23.000 --> 03:58:24.000
Mm-hmm, mm-hmm.

03:58:24.000 --> 03:58:33.000
He, uh, this part of the query is getting executed. So, here… embedding and the class is being imported, and there is no issue in that.

03:58:33.000 --> 03:58:34.000
Mm-hmm. Okay.

03:58:34.000 --> 03:58:39.000
But when I'm trying to do some tech search, regardless of what I'm searching.

03:58:39.000 --> 03:58:40.000
Hmm.

03:58:40.000 --> 03:58:46.000
Uh, this is probably throwing an error. So, I am using an office laptop. I think it's an office laptop issue regarding to, uh…

03:58:46.000 --> 03:58:56.000
No, no, no, no, just show me, show me, show me that. Uh, SSL certificate verification, error verification failed, I think there is a key issue. Just show me the above one.

03:58:56.000 --> 03:59:06.000
Okay, one second.

03:59:06.000 --> 03:59:08.000
Yeah.

03:59:08.000 --> 03:59:14.000
Hmm, show me the… above 1?

03:59:14.000 --> 03:59:25.000
Give me a remote control, I'll check it by myself. Yeah, give me control. Hmm.

03:59:25.000 --> 03:59:39.000
Hmm, fine, so Yuri API key, everything is fine, and then generate embeddings.

03:59:39.000 --> 03:59:50.000
Fine. Line.

03:59:50.000 --> 03:59:57.000
I would exceeded the size limit, open the full output in a text editor.

03:59:57.000 --> 04:00:04.000
Output exceeded the size limit, so it is trying to return the output, but uh… It is exceeded the… Size…

04:00:04.000 --> 04:00:20.000
Because I'm getting a similar error in when I'm trying to… if you see the bottom part, I'll just take the screen once again.

04:00:20.000 --> 04:00:21.000
Hmm, hmm. Hmm.

04:00:21.000 --> 04:00:29.000
So this condo is already installed in my system. In the different folder, but at least it's allowed in that particular version. I have… seen, uh, certain environments also that I have created. But when I'm trying to, you know, install it, I think this code is correct, uh, the syntax.

04:00:29.000 --> 04:00:35.000
So, when I'm trying to do this, uh, then a similar type of error with that, uh, particular port ID of 443.

04:00:35.000 --> 04:00:47.000
So maybe it's an office laptop, that is why it is getting issue. That is why I wanted to ask you. So, for the next class, I will probably switch to my personal laptop, which… which has limited abilities, but I will try to do that.

04:00:47.000 --> 04:00:50.000
So I just wanted your confirmation on this.

04:00:50.000 --> 04:00:57.000
But if you create a verification, HTTP self-method. Uh, you are able to open up Euron website, right?

04:00:57.000 --> 04:01:03.000
Yes, yes, yes, everything. You're on a website, I'm able to hit the, uh, create the APIs as well.

04:01:03.000 --> 04:01:12.000
I'm able to do the Swagger interface. Those are all done, but this particular… when I'm trying to access the API.

04:01:12.000 --> 04:01:21.000
So, uh, then certain things are… Uh, getting messed up.

04:01:21.000 --> 04:01:32.000
So, this error, and as well as, uh, this hot. So both of them are of the… same type.

04:01:32.000 --> 04:01:37.000
Probably that… perhaps the port is disabled from my office laptop, I don't know.

04:01:37.000 --> 04:01:45.000
Whom there is a possibility. So, external certificate verification, right? Uh, yes.

04:01:45.000 --> 04:01:46.000
Hmm, hmm.

04:01:46.000 --> 04:01:53.000
We are concerned with ChatGPT, and they're saying that probably when the return is coming, uh… My firewall is adding some headers, which, uh, it's not able to understand.

04:01:53.000 --> 04:02:00.000
Exactly, yeah. So it is not allowing, like, our responses, basically, in your system.

04:02:00.000 --> 04:02:02.000
Okay, so this… if I switch to a personal laptop, this won't be an issue, right?

04:02:02.000 --> 04:02:11.000
Hmm, yeah, it's 30. Not at all, not at all. It will be, like, as it is, like, as it is running for every one of us.

04:02:11.000 --> 04:02:12.000
Unable to get a local issuer certificate, hmm, that is the only issue.

04:02:12.000 --> 04:02:15.000
Okay, okay.

04:02:15.000 --> 04:02:26.000
So, when you receive a packet, right? So, inside your system, if there is a security, so it will try to match that, whether this packet inside my system is allowed or not.

04:02:26.000 --> 04:02:31.000
This is what you are getting in the last line. Unable to get a local issuer certificate, so it is not able to.

04:02:31.000 --> 04:02:33.000
Your local is not able to verify that one.

04:02:33.000 --> 04:02:39.000
Okay, okay. Uh, and one more, uh. Perhaps request or feedback that I have is that, uh…

04:02:39.000 --> 04:02:41.000
Mm-hmm.

04:02:41.000 --> 04:02:49.000
I know from prior experience that you do not entertain all these, uh, chats that you see in the chat window because of sheer lack of time or repeated questions.

04:02:49.000 --> 04:02:52.000
Mm-hmm, mm-hmm. Hmm. Mm-hmm.

04:02:52.000 --> 04:02:58.000
Uh, but in case the, uh, like, for myself, I'm asking some valid questions related to this particular class.

04:02:58.000 --> 04:02:59.000
So, is there any way that Zoom tries to, you know.

04:02:59.000 --> 04:03:03.000
Mm-hmm.

04:03:03.000 --> 04:03:07.000
Undermine those, or boost up certain requests, because I have been asking.

04:03:07.000 --> 04:03:12.000
Zoom gives you… Zoom gives you just a simple window interface. Do whatever you want kind of a thing.

04:03:12.000 --> 04:03:13.000
Okay, but…

04:03:13.000 --> 04:03:27.000
So generally, what happens is, like, when people are, like, you know, sending a message frequently. So, again, Zoom is Zoom, which will show you the message, but I'm a person, right? I'm a human being. I can focus only on certain questions. If questions is, you know.

04:03:27.000 --> 04:03:34.000
Uh, coming frequently. Uh, that might be the issue, but yeah. So, Zoom is a…

04:03:34.000 --> 04:03:35.000
Yeah, yeah, obviously, obviously, yeah, yeah, obviously. I receive all of your messages.

04:03:35.000 --> 04:03:41.000
Yeah. But you are… you are receiving those things, right? That is why you're…

04:03:41.000 --> 04:03:47.000
So, uh, so is there any reason why you will, uh, you know, not entering a particular question or a particular set of questions?

04:03:47.000 --> 04:03:52.000
Whatever I see, I just entertain it at that point of a time.

04:03:52.000 --> 04:03:53.000
Okay, okay. It's not like that it is something of a stupid question.

04:03:53.000 --> 04:03:57.000
Yeah. No, no, not like a priority.

04:03:57.000 --> 04:04:05.000
Even though I don't… I didn't ask stupid questions today, I asked 3 or 4 relevant questions.

04:04:05.000 --> 04:04:06.000
It's a running, uh, flow.

04:04:06.000 --> 04:04:17.000
It's all… matter of fact, it's like, uh, when I'm looking at the chat screen, right? So… Exactly, it's a running flow of the messages, so which message is there at that point of a time? Because I know, anyhow, we have a doubt clean session, so over there, people can discuss anything.

04:04:17.000 --> 04:04:34.000
Yeah, but the one problem that I have is that now we're at a rudimentary stage, right? So, if I miss something, I probably, after class, I will… I'll have to do this entire class again, that's okay with me. But, uh, moving ahead, uh, as the classes get more complex, if we miss one step.

04:04:34.000 --> 04:04:37.000
Or if we do not understand the clarity behind it, then the later… the rest of the class is as futile.

04:04:37.000 --> 04:04:47.000
Comes without stream. A simple thing is, even if I'm going to skip one topic, and if people are… even if I'm, like, not able to explain one topic in a clear manner.

04:04:47.000 --> 04:04:50.000
For sure, people will ask those questions in a doubt clearing, I know.

04:04:50.000 --> 04:04:58.000
And then I have to clarify it, right? So anyhow, like, if you are not able to understand, it will be not just your problem, it will be many people's problem.

04:04:58.000 --> 04:05:00.000
And, uh, obviously, many people will ask it. So anyhow. We are going to talk about it.

04:05:00.000 --> 04:05:07.000
Yes, certain of the people who are also raising the same questions, which was entertained much later on. Probably it hit your eye at that point of time, I understand.

04:05:07.000 --> 04:05:15.000
Yeah, because immediately I don't need it, and if I will keep on entertaining all the questions, then.

04:05:15.000 --> 04:05:17.000
My first law will go just in a question answering. Yeah, so don't worry about it. Anyhow, it will be handled, yeah?

04:05:17.000 --> 04:05:25.000
Yeah, yeah, fine, I understand your headache, James. Okay. And one more point that I wanted to, uh, you know, add.

04:05:25.000 --> 04:05:41.000
Hmm.

04:05:41.000 --> 04:05:42.000
Hmm.

04:05:42.000 --> 04:06:01.000
Or rather ask, is that I found in the WhatsApp group, many of them are quite pro into, uh, you know, programming and all that. They were able to do the, uh, assignment that you have given, uh, related, uh, to the API second course, right? So, whatever you've taught in class, I was able to replicate it, uh, and I was able to understand not a problem.

04:06:01.000 --> 04:06:02.000
Hmm, hmm.

04:06:02.000 --> 04:06:10.000
Going through a PDF, that 7-point PDF that you have KM7 or 8-point, I… it's kind of complex. Now, I can… I can surely, you know, upload it onto ChatGPT or any Gemini or Cursor or whatever, and I can get an output, but I don't want to go through that… you know, dumb process. You know, Usman Kali ko di rega aapko pandrame me tachalagea, but you have not learned anything in the long run, and you will not…

04:06:10.000 --> 04:06:23.000
No, no, say, learning… learning doesn't mean that you will write line-by-line code, even in a current situation, right? No one of… none of us are doing it. So, learning simply means that, first of all, try to find out the solution, and then out of curiosity, you have to understand the solution.

04:06:23.000 --> 04:06:37.000
So let's suppose even if you are going to generate those solutions from a chat GPT or anywhere, and if you are trying to focus over there for Hapmi will, like, it will just take 10 minutes of time to generate the code, but maybe if you're spending half an hour, 45 minute time, you will be able to understand it.

04:06:37.000 --> 04:06:38.000
So that is a good process to learn.

04:06:38.000 --> 04:06:54.000
Right? And that was the purpose behind the… That is… that is actually a best process to learn in a current situation, because, see, code means what? There can be a millions of combination, right? There can be a hundreds of ways to solve the exact same problem, and if I'm going to give this problem to 100 people, obviously, if you'll check their code, everyone else's code will be different.

04:06:54.000 --> 04:06:59.000
Right? Everyone's code will be literally different. But again, the core fundamentals is going to be exact same. There is no changes at all.

04:06:59.000 --> 04:07:14.000
So, this is how actual development happens. So, again, we write a 10th house line of code. Even 5 years back, when there was no AI, right? So we were writing a 5,000 line of code 10,000 line of code. Now, none of the code or none of the lines we remember, right? We just remember the concept.

04:07:14.000 --> 04:07:19.000
Yes.

04:07:19.000 --> 04:07:20.000
Exactly, that's a… that's a writer. Solving a problem and then understanding the solution.

04:07:20.000 --> 04:07:25.000
Actually, I have taken a lot of help from that, but I just wanted to, whether that's the right approach or not, because I have created…

04:07:25.000 --> 04:07:28.000
Is the right approach in a current situation?

04:07:28.000 --> 04:07:35.000
Okay, because I've created all the things in my screen is what I've created all of these, uh.

04:07:35.000 --> 04:07:42.000
You know, workflows for my company, and they have reduced my workload from 3 to 4 hours to around 15-20 minutes.

04:07:42.000 --> 04:07:43.000
Okay, and even if you are going… going to join some organization, right? You will be doing the exact same thing.

04:07:43.000 --> 04:07:49.000
I guess, you know, it's credit market.

04:07:49.000 --> 04:07:57.000
So, it's more like finding the solution, knowing a lot of things together. So, as of now, if someone is going to come and claim that I'm master of one.

04:07:57.000 --> 04:08:04.000
Now, that was true, and that was working since the last couple of decades, or so many decades, but now it's not true.

04:08:04.000 --> 04:08:08.000
You should be knowing everything, and you should be able to find out the solution immediately.

04:08:08.000 --> 04:08:12.000
With the help of AI. And if you're not doing it, again, so someone else will do it with the help of.

04:08:12.000 --> 04:08:16.000
What I understand is that, Abhito, it said it's become a necessity, uh, because I am actually… I'm from Telecom, so it is completely not related to me.

04:08:16.000 --> 04:08:21.000
Hmm. Hmm.

04:08:21.000 --> 04:08:27.000
But automation, though what I understand. Will be affecting everything, all of… all of the field. It is agnostic to…

04:08:27.000 --> 04:08:30.000
Even… even… even agriculture.

04:08:30.000 --> 04:08:39.000
Yeah, even agriculture, right. And on top of that, everything right now, today, lies on data, you know, kind of data that has been pulled at the back end.

04:08:39.000 --> 04:08:40.000
Yeah.

04:08:40.000 --> 04:08:46.000
Uh, to, uh, it's huge. I mean, I've, I've seen what my current company has done with data.

04:08:46.000 --> 04:08:51.000
And what they are going to do in the future, you know, I won't mention the OEM.

04:08:51.000 --> 04:09:01.000
But it's huge. So that is why I jumped shipped onto this, and probably if a data center comes up in my vicinity, I'll probably have a chance to shift onto that.

04:09:01.000 --> 04:09:04.000
So that is why I'm running. So, I'm learning to conduct…

04:09:04.000 --> 04:09:14.000
Um, optioning, yeah, Vito.

04:09:14.000 --> 04:09:15.000
Exactly.

04:09:15.000 --> 04:09:21.000
Alright, actually, actually, in the last 2 years, I got appreciation also, you know, for the kind of work that I'm doing.

04:09:21.000 --> 04:09:25.000
Same level pehena toh, are we a free season come mughey, toh, I have to upgrade myself.

04:09:25.000 --> 04:09:39.000
Subject HL, right? Hara industry mein hai. Change hoge ya. And again, aap totalasana.

04:09:39.000 --> 04:09:51.000
Hota nagi fast approach. That is the approach that we all should follow.

04:09:51.000 --> 04:09:56.000
Yeah, basically the backtracking learning that Chinese used for the last 10-15 years, and now they've overtaken the world.

04:09:56.000 --> 04:09:57.000
That is what you're saying.

04:09:57.000 --> 04:10:09.000
Exactly. But copy-paste karke, or, like, reverse engineering karke? Unone hai?

04:10:09.000 --> 04:10:10.000
And now their base is so good that now they can, you know it like hell, OSI Hoda.

04:10:10.000 --> 04:10:19.000
Sabanaliya hai. Exactly, exactly. Take care. Is it a move fast. See, aapkona parfaito tani, dunya mein perfection aka cheese ini hotay gush bhi.

04:10:19.000 --> 04:10:23.000
The perfection is just a state of mind. Kia perfect hai.

04:10:23.000 --> 04:10:32.000
Is just a state of mind for that particular point of a time.

04:10:32.000 --> 04:10:37.000
The simple philosophy in our life, even I have used it in my entire entrepreneurship journey.

04:10:37.000 --> 04:10:40.000
Is move as fast as possible.

04:10:40.000 --> 04:10:42.000
Thanks, thanks.

04:10:42.000 --> 04:10:49.000
Nick, thanks. Uh, yes, Al Jha, yeah. So, I think you are sharing your screen, so let me know.

04:10:49.000 --> 04:11:02.000
How I can help. Ma'am, I think you are on mute, so if you can unmute yourself…

04:11:02.000 --> 04:11:08.000
Hello? Hello? I think, ma'am, you are not audible…

04:11:08.000 --> 04:11:15.000
To me?

04:11:15.000 --> 04:11:34.000
Hello.

04:11:34.000 --> 04:11:39.000
Hello, hello.

04:11:39.000 --> 04:11:47.000
Ma'am, you're not audible to me. Anyone, guys, who is able to hear Salja?

04:11:47.000 --> 04:11:54.000
No, right? Yeah. Hello, hello.

04:11:54.000 --> 04:12:06.000
Maybe you're not audible. Maybe you can, like, ping your, uh… question, or maybe concern, or whatever you are facing inside a chat group, yeah?

04:12:06.000 --> 04:12:10.000
So, inside our WhatsApp chat group, and then let's have a discussion over there.

04:12:10.000 --> 04:12:18.000
We'll try to fix your issue. Because I'm not able to hear you, ma'am.

04:12:18.000 --> 04:12:27.000
Okay, so fine guys, thank you so much everyone, and take care, see you again, not next week, so next week, I'm on leave. I've already made an announcement, I'll make an announcement again inside the group.

04:12:27.000 --> 04:12:34.000
Uh, again, those who will be joining, uh, are new group members, so help them out to understand that.

04:12:34.000 --> 04:12:44.000
There is no class next week, right? And, uh, yeah, so next to next week, again, we'll try to continue from the same state, a vector database. So, we are not done with the vector DB.

04:12:44.000 --> 04:12:51.000
Uh, there are so many things that we have to discuss, even from a vector DB. So with that, thank you so much, everyone. Take care, hope all of you are liking it. With that.

04:12:51.000 --> 04:12:55.000
Thank you so much, everyone. Happy Sunday to all of you.

